
<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8">
	<title>the nullfactory</title>
	<meta name="description" content="the nullfactory">
	<meta name="keywords" content="ALM,Azure,Azure Storage Accounts,CDN,Code Access Security,commitizen,conventional-changelog,Deployment,Dynamics CRM,Dynamics CRM Online,Entity Framework,generator-nullfactory-xrm,Git,HtmlAgilityPack,Hyper-V,Log4Net,Miscellaneous,Mobile Development,nodejs,npm,Octopus Deploy,PowerShell,REST,Security,SharePoint,SOAP,SQL Server,SQL Server Data Tools,SQL Server Reporting Services,StyleCop,Team Build,Team Foundation Server,TFS Tips,TFSVC,Virtualization,Visual Studio,Visual Studio Team Services,WCF,Windows,Windows Phone,Yeoman" />

	<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="the nullfactory" Feed">
	<meta http-equiv="content-type" content="text/html; charset=utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1.0" />
	<link rel="stylesheet" href="http://www.nullfactory.net/stylesheets/base.css" type="text/css" />
	<link rel="stylesheet" href="http://www.nullfactory.net/stylesheets/github.css" type="text/css" />
	<link href='http://fonts.googleapis.com/css?family=Lato' rel='stylesheet' type='text/css'>
	<link rel="stylesheet" href="http://www.nullfactory.net/stylesheets/octicons.css" type="text/css" />
  <link rel="stylesheet" type="text/css" href="http://www.nullfactory.net/stylesheets/font-awesome/css/font-awesome.min.css" />
	<link rel="canonical" href="http://nullfactory.net/page4/" />
</head>
<body>
  <!-- header -->

	<div class="header-container">
	  <header>
		  <ul class="nav">
			<!--Change the  URL here if working on an absolute domain-->
			<li><a href="http://www.nullfactory.net"><span class="mega-octicon octicon-terminal" style="margin-right: 6px;"></span>the nullfactory</a></li>
			<li><a href="http://www.nullfactory.net/archive"><span class="mega-octicon octicon-book" style="margin-right: 6px;"></span>archive</a></li>
			<li><a href="http://www.nullfactory.net/about"><span class="mega-octicon octicon-person" style="margin-right: 6px;"></span>about</a></li>
		  </ul>
	  </header>
	</div>

  <!-- header -->

  <div class="container">
	
<header>
  <div class="head-inner">
    <!--<h2>&nbsp;</h2>-->
  </div>
</header>
 <div class="listing">
    <div class="post other link">
      <h2><span class="mega-octicon octicon-file-text" style="min-width: 32px;"></span><a href="/2015/11/strategy-updating-sql-server-schema-via-ssdt-delta-script/">Strategy for Updating a SQL Server Database Schema via SSDT Delta Script</a></h2>
      <p class="post-date">25 Nov 2015

      | <a href="/category/sql-server" title="SQL Server">SQL Server</a>
      | <a href="/category/sql-server-data-tools" title="SQL Server Data Tools">SQL Server Data Tools</a>
</p>

      <p>
		
		<p>This posts talks about the high level steps I went through in order to get the SQL Server related components ready for automation in a project I worked on recently. </p>

<p>This project uses SQL Server Data Tools (SSDT) project in order to maintain the database schema in source control. Its output - the Data-tier Application Component Packages (DACPAC) gets deployed into the appropriate target environment via a WebDeploy package. And considering that the solution was designed as an Entity Framework (EF) database first approach, code first migrations were not a viable upgrade strategy.</p>

<p>Here are the steps I followed in order to bring the production environment up-to-date: </p>


		<p><a href="/2015/11/strategy-updating-sql-server-schema-via-ssdt-delta-script/">Read more...</a></p>
	  </p>
    </div>
    <div class="post other link">
      <h2><span class="mega-octicon octicon-file-text" style="min-width: 32px;"></span><a href="/2015/10/cdn-streaming-video-azure-storage/">Setting up a CDN to Stream Video via Azure Storage</a></h2>
      <p class="post-date">11 Oct 2015

      | <a href="/category/azure" title="Azure">Azure</a>
      | <a href="/category/cdn" title="CDN">CDN</a>
      | <a href="/category/azure-storage-accounts" title="Azure Storage Accounts">Azure Storage Accounts</a>
</p>

      <p>
		
		<p>I needed to setup an Azure Content Delivery Network (CDN) in order to stream some video files stored in Azure Blob Storage. Sounds simple enough right? Well, yes for the most part, but I did hit a few hurdles along the way. This post would hopefully help me avoid them the next time.</p>

<h2>Create the Storage Account</h2>

<p>Something I found out after the fact was that CDN endpoints <a href="http://stackoverflow.com/questions/32569564/azure-resource-manager-deployment-vs-classic-deployment-of-storage-accounts">currently only support classic storage accounts</a>. So the first order of business is to create a classic storage account either via old portal or using a <a href="/2015/10/deploy-classic-storage-azure-resource-manager/">resource group manager template</a>. </p>

<p>Another thing I found out is that, at the time of writing, classic storage accounts cannot be made under the 'East US' location. The closest alternative was 'East US 2' and worked fine; I guess its something worth considering if you wanted to co-locate all your resources.</p>

<p>Next, create a container within storage account - the container would host the files that would be served by the CDN. It can be created manually via the old portal or even through visual studio. Ensure that container access type is set to <code>Public Blob</code>.</p>

<h2>Upgrade the Storage Account to a Newer Service Version</h2>

<p>The first time I tried to tried to stream a video, it did not work as expected; stream was very choppy. It turns out that the service version that got set on the storage was not the latest. <a href="http://blog.thoughtstuff.co.uk/2014/01/streaming-mp4-video-files-in-azure-storage-containers-blob-storage/">Read more here</a>, <a href="https://msdn.microsoft.com/library/azure/dd894041.aspx">and here</a>.</p>

<p>So the next step is update the storage account to the latest version in order to take advantage of the improvements. This can be done using the following code:</p>

<pre><code>    var credentials = new StorageCredentials("accountname", "accountkey");
    var account = new CloudStorageAccount(credentials, true);
    var client = account.CreateCloudBlobClient();
    var properties = client.GetServiceProperties();
    properties.DefaultServiceVersion = "2013-08-15";
    client.SetServiceProperties(properties);
    Console.WriteLine(properties.DefaultServiceVersion);
</code></pre>


		<p><a href="/2015/10/cdn-streaming-video-azure-storage/">Read more...</a></p>
	  </p>
    </div>
    <div class="post other link">
      <h2><span class="mega-octicon octicon-file-text" style="min-width: 32px;"></span><a href="/2015/10/deploy-classic-storage-azure-resource-manager/">Deploying a Azure Classic Storage Account using Azure Resource Manager</a></h2>
      <p class="post-date">10 Oct 2015

      | <a href="/category/azure" title="Azure">Azure</a>
      | <a href="/category/deployment" title="Deployment">Deployment</a>
      | <a href="/category/azure-storage-accounts" title="Azure Storage Accounts">Azure Storage Accounts</a>
</p>

      <p>
		
		<p>I've been working on Azure Resource Group templates quite a bit over the last few weeks. While it has been a pleasant experience overall, I ran into some hurdles the other day while attempting to figure out how to create a <code>Microsoft.ClassicStorage/StorageAccounts</code> using the Azure Resource Manager(ARM) API.</p>

<p>The latest version (2.7 at the time of writing) of Azure SDK GUI tools for visual studio were not particularly helpful in generating the required json, but thankfully <a href="http://stackoverflow.com/questions/27347200/add-storage-to-azure-resource-manager">this</a> post pointed me in the right direction. And after a little bit of fiddling I find that <code>2015-06-01</code> appears to be last supported <code>apiVersion</code> that works with classic storage.</p>

<p><a href="/images/posts/DeployClassicStorageArm/10_SupportedVersion.png"><img src="/images/posts/DeployClassicStorageArm/10_SupportedVersion.png" alt="Azure PowerShell Unsupported" /></a></p>

<p>Here's the final script I used to create a classic storage container: </p>

<pre><code>{
    "$schema": "https://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
    "contentVersion": "1.0.0.0",
    "parameters": {
        "PrimaryStorageName": {
            "type": "string"
        },
        "PrimaryStorageType": {
            "type": "string",
            "defaultValue": "Standard_LRS",
            "allowedValues": [
                "Standard_LRS",
                "Standard_GRS",
                "Standard_ZRS"
            ]
        },
        "PrimaryStorageLocation": {
        "type": "string",
        "defaultValue": "East US",
        "allowedValues": [
            "East US",
            "West US",
            "West Europe",
            "East Asia",
            "South East Asia"
            ]
        }
    },
    "variables": {
    },
    "resources": [
        {
            "name": "[parameters('PrimaryStorageName')]",
            "type": "Microsoft.ClassicStorage/StorageAccounts",
            "location": "[parameters('PrimaryStorageLocation')]",
            "apiVersion":  "2015-06-01",
            "dependsOn": [ ],
            "properties": {
                "accountType": "[parameters('PrimaryStorageType')]"
            }
        }
    ],
    "outputs": {
    }
}
</code></pre>


		<p><a href="/2015/10/deploy-classic-storage-azure-resource-manager/">Read more...</a></p>
	  </p>
    </div>
    <div class="post other link">
      <h2><span class="mega-octicon octicon-file-text" style="min-width: 32px;"></span><a href="/2015/08/publishing-assemblies-without-gacutil/">Publishing Assemblies into the GAC without GacUtil</a></h2>
      <p class="post-date">31 Aug 2015

      | <a href="/category/deployment" title="Deployment">Deployment</a>
</p>

      <p>
		
		<p>I constantly find myself googling this code snippet - its nice to keep handy: </p>

<pre><code>[System.Reflection.Assembly]::Load("System.EnterpriseServices, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b03f5f7f11d50a3a")
$publish = New-Object System.EnterpriseServices.Internal.Publish
$publish.GacInstall("c:\temp\publish_dll.dll")
</code></pre>


		<p><a href="/2015/08/publishing-assemblies-without-gacutil/">Read more...</a></p>
	  </p>
    </div>
    <div class="post other link">
      <h2><span class="mega-octicon octicon-file-text" style="min-width: 32px;"></span><a href="/2015/08/sharing-configuration-between-webjobs/">Sharing Configuration Between WebJobs</a></h2>
      <p class="post-date">29 Aug 2015

      | <a href="/category/azure" title="Azure">Azure</a>
</p>

      <p>
		
		<p>The project I am working on started out with the single webjob and has since grown to multiple jobs running in parallel. They are all hosted within a dedicated web app, which allows us to scale the jobs independent of the rest of the application. And because they share a single container there is the added side effect of the jobs sharing all the Application Settings and connection strings too.</p>

<p>While each webjob had its own class library, I didn't want to maintain multiple copies of  the <code>App.Config</code> file. I decided to share the the common bits (<code>AppSettings</code> and <code>ConnectionString</code> sections) in their own files:</p>

<ol>
<li><p>In one of the webjob projects, I moved the <code>AppSettings</code> and <code>ConnectionStrings</code> into their own <code>.config</code> files - <code>appSettings.config</code> and <code>connectionStrings.config</code> respectively.</p></li>
<li><p>Next, I referenced them back to the <code>App.config</code> using the <code>configSource</code> attribute.</p></li>
<li><p>Finally, I added the same files as linked files to the otherweb jobs and set their <code>Copy to Output Directory</code> file property to <code>Copy Always</code>.</p></li>
</ol>

<p>This works well enough, but for one caveat - which prompted me to write this post in the first place. The problem is that the <code>Web Deploy Package</code> publishing process does not appear to honor folder structures for the config files. That means that if you've separated the configuration into sub folders (like shown below), the publishing process would flatten it out.</p>


		<p><a href="/2015/08/sharing-configuration-between-webjobs/">Read more...</a></p>
	  </p>
    </div>
    <div class="post other link">
      <h2><span class="mega-octicon octicon-file-text" style="min-width: 32px;"></span><a href="/2015/08/enable-ssrs-remote-error-sharepoint-integrated/">Enable SSRS Remote Errors in SharePoint Integrated Mode</a></h2>
      <p class="post-date">28 Aug 2015

      | <a href="/category/sharepoint" title="SharePoint">SharePoint</a>
      | <a href="/category/sql-server-reporting-services" title="SQL Server Reporting Services">SQL Server Reporting Services</a>
</p>

      <p>
		
		<p>Any time I have to troubleshoot issues in SQL Server Reporting Services (SSRS) reports in a production environment, I usually end up enabling <code>Remote Errors</code> at some point as part my process. </p>

<p>Remote errors are enabled via the SSRS Service Application:</p>

<ol>
<li>Navigate to <code>Central Administration &gt; Application Management &gt; Manage Service Applications</code></li>
<li>Next, click on the appropriate  <code>SQL Server Reporting Services Service Application</code> service application to manage it. </li>
<li>Click <code>System Settings</code> from the toolbar.</li>
<li>Finally, enable remote errors by navigating into checking the <code>Enable Remote Errors</code> checkbox. </li>
</ol>


		<p><a href="/2015/08/enable-ssrs-remote-error-sharepoint-integrated/">Read more...</a></p>
	  </p>
    </div>
    <div class="post other link">
      <h2><span class="mega-octicon octicon-file-text" style="min-width: 32px;"></span><a href="/2015/06/entity-framework-multiple-context-namespace-collision/">Entity Framework Namespace Collisions When Working with Multiple Contexts</a></h2>
      <p class="post-date">03 Jun 2015

      | <a href="/category/entity-framework" title="Entity Framework">Entity Framework</a>
      | <a href="/category/sql-server" title="SQL Server">SQL Server</a>
</p>

      <p>
		
		<p>I came across the following exception whilst attempting working with a solution that contained a <em>couple of</em> Entity Framework (EF) 6 database contexts.</p>

<pre><code>System.Data.Entity.Core.MetadataException

Schema specified is not valid. Errors: 
The mapping of CLR type to EDM type is ambiguous because multiple CLR types match the EDM type 'Setting'. Previously found CLR type 'SqlHelper.Primary.Setting', newly found CLR type 'SqlHelper.Secondary.Setting'.

at System.Data.Entity.Core.Metadata.Edm.ObjectItemCollection.LoadAssemblyFromCache(Assembly assembly, Boolean loadReferencedAssemblies, EdmItemCollection edmItemCollection, Action`1 logLoadMessage)
at System.Data.Entity.Core.Metadata.Edm.ObjectItemCollection.ExplicitLoadFromAssembly(Assembly assembly, EdmItemCollection edmItemCollection, Action`1 logLoadMessage)
at System.Data.Entity.Core.Metadata.Edm.MetadataWorkspace.ExplicitLoadFromAssembly(Assembly assembly, ObjectItemCollection collection, Action`1 logLoadMessage)
at System.Data.Entity.Core.Metadata.Edm.MetadataWorkspace.LoadFromAssembly(Assembly assembly, Action`1 logLoadMessage)
at System.Data.Entity.Core.Metadata.Edm.MetadataWorkspace.LoadFromAssembly(Assembly assembly)
at System.Data.Entity.Internal.InternalContext.TryUpdateEntitySetMappingsForType(Type entityType)
at System.Data.Entity.Internal.InternalContext.UpdateEntitySetMappingsForType(Type entityType)
at System.Data.Entity.Internal.InternalContext.GetEntitySetAndBaseTypeForType(Type entityType)
at System.Data.Entity.Internal.Linq.InternalSet`1.Initialize()
at System.Data.Entity.Internal.Linq.InternalSet`1.get_InternalContext()
at System.Data.Entity.Internal.Linq.InternalSet`1.ActOnSet(Action action, EntityState newState, Object entity, String methodName)
at System.Data.Entity.Internal.Linq.InternalSet`1.Add(Object entity)
at System.Data.Entity.DbSet`1.Add(TEntity entity)
at MultiContextConsoleApp.Program.Main(String[] args) in e:\shane\Projects\Orca\Sandbox\MultiContextConsoleApp\MultiContextConsoleApp\Program.cs:line 16
at System.AppDomain._nExecuteAssembly(RuntimeAssembly assembly, String[] args)
at System.AppDomain.ExecuteAssembly(String assemblyFile, Evidence assemblySecurity, String[] args)
at Microsoft.VisualStudio.HostingProcess.HostProc.RunUsersAssembly()
at System.Threading.ThreadHelper.ThreadStart_Context(Object state)
at System.Threading.ExecutionContext.RunInternal(ExecutionContext executionContext, ContextCallback callback, Object state, Boolean preserveSyncCtx)
at System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Object state, Boolean preserveSyncCtx)
at System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Object state)
at System.Threading.ThreadHelper.ThreadStart()
</code></pre>


		<p><a href="/2015/06/entity-framework-multiple-context-namespace-collision/">Read more...</a></p>
	  </p>
    </div>
    <div class="post other link">
      <h2><span class="mega-octicon octicon-file-text" style="min-width: 32px;"></span><a href="/2015/06/generate-clean-up-script-drop-objects-sql-database/">Generate a Clean Up Script to Drop All Objects in a SQL Server Database</a></h2>
      <p class="post-date">02 Jun 2015

      | <a href="/category/sql-server" title="SQL Server">SQL Server</a>
</p>

      <p>
		
		<p>I needed a quick and reusable way to drop all SQL server objects from an Azure database. The objective was to have some kind of process to clean up and prep the database before the main deployment is kicked off. And given that I am particularly biased towards using a sql script my search for a solution focused around it.</p>

<p>In addition to actually dropping the artifacts, the script should be aware of the order in which it should do it - that is to drop the most dependent objects first and work its way towards the least dependent ones. And my nice-to-have feature is to be able to parameterize the schema name so that it could be used with a multi-tenant database schema.</p>

<p>I saw a few possible solutions and finally settled on using the <a href="http://stackoverflow.com/questions/536350/drop-all-the-tables-stored-procedures-triggers-constraints-and-all-the-depend">out-of-the-box feature</a> that's already available through SQL Server Management Studio (SSMS).</p>

<ol>
<li>Open up SQL Server Management Studio.</li>
<li><p>Select <code>Task  &gt; Generate Script...</code> on on your the database context menu. This would open up the <code>Generate and Publish Scripts</code> dialog.</p>

<p><img src="/images/posts/GenerateDropScript/10_ContextMenu.png" alt="SSMS Context Menu" /></p></li>
<li><p>First, navigate to the <code>Choose Objects</code> tab and select all the objects that need to be dropped.</p></li>
<li><p>Next, on the <code>Set Scripting Options</code> tab, select the preferred output location.</p>

<p><img src="/images/posts/GenerateDropScript/20_SetScriptingOptions.png" alt="Set Scripting Options" /></p></li>
<li><p>Next, click the <code>Advanced</code> button which result in the <code>Advanced Scripting Options</code> dialog.</p>

<p><img src="/images/posts/GenerateDropScript/30_AdvancedScriptingOptions.png" alt="Advanced Scripting Options" /></p></li>
<li><p>Navigate down towards to and change the <code>General &gt; Script DROP and CREATE</code> option to <code>Script DROP</code>.</p></li>
<li>Set the default values for the rest of the steps and finally click the <code>Finish</code> button.</li>
</ol>


		<p><a href="/2015/06/generate-clean-up-script-drop-objects-sql-database/">Read more...</a></p>
	  </p>
    </div>
    <div class="post other link">
      <h2><span class="mega-octicon octicon-file-text" style="min-width: 32px;"></span><a href="/2015/05/recording-diagnostics-azure-app-service-website-log4net/">Recording Diagnostics on a Azure App Service Hosted Website using Log4Net</a></h2>
      <p class="post-date">24 May 2015

      | <a href="/category/azure" title="Azure">Azure</a>
      | <a href="/category/log4net" title="Log4Net">Log4Net</a>
</p>

      <p>
		
		<p>I've been working on moving an existing web based software solution into the Azure cloud ecosystem. The solution is tightly integrated with and uses Log4Net as it logging framework. My primary goal, in terms of logging, was to keep as much of my original architecture intact and at the same time make maximum use of the diagnostics infrastructure that is available in Azure.</p>

<p>The <a href="http://azure.microsoft.com/en-in/documentation/articles/web-sites-enable-diagnostic-log/">official documentation states</a> that calls to the <code>System.Diagnostics.Trace</code> methods are all that is required to start capturing diagnostic information. In summary, this is all I needed to do:</p>

<ol>
<li>Enable diagnostics and configure the storage locations (discussed later down the post).</li>
<li>From within my code write the <code>Warning</code>, <code>Error</code> and <code>Information</code> messages via their respective trace methods.</li>
<li>...</li>
<li>Azure starts capturing the custom diagnostics information - PROFIT! </li>
</ol>

<p>Sounds simple enough. </p>

<p>So I thought if I just set up a <code>TraceAppender</code> everything would work fine and that would be the end of it. The results were not what I was expecting and this was the output in my table storage:</p>

<p><img src="/images/posts/AzureAppSvcDiag/10_AppServiceTableDiag.png" alt="Table Diagnostics" /></p>

<p>The trace entries are bunched together as a single <code>Verbose</code> entry and the writes appear to be buffered. Not acceptable. I suppose the buffering could be because I had not used the <code>ImmediateFlush</code> option for the <code>TraceAppender</code>, but I need to have each Trace statement to have its own entry in the table.</p>

<p>While there are a lot of posts on the internet on how to setup Log4Net with Azure, most of them appear to be out of date and seem to be compensating for features were not available in the Azure at the time of their implementation. Then there are others that targeted towards integrating with the Cloud Service which is not what I was looking for.</p>


		<p><a href="/2015/05/recording-diagnostics-azure-app-service-website-log4net/">Read more...</a></p>
	  </p>
    </div>
    <div class="post other link">
      <h2><span class="mega-octicon octicon-file-text" style="min-width: 32px;"></span><a href="/2015/05/start-azure-webjobs-on-demand/">Start Azure Web Jobs On Demand</a></h2>
      <p class="post-date">18 May 2015

      | <a href="/category/azure" title="Azure">Azure</a>
      | <a href="/category/powershell" title="PowerShell">PowerShell</a>
      | <a href="/category/rest" title="REST">REST</a>
</p>

      <p>
		
		<p>I've been working on an Azure based solution recently and have been using the free tiers to quickly get the solution up and running and to perform the first few QA cycles. The core solution is based around single app service website and then a second website that acts as the host for a continuous web job which is triggered via a queue.
The problem with the free tiers is that there's a high possibility that the web job would shut itself down and hibernate if it is <a href="http://azure.microsoft.com/en-us/documentation/articles/web-sites-create-web-jobs/">idle for more that 20 mins</a>:</p>

<blockquote>
  <p>As of March 2014, web apps in Free mode can time out after 20 minutes if there are no requests to the scm (deployment) site and the web app's portal is not open in Azure. Requests to the actual site will not reset this.</p>
</blockquote>

<p>A little research shows a few possible solutions:</p>

<ol>
<li>If the job is not time sensitive, then manually start the service remotely using a script or tool. </li>
<li>Make your code explicitly start the web job just as a new request is being enqueued. This can be done by <a href="https://github.com/projectkudu/kudu/wiki/WebJobs-API">making a REST call</a> to the deployment site.</li>
<li>And lastly, upgrade to a basic or standard tier and enabling "Always On" keeps the site (and jobs) "warm" and prevent them from hibernating.</li>
</ol>


		<p><a href="/2015/05/start-azure-webjobs-on-demand/">Read more...</a></p>
	  </p>
    </div>
</div>

  <div id="post-pagination" class="pagination">


      <p class="previous">
        <a href="/page3">Previous Page</a>
        </p>


    <p class="previous">
      <a href="/page5">Next Page</a>
    </p>

  </div>

  </div>

  <!-- /.main -->

  <script type="text/javascript">
var _gaq = _gaq || [];

_gaq.push(['_setAccount', 'UA-57983893-1']);
_gaq.push(['_trackPageview']);
        
(function () {
    var ga = document.createElement('script');
    ga.type = 'text/javascript';
    ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(ga, s);
})();
</script>
</body>
</html>

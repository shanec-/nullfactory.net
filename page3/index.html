
<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8">
	<title>the nullfactory</title>
	<meta name="description" content="the nullfactory">
	<meta name="keywords" content="ALM,Azure,Azure Storage Accounts,CDN,Code Access Security,commitizen,conventional-changelog,Deployment,Dynamics CRM,Dynamics CRM Online,Entity Framework,generator-nullfactory-xrm,Git,HtmlAgilityPack,Hyper-V,Log4Net,Miscellaneous,Mobile Development,nodejs,npm,Octopus Deploy,PowerShell,REST,Security,SharePoint,SQL Server,SQL Server Data Tools,SQL Server Reporting Services,Team Build,Team Foundation Server,TFS Tips,TFSVC,Virtualization,Visual Studio Team Services,Windows,Windows Phone,Yeoman" />

	<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="the nullfactory" Feed">
	<meta http-equiv="content-type" content="text/html; charset=utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1.0" />
	<link rel="stylesheet" href="http://www.nullfactory.net/stylesheets/base.css" type="text/css" />
	<link rel="stylesheet" href="http://www.nullfactory.net/stylesheets/github.css" type="text/css" />
	<link href='http://fonts.googleapis.com/css?family=Lato' rel='stylesheet' type='text/css'>
	<link rel="stylesheet" href="http://www.nullfactory.net/stylesheets/octicons.css" type="text/css" />
  <link rel="stylesheet" type="text/css" href="http://www.nullfactory.net/stylesheets/font-awesome/css/font-awesome.min.css" />
	<link rel="canonical" href="http://nullfactory.net/page3/" />
</head>
<body>
  <!-- header -->

	<div class="header-container">
	  <header>
		  <ul class="nav">
			<!--Change the  URL here if working on an absolute domain-->
			<li><a href="http://www.nullfactory.net"><span class="mega-octicon octicon-terminal" style="margin-right: 6px;"></span>the nullfactory</a></li>
			<li><a href="http://www.nullfactory.net/archive"><span class="mega-octicon octicon-book" style="margin-right: 6px;"></span>archive</a></li>
			<li><a href="http://www.nullfactory.net/about"><span class="mega-octicon octicon-person" style="margin-right: 6px;"></span>about</a></li>
		  </ul>
	  </header>
	</div>

  <!-- header -->

  <div class="container">
	
<header>
  <div class="head-inner">
    <!--<h2>&nbsp;</h2>-->
  </div>
</header>
 <div class="listing">
    <div class="post other link">
      <h2><span class="mega-octicon octicon-file-text" style="min-width: 32px;"></span><a href="/2016/04/non-searchable-field-breaks-pre-filtering/">Non-searchable Primary Key Field Breaks Pre-filtering</a></h2>
      <p class="post-date">16 Apr 2016

      | <a href="/category/dynamics-crm" title="Dynamics CRM">Dynamics CRM</a>
      | <a href="/category/dynamics-crm-online" title="Dynamics CRM Online">Dynamics CRM Online</a>
</p>

      <p>
		
		<p>I recently implemented a custom FetchXml based SSRS report that was designed to be run against a filtered list of accounts. The accounts were to be determined by the user at the time of execution, hence the report was setup to use pre-filtering on the accounts entity.</p>

<p>The report worked fine except in one environment where the user was greeted with the following warning message:</p>

<p><img src="/images/posts/PreFilterNonSearchable/10_FilteringError.png" alt="Filtering error" /></p>

<p>Dismissing the warning opened up the <code>Report Filtering Criteria</code> dialog with the following error:</p>

<pre><code>There was an error in showing this condition
</code></pre>

<p>And additional information:</p>

<pre><code>The condition was referencing the field accountid. The field has been removed from the system or is not valid for advanced find.
</code></pre>

<p><img src="/images/posts/PreFilterNonSearchable/20_ReportFilteringCriteria.png" alt="Report filtering criteria" /></p>


		<p><a href="/2016/04/non-searchable-field-breaks-pre-filtering/">Read more...</a></p>
	  </p>
    </div>
    <div class="post other link">
      <h2><span class="mega-octicon octicon-file-text" style="min-width: 32px;"></span><a href="/2016/04/dynamics-crm-base64-attachment-size/">Base64 and Maximum Attachment Size in Dynamics CRM</a></h2>
      <p class="post-date">15 Apr 2016

      | <a href="/category/dynamics-crm" title="Dynamics CRM">Dynamics CRM</a>
      | <a href="/category/dynamics-crm-online" title="Dynamics CRM Online">Dynamics CRM Online</a>
</p>

      <p>
		
		<p>Microsoft Dynamics CRM provides out-of-the-box functionality to store and associate small file attachments against an entity record. This is achieved via the <code>annotation</code> entity - it is similar to any other entity except that it stores meta data as well as the <a href="https://msdn.microsoft.com/en-us/library/gg334398.aspx">actual content of the file attachment</a> within it. </p>

<p>As CRM is not designed to be a <a href="http://www.optimalcrm.co.uk/storage-limit-reached-in-microsoft-dynamics-crm-online/">file store</a>, it imposes some limitations on the size of attachments that can be uploaded. Recent versions of the product, including 2016, defaults this size to 5120Kb which can be adjusted to a <a href="https://dynamicscrmherald.wordpress.com/2014/01/03/increasing-web-resource-and-email-note-attachment-file-size-in-microsoft-dynamics-crm-2013/">maximum hard limit of 32768Kb</a>. </p>

<p>However, there is one caveat with this limitation - CRM stores the byte stream in a base64 encoded format, this means that there would be an <a href="http://stackoverflow.com/questions/4715415/base64-what-is-the-worst-possible-increase-in-space-usage">increase</a> in the final saved file size. </p>


		<p><a href="/2016/04/dynamics-crm-base64-attachment-size/">Read more...</a></p>
	  </p>
    </div>
    <div class="post other link">
      <h2><span class="mega-octicon octicon-file-text" style="min-width: 32px;"></span><a href="/2016/01/crm-solution-tfs-microsoft-xrm-data-powershell/">Strategy for Maintaining CRM Solutions in Team Foundation Server using Microsoft.Xrm.Data.PowerShell</a></h2>
      <p class="post-date">21 Jan 2016

      | <a href="/category/dynamics-crm" title="Dynamics CRM">Dynamics CRM</a>
      | <a href="/category/team-foundation-server" title="Team Foundation Server">Team Foundation Server</a>
      | <a href="/category/alm" title="ALM">ALM</a>
</p>

      <p>
		
		<p>I've come across a few strategies on the internet on achieving this goal, with each one having its pros and cons. This post describes my own attempt at setting up a development workflow that can be integrated with the team builds.</p>

<p>This implementation at its core revolves around the <a href="https://github.com/seanmcne/Microsoft.Xrm.Data.PowerShell"><code>Microsoft.Xrm.Data.PowerShell</code></a> module and the <code>Solution Packager</code> tool provided with the official SDK. I have minimized the use of 3rd party libraries and have intentionally excluded the use of any visual studio extensions or helper tools.</p>

<h2>Setting up the Tools</h2>

<h3>Installing Microsoft.CrmSdk.CoreTools</h3>

<p>Let's start off by creating a "tooling" project that would act as a hosts for the tools and scripts involved in the process.</p>

<ol>
<li>Create a class library project to host the tools using for building the packages. I named mine <code>Nullfactory.Crm.Tooling</code>.</li>
<li><p>Install the <code>Microsoft.CrmSdk.CoreTools</code> nuget package by running the following command in the package manager console: </p>

<p><code>Install-Package Microsoft.CrmSdk.CoreTools -Project Nullfactory.Crm.Tooling</code></p>

<p>This nuget package includes the <code>SolutionPackager.exe</code> tool.</p>

<p><img src="/images/posts/CrmDataPowershell/10_InstallCoreTools.png" alt="Install Crm Core Tools" /></p></li>
<li><p>Next, clean up the project by removing the default <code>Class1.cs</code> file as well as the <code>Debug</code> and <code>Release</code> within the <code>bin</code> folder.</p></li>
<li><p>Update the solution configurations to not build this project. Do this by navigating to the solution property pages > <code>Configuration Properties</code> and un-ticking the check box against the build column.</p>

<p><img src="/images/posts/CrmDataPowershell/20_DontBuild.png" alt="Do not Build Project" /></p></li>
</ol>


		<p><a href="/2016/01/crm-solution-tfs-microsoft-xrm-data-powershell/">Read more...</a></p>
	  </p>
    </div>
    <div class="post other link">
      <h2><span class="mega-octicon octicon-file-text" style="min-width: 32px;"></span><a href="/2015/12/disabling-recurring-ondemand-webjob/">Disabling Recurring and OnDemand Web Jobs within a Deployment Slot</a></h2>
      <p class="post-date">20 Dec 2015

      | <a href="/category/azure" title="Azure">Azure</a>
</p>

      <p>
		
		<p>I've come to realize that things can get a bit tricky when working with slot deployments and webjobs. I learned <em>the hard way</em> that stopping a slotted Web App does <strong>not</strong> stop the web jobs it hosts. This means that I can't just stop all my website slots and expect the related jobs to automatically shutdown as well. Bummer. 
Okay, so I am thinking maybe I'll just disable the individual jobs for each of the slots? Not much luck on that front either as the Azure portal only provides a <code>stop</code> option for <code>continuous</code> jobs and not for the <code>recurring</code> and <code>OnDemand</code> jobs.</p>

<p>This limits us to a few possible solutions:</p>


		<p><a href="/2015/12/disabling-recurring-ondemand-webjob/">Read more...</a></p>
	  </p>
    </div>
    <div class="post other link">
      <h2><span class="mega-octicon octicon-file-text" style="min-width: 32px;"></span><a href="/2015/11/strategy-updating-sql-server-schema-via-ssdt-delta-script/">Strategy for Updating a SQL Server Database Schema via SSDT Delta Script</a></h2>
      <p class="post-date">25 Nov 2015

      | <a href="/category/sql-server" title="SQL Server">SQL Server</a>
      | <a href="/category/sql-server-data-tools" title="SQL Server Data Tools">SQL Server Data Tools</a>
</p>

      <p>
		
		<p>This posts talks about the high level steps I went through in order to get the SQL Server related components ready for automation in a project I worked on recently. </p>

<p>This project uses SQL Server Data Tools (SSDT) project in order to maintain the database schema in source control. Its output - the Data-tier Application Component Packages (DACPAC) gets deployed into the appropriate target environment via a WebDeploy package. And considering that the solution was designed as an Entity Framework (EF) database first approach, code first migrations were not a viable upgrade strategy.</p>

<p>Here are the steps I followed in order to bring the production environment up-to-date: </p>


		<p><a href="/2015/11/strategy-updating-sql-server-schema-via-ssdt-delta-script/">Read more...</a></p>
	  </p>
    </div>
    <div class="post other link">
      <h2><span class="mega-octicon octicon-file-text" style="min-width: 32px;"></span><a href="/2015/10/cdn-streaming-video-azure-storage/">Setting up a CDN to Stream Video via Azure Storage</a></h2>
      <p class="post-date">11 Oct 2015

      | <a href="/category/azure" title="Azure">Azure</a>
      | <a href="/category/cdn" title="CDN">CDN</a>
      | <a href="/category/azure-storage-accounts" title="Azure Storage Accounts">Azure Storage Accounts</a>
</p>

      <p>
		
		<p>I needed to setup an Azure Content Delivery Network (CDN) in order to stream some video files stored in Azure Blob Storage. Sounds simple enough right? Well, yes for the most part, but I did hit a few hurdles along the way. This post would hopefully help me avoid them the next time.</p>

<h2>Create the Storage Account</h2>

<p>Something I found out after the fact was that CDN endpoints <a href="http://stackoverflow.com/questions/32569564/azure-resource-manager-deployment-vs-classic-deployment-of-storage-accounts">currently only support classic storage accounts</a>. So the first order of business is to create a classic storage account either via old portal or using a <a href="/2015/10/deploy-classic-storage-azure-resource-manager/">resource group manager template</a>. </p>

<p>Another thing I found out is that, at the time of writing, classic storage accounts cannot be made under the 'East US' location. The closest alternative was 'East US 2' and worked fine; I guess its something worth considering if you wanted to co-locate all your resources.</p>

<p>Next, create a container within storage account - the container would host the files that would be served by the CDN. It can be created manually via the old portal or even through visual studio. Ensure that container access type is set to <code>Public Blob</code>.</p>

<h2>Upgrade the Storage Account to a Newer Service Version</h2>

<p>The first time I tried to tried to stream a video, it did not work as expected; stream was very choppy. It turns out that the service version that got set on the storage was not the latest. <a href="http://blog.thoughtstuff.co.uk/2014/01/streaming-mp4-video-files-in-azure-storage-containers-blob-storage/">Read more here</a>, <a href="https://msdn.microsoft.com/library/azure/dd894041.aspx">and here</a>.</p>

<p>So the next step is update the storage account to the latest version in order to take advantage of the improvements. This can be done using the following code:</p>

<pre><code>    var credentials = new StorageCredentials("accountname", "accountkey");
    var account = new CloudStorageAccount(credentials, true);
    var client = account.CreateCloudBlobClient();
    var properties = client.GetServiceProperties();
    properties.DefaultServiceVersion = "2013-08-15";
    client.SetServiceProperties(properties);
    Console.WriteLine(properties.DefaultServiceVersion);
</code></pre>


		<p><a href="/2015/10/cdn-streaming-video-azure-storage/">Read more...</a></p>
	  </p>
    </div>
    <div class="post other link">
      <h2><span class="mega-octicon octicon-file-text" style="min-width: 32px;"></span><a href="/2015/10/deploy-classic-storage-azure-resource-manager/">Deploying a Azure Classic Storage Account using Azure Resource Manager</a></h2>
      <p class="post-date">10 Oct 2015

      | <a href="/category/azure" title="Azure">Azure</a>
      | <a href="/category/deployment" title="Deployment">Deployment</a>
      | <a href="/category/azure-storage-accounts" title="Azure Storage Accounts">Azure Storage Accounts</a>
</p>

      <p>
		
		<p>I've been working on Azure Resource Group templates quite a bit over the last few weeks. While it has been a pleasant experience overall, I ran into some hurdles the other day while attempting to figure out how to create a <code>Microsoft.ClassicStorage/StorageAccounts</code> using the Azure Resource Manager(ARM) API.</p>

<p>The latest version (2.7 at the time of writing) of Azure SDK GUI tools for visual studio were not particularly helpful in generating the required json, but thankfully <a href="http://stackoverflow.com/questions/27347200/add-storage-to-azure-resource-manager">this</a> post pointed me in the right direction. And after a little bit of fiddling I find that <code>2015-06-01</code> appears to be last supported <code>apiVersion</code> that works with classic storage.</p>

<p><a href="/images/posts/DeployClassicStorageArm/10_SupportedVersion.png"><img src="/images/posts/DeployClassicStorageArm/10_SupportedVersion.png" alt="Azure PowerShell Unsupported" /></a></p>

<p>Here's the final script I used to create a classic storage container: </p>

<pre><code>{
    "$schema": "https://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
    "contentVersion": "1.0.0.0",
    "parameters": {
        "PrimaryStorageName": {
            "type": "string"
        },
        "PrimaryStorageType": {
            "type": "string",
            "defaultValue": "Standard_LRS",
            "allowedValues": [
                "Standard_LRS",
                "Standard_GRS",
                "Standard_ZRS"
            ]
        },
        "PrimaryStorageLocation": {
        "type": "string",
        "defaultValue": "East US",
        "allowedValues": [
            "East US",
            "West US",
            "West Europe",
            "East Asia",
            "South East Asia"
            ]
        }
    },
    "variables": {
    },
    "resources": [
        {
            "name": "[parameters('PrimaryStorageName')]",
            "type": "Microsoft.ClassicStorage/StorageAccounts",
            "location": "[parameters('PrimaryStorageLocation')]",
            "apiVersion":  "2015-06-01",
            "dependsOn": [ ],
            "properties": {
                "accountType": "[parameters('PrimaryStorageType')]"
            }
        }
    ],
    "outputs": {
    }
}
</code></pre>


		<p><a href="/2015/10/deploy-classic-storage-azure-resource-manager/">Read more...</a></p>
	  </p>
    </div>
    <div class="post other link">
      <h2><span class="mega-octicon octicon-file-text" style="min-width: 32px;"></span><a href="/2015/08/publishing-assemblies-without-gacutil/">Publishing Assemblies into the GAC without GacUtil</a></h2>
      <p class="post-date">31 Aug 2015

      | <a href="/category/deployment" title="Deployment">Deployment</a>
</p>

      <p>
		
		<p>I constantly find myself googling this code snippet - its nice to keep handy: </p>

<pre><code>[System.Reflection.Assembly]::Load("System.EnterpriseServices, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b03f5f7f11d50a3a")
$publish = New-Object System.EnterpriseServices.Internal.Publish
$publish.GacInstall("c:\temp\publish_dll.dll")
</code></pre>


		<p><a href="/2015/08/publishing-assemblies-without-gacutil/">Read more...</a></p>
	  </p>
    </div>
    <div class="post other link">
      <h2><span class="mega-octicon octicon-file-text" style="min-width: 32px;"></span><a href="/2015/08/sharing-configuration-between-webjobs/">Sharing Configuration Between WebJobs</a></h2>
      <p class="post-date">29 Aug 2015

      | <a href="/category/azure" title="Azure">Azure</a>
</p>

      <p>
		
		<p>The project I am working on started out with the single webjob and has since grown to multiple jobs running in parallel. They are all hosted within a dedicated web app, which allows us to scale the jobs independent of the rest of the application. And because they share a single container there is the added side effect of the jobs sharing all the Application Settings and connection strings too.</p>

<p>While each webjob had its own class library, I didn't want to maintain multiple copies of  the <code>App.Config</code> file. I decided to share the the common bits (<code>AppSettings</code> and <code>ConnectionString</code> sections) in their own files:</p>

<ol>
<li><p>In one of the webjob projects, I moved the <code>AppSettings</code> and <code>ConnectionStrings</code> into their own <code>.config</code> files - <code>appSettings.config</code> and <code>connectionStrings.config</code> respectively.</p></li>
<li><p>Next, I referenced them back to the <code>App.config</code> using the <code>configSource</code> attribute.</p></li>
<li><p>Finally, I added the same files as linked files to the otherweb jobs and set their <code>Copy to Output Directory</code> file property to <code>Copy Always</code>.</p></li>
</ol>

<p>This works well enough, but for one caveat - which prompted me to write this post in the first place. The problem is that the <code>Web Deploy Package</code> publishing process does not appear to honor folder structures for the config files. That means that if you've separated the configuration into sub folders (like shown below), the publishing process would flatten it out.</p>


		<p><a href="/2015/08/sharing-configuration-between-webjobs/">Read more...</a></p>
	  </p>
    </div>
    <div class="post other link">
      <h2><span class="mega-octicon octicon-file-text" style="min-width: 32px;"></span><a href="/2015/08/enable-ssrs-remote-error-sharepoint-integrated/">Enable SSRS Remote Errors in SharePoint Integrated Mode</a></h2>
      <p class="post-date">28 Aug 2015

      | <a href="/category/sharepoint" title="SharePoint">SharePoint</a>
      | <a href="/category/sql-server-reporting-services" title="SQL Server Reporting Services">SQL Server Reporting Services</a>
</p>

      <p>
		
		<p>Any time I have to troubleshoot issues in SQL Server Reporting Services (SSRS) reports in a production environment, I usually end up enabling <code>Remote Errors</code> at some point as part my process. </p>

<p>Remote errors are enabled via the SSRS Service Application:</p>

<ol>
<li>Navigate to <code>Central Administration &gt; Application Management &gt; Manage Service Applications</code></li>
<li>Next, click on the appropriate  <code>SQL Server Reporting Services Service Application</code> service application to manage it. </li>
<li>Click <code>System Settings</code> from the toolbar.</li>
<li>Finally, enable remote errors by navigating into checking the <code>Enable Remote Errors</code> checkbox. </li>
</ol>


		<p><a href="/2015/08/enable-ssrs-remote-error-sharepoint-integrated/">Read more...</a></p>
	  </p>
    </div>
</div>

  <div id="post-pagination" class="pagination">


      <p class="previous">
        <a href="/page2">Previous Page</a>
        </p>


    <p class="previous">
      <a href="/page4">Next Page</a>
    </p>

  </div>

  </div>

  <!-- /.main -->

  <script type="text/javascript">
var _gaq = _gaq || [];

_gaq.push(['_setAccount', 'UA-57983893-1']);
_gaq.push(['_trackPageview']);
        
(function () {
    var ga = document.createElement('script');
    ga.type = 'text/javascript';
    ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(ga, s);
})();
</script>
</body>
</html>

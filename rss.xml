<rss xmlns:a10="http://www.w3.org/2005/Atom" version="2.0"><channel><title>nullfactory.net</title><link>http://nullfactory.net/rss.xml</link><description>nullfactory.net</description><item><guid isPermaLink="true">http://nullfactory.net/2015/06/entity-framework-multiple-context-namespace-collision/</guid><link>http://nullfactory.net/2015/06/entity-framework-multiple-context-namespace-collision/</link><title>Entity Framework Namespace Collisions When Working with Multiple Contexts</title><description>&lt;p&gt;I came across the following exception whilst attempting working with a solution that contained a &lt;em&gt;couple of&lt;/em&gt; Entity Framework (EF) 6 database contexts.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;System.Data.Entity.Core.MetadataException

Schema specified is not valid. Errors: 
The mapping of CLR type to EDM type is ambiguous because multiple CLR types match the EDM type 'Setting'. Previously found CLR type 'SqlHelper.Primary.Setting', newly found CLR type 'SqlHelper.Secondary.Setting'.

at System.Data.Entity.Core.Metadata.Edm.ObjectItemCollection.LoadAssemblyFromCache(Assembly assembly, Boolean loadReferencedAssemblies, EdmItemCollection edmItemCollection, Action`1 logLoadMessage)
at System.Data.Entity.Core.Metadata.Edm.ObjectItemCollection.ExplicitLoadFromAssembly(Assembly assembly, EdmItemCollection edmItemCollection, Action`1 logLoadMessage)
at System.Data.Entity.Core.Metadata.Edm.MetadataWorkspace.ExplicitLoadFromAssembly(Assembly assembly, ObjectItemCollection collection, Action`1 logLoadMessage)
at System.Data.Entity.Core.Metadata.Edm.MetadataWorkspace.LoadFromAssembly(Assembly assembly, Action`1 logLoadMessage)
at System.Data.Entity.Core.Metadata.Edm.MetadataWorkspace.LoadFromAssembly(Assembly assembly)
at System.Data.Entity.Internal.InternalContext.TryUpdateEntitySetMappingsForType(Type entityType)
at System.Data.Entity.Internal.InternalContext.UpdateEntitySetMappingsForType(Type entityType)
at System.Data.Entity.Internal.InternalContext.GetEntitySetAndBaseTypeForType(Type entityType)
at System.Data.Entity.Internal.Linq.InternalSet`1.Initialize()
at System.Data.Entity.Internal.Linq.InternalSet`1.get_InternalContext()
at System.Data.Entity.Internal.Linq.InternalSet`1.ActOnSet(Action action, EntityState newState, Object entity, String methodName)
at System.Data.Entity.Internal.Linq.InternalSet`1.Add(Object entity)
at System.Data.Entity.DbSet`1.Add(TEntity entity)
at MultiContextConsoleApp.Program.Main(String[] args) in e:\shane\Projects\Orca\Sandbox\MultiContextConsoleApp\MultiContextConsoleApp\Program.cs:line 16
at System.AppDomain._nExecuteAssembly(RuntimeAssembly assembly, String[] args)
at System.AppDomain.ExecuteAssembly(String assemblyFile, Evidence assemblySecurity, String[] args)
at Microsoft.VisualStudio.HostingProcess.HostProc.RunUsersAssembly()
at System.Threading.ThreadHelper.ThreadStart_Context(Object state)
at System.Threading.ExecutionContext.RunInternal(ExecutionContext executionContext, ContextCallback callback, Object state, Boolean preserveSyncCtx)
at System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Object state, Boolean preserveSyncCtx)
at System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Object state)
at System.Threading.ThreadHelper.ThreadStart()
&lt;/code&gt;&lt;/pre&gt;

</description><pubDate>Tue, 02 Jun 2015 18:30:00 Z</pubDate><a10:updated>2015-06-02T18:30:00Z</a10:updated><a10:content type="html">&lt;p&gt;I came across the following exception whilst attempting working with a solution that contained a &lt;em&gt;couple of&lt;/em&gt; Entity Framework (EF) 6 database contexts.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;System.Data.Entity.Core.MetadataException

Schema specified is not valid. Errors: 
The mapping of CLR type to EDM type is ambiguous because multiple CLR types match the EDM type 'Setting'. Previously found CLR type 'SqlHelper.Primary.Setting', newly found CLR type 'SqlHelper.Secondary.Setting'.

at System.Data.Entity.Core.Metadata.Edm.ObjectItemCollection.LoadAssemblyFromCache(Assembly assembly, Boolean loadReferencedAssemblies, EdmItemCollection edmItemCollection, Action`1 logLoadMessage)
at System.Data.Entity.Core.Metadata.Edm.ObjectItemCollection.ExplicitLoadFromAssembly(Assembly assembly, EdmItemCollection edmItemCollection, Action`1 logLoadMessage)
at System.Data.Entity.Core.Metadata.Edm.MetadataWorkspace.ExplicitLoadFromAssembly(Assembly assembly, ObjectItemCollection collection, Action`1 logLoadMessage)
at System.Data.Entity.Core.Metadata.Edm.MetadataWorkspace.LoadFromAssembly(Assembly assembly, Action`1 logLoadMessage)
at System.Data.Entity.Core.Metadata.Edm.MetadataWorkspace.LoadFromAssembly(Assembly assembly)
at System.Data.Entity.Internal.InternalContext.TryUpdateEntitySetMappingsForType(Type entityType)
at System.Data.Entity.Internal.InternalContext.UpdateEntitySetMappingsForType(Type entityType)
at System.Data.Entity.Internal.InternalContext.GetEntitySetAndBaseTypeForType(Type entityType)
at System.Data.Entity.Internal.Linq.InternalSet`1.Initialize()
at System.Data.Entity.Internal.Linq.InternalSet`1.get_InternalContext()
at System.Data.Entity.Internal.Linq.InternalSet`1.ActOnSet(Action action, EntityState newState, Object entity, String methodName)
at System.Data.Entity.Internal.Linq.InternalSet`1.Add(Object entity)
at System.Data.Entity.DbSet`1.Add(TEntity entity)
at MultiContextConsoleApp.Program.Main(String[] args) in e:\shane\Projects\Orca\Sandbox\MultiContextConsoleApp\MultiContextConsoleApp\Program.cs:line 16
at System.AppDomain._nExecuteAssembly(RuntimeAssembly assembly, String[] args)
at System.AppDomain.ExecuteAssembly(String assemblyFile, Evidence assemblySecurity, String[] args)
at Microsoft.VisualStudio.HostingProcess.HostProc.RunUsersAssembly()
at System.Threading.ThreadHelper.ThreadStart_Context(Object state)
at System.Threading.ExecutionContext.RunInternal(ExecutionContext executionContext, ContextCallback callback, Object state, Boolean preserveSyncCtx)
at System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Object state, Boolean preserveSyncCtx)
at System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Object state)
at System.Threading.ThreadHelper.ThreadStart()
&lt;/code&gt;&lt;/pre&gt;

&lt;!--excerpt--&gt;

&lt;h2&gt;Reproducing the Problem&lt;/h2&gt;

&lt;p&gt;Here's a quick run down of the steps required to reproduce the scenario:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Start off by creating two databases.&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Create a new table with the same name on each of them.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/EFNamespaceConflict/10_DatabaseSchema.png" alt="Database Schema" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Next, open up Visual Studio and create a Class Library project to host both EF database contexts.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Within the same project, create two EF (&lt;em&gt;ADO.NET Entity Data Model&lt;/em&gt;) contexts; one for each database. Ensure that each context is under its own namespace.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/EFNamespaceConflict/15_InitialProjectStructure.png" alt="Project Structure" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/EFNamespaceConflict/20_PrimaryContext.png" alt="Primary Context" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/EFNamespaceConflict/30_SecondaryContext.png" alt="Secondary Context" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/EFNamespaceConflict/40_PrimarySetting.png" alt="Primary Context Settings File" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/EFNamespaceConflict/50_SecondarySetting.png" alt="Secondary Context Settings File" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Next, let's create a simple console application that would act as the client and invoke operations on the contexts. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Run the application - an exception is thrown the moment there is any kind of interaction with either of the contexts. &lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/EFNamespaceConflict/60_Exception.png" alt="SSMS Context Menu" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2&gt;The Solution&lt;/h2&gt;

&lt;p&gt;This issue is only reproducible when working with multiple database contexts that have tables with the same name and share the same assembly. It does not even matter that the contexts are across different namespaces. &lt;/p&gt;

&lt;p&gt;The problem appears to be how Entity Framework resolves namespaces, &lt;a href="http://entityframework.codeplex.com/workitem/483"&gt;this ticket goes into more detail&lt;/a&gt;. I was able to reproduce this with the latest version of EF and a fix does not appear to be on the immediate schedule. &lt;/p&gt;

&lt;p&gt;Luckily there are couple of workarounds which are pretty straightforward:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Make sure that that both contexts don't share tables with the same name - &lt;em&gt;not the most practical approach&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Restructure the solution by isolating the database contexts within their own assemblies.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/EFNamespaceConflict/70_NewProjectStructure.png" alt="SSMS Context Menu" /&gt;   &lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="http://entityframework.codeplex.com/workitem/483"&gt;CodePlex - Entity Framework - View Issue #483: Can't map two classes with same name from different namespace&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/14927391/the-mapping-of-clr-type-to-edm-type-is-ambiguous-with-ef-6-5"&gt;StackOverflow.com - c# - The mapping of CLR type to EDM type is ambiguous with EF 6 &amp;amp; 5?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://social.msdn.microsoft.com/Forums/en-US/5a8ea003-c6bc-4fc6-ad2a-634f09447c49/ef4-mapping-of-clr-type-to-edm-type-is-ambiguous-error?forum=adodotnetentityframework"&gt;MSDN Forum - EF4 Mapping of CLR type to EDM type is ambiguous error.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</a10:content></item><item><guid isPermaLink="true">http://nullfactory.net/2015/06/generate-clean-up-script-drop-objects-sql-database/</guid><link>http://nullfactory.net/2015/06/generate-clean-up-script-drop-objects-sql-database/</link><title>Generate a Clean Up Script to Drop All Objects in a SQL Server Database</title><description>&lt;p&gt;I needed a quick and reusable way to drop all SQL server objects from an Azure database. The objective was to have some kind of process to clean up and prep the database before the main deployment is kicked off. And given that I am particularly biased towards using a sql script my search for a solution focused around it.&lt;/p&gt;

&lt;p&gt;In addition to actually dropping the artifacts, the script should be aware of the order in which it should do it - that is to drop the most dependent objects first and work its way towards the least dependent ones. And my nice-to-have feature is to be able to parameterize the schema name so that it could be used with a multi-tenant database schema.&lt;/p&gt;

&lt;p&gt;I saw a few possible solutions and finally settled on using the &lt;a href="http://stackoverflow.com/questions/536350/drop-all-the-tables-stored-procedures-triggers-constraints-and-all-the-depend"&gt;out-of-the-box feature&lt;/a&gt; that's already available through SQL Server Management Studio (SSMS).&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Open up SQL Server Management Studio.&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Select &lt;code&gt;Task  &amp;gt; Generate Script...&lt;/code&gt; on on your the database context menu. This would open up the &lt;code&gt;Generate and Publish Scripts&lt;/code&gt; dialog.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/GenerateDropScript/10_ContextMenu.png" alt="SSMS Context Menu" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;First, navigate to the &lt;code&gt;Choose Objects&lt;/code&gt; tab and select all the objects that need to be dropped.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Next, on the &lt;code&gt;Set Scripting Options&lt;/code&gt; tab, select the preferred output location.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/GenerateDropScript/20_SetScriptingOptions.png" alt="Set Scripting Options" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Next, click the &lt;code&gt;Advanced&lt;/code&gt; button which result in the &lt;code&gt;Advanced Scripting Options&lt;/code&gt; dialog.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/GenerateDropScript/30_AdvancedScriptingOptions.png" alt="Advanced Scripting Options" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Navigate down towards to and change the &lt;code&gt;General &amp;gt; Script DROP and CREATE&lt;/code&gt; option to &lt;code&gt;Script DROP&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;Set the default values for the rest of the steps and finally click the &lt;code&gt;Finish&lt;/code&gt; button.&lt;/li&gt;
&lt;/ol&gt;

</description><pubDate>Mon, 01 Jun 2015 18:30:00 Z</pubDate><a10:updated>2015-06-01T18:30:00Z</a10:updated><a10:content type="html">&lt;p&gt;I needed a quick and reusable way to drop all SQL server objects from an Azure database. The objective was to have some kind of process to clean up and prep the database before the main deployment is kicked off. And given that I am particularly biased towards using a sql script my search for a solution focused around it.&lt;/p&gt;

&lt;p&gt;In addition to actually dropping the artifacts, the script should be aware of the order in which it should do it - that is to drop the most dependent objects first and work its way towards the least dependent ones. And my nice-to-have feature is to be able to parameterize the schema name so that it could be used with a multi-tenant database schema.&lt;/p&gt;

&lt;p&gt;I saw a few possible solutions and finally settled on using the &lt;a href="http://stackoverflow.com/questions/536350/drop-all-the-tables-stored-procedures-triggers-constraints-and-all-the-depend"&gt;out-of-the-box feature&lt;/a&gt; that's already available through SQL Server Management Studio (SSMS).&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Open up SQL Server Management Studio.&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Select &lt;code&gt;Task  &amp;gt; Generate Script...&lt;/code&gt; on on your the database context menu. This would open up the &lt;code&gt;Generate and Publish Scripts&lt;/code&gt; dialog.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/GenerateDropScript/10_ContextMenu.png" alt="SSMS Context Menu" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;First, navigate to the &lt;code&gt;Choose Objects&lt;/code&gt; tab and select all the objects that need to be dropped.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Next, on the &lt;code&gt;Set Scripting Options&lt;/code&gt; tab, select the preferred output location.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/GenerateDropScript/20_SetScriptingOptions.png" alt="Set Scripting Options" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Next, click the &lt;code&gt;Advanced&lt;/code&gt; button which result in the &lt;code&gt;Advanced Scripting Options&lt;/code&gt; dialog.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/GenerateDropScript/30_AdvancedScriptingOptions.png" alt="Advanced Scripting Options" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Navigate down towards to and change the &lt;code&gt;General &amp;gt; Script DROP and CREATE&lt;/code&gt; option to &lt;code&gt;Script DROP&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;Set the default values for the rest of the steps and finally click the &lt;code&gt;Finish&lt;/code&gt; button.&lt;/li&gt;
&lt;/ol&gt;

&lt;!--excerpt--&gt;

&lt;p&gt;SSMS sorts out the dependencies and generates a script similar to the one below. Note that the statements are in the required sequence.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;USE [test]
GO
ALTER TABLE [dbo].[Contact] DROP CONSTRAINT [FK_Contact_Company]
GO
/****** Object:  Table [dbo].[Contact]Script Date: 6/2/2015 9:33:36 AM ******/
DROP TABLE [dbo].[Contact]
GO
/****** Object:  Table [dbo].[Company]Script Date: 6/2/2015 9:33:36 AM ******/
DROP TABLE [dbo].[Company]
GO
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I finally made the following tweaks to convert the script to a &lt;code&gt;SQLCMD&lt;/code&gt; script and parameterize the schema:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;:setvar TenantSchemaName "scm"

ALTER TABLE [$(TenantSchemaName)].[Contact] DROP CONSTRAINT [FK_Contact_Company]
GO
/****** Object:  Table [$(TenantSchemaName)].[Contact]    Script Date: 6/2/2015 9:33:36 AM ******/
DROP TABLE [$(TenantSchemaName)].[Contact]
GO
/****** Object:  Table [$(TenantSchemaName)].[Company]    Script Date: 6/2/2015 9:33:36 AM ******/
DROP TABLE [$(TenantSchemaName)].[Company]
GO
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Although, I was not really focused on automation, it should not be too difficult to integrate it with existing automated processes.&lt;/p&gt;

&lt;h2&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/536350/drop-all-the-tables-stored-procedures-triggers-constraints-and-all-the-depend"&gt;StackOverflow.com - sql server - Drop all the tables, stored procedures, triggers, constraints and all the dependencies in one sql statement - Stack Overflow&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</a10:content></item><item><guid isPermaLink="true">http://nullfactory.net/2015/05/recording-diagnostics-azure-app-service-website-log4net/</guid><link>http://nullfactory.net/2015/05/recording-diagnostics-azure-app-service-website-log4net/</link><title>Recording Diagnostics on a Azure App Service Hosted Website using Log4Net</title><description>&lt;p&gt;I've been working on moving an existing web based software solution into the Azure cloud ecosystem. The solution is tightly integrated with and uses Log4Net as it logging framework. My primary goal, in terms of logging, was to keep as much of my original architecture intact and at the same time make maximum use of the diagnostics infrastructure that is available in Azure.&lt;/p&gt;

&lt;p&gt;The &lt;a href="http://azure.microsoft.com/en-in/documentation/articles/web-sites-enable-diagnostic-log/"&gt;official documentation states&lt;/a&gt; that calls to the &lt;code&gt;System.Diagnostics.Trace&lt;/code&gt; methods are all that is required to start capturing diagnostic information. In summary, this is all I needed to do:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Enable diagnostics and configure the storage locations (discussed later down the post).&lt;/li&gt;
&lt;li&gt;From within my code write the &lt;code&gt;Warning&lt;/code&gt;, &lt;code&gt;Error&lt;/code&gt; and &lt;code&gt;Information&lt;/code&gt; messages via their respective trace methods.&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;li&gt;Azure starts capturing the custom diagnostics information - PROFIT! &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Sounds simple enough. &lt;/p&gt;

&lt;p&gt;So I thought if I just set up a &lt;code&gt;TraceAppender&lt;/code&gt; everything would work fine and that would be the end of it. The results were not what I was expecting and this was the output in my table storage:&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/AzureAppSvcDiag/10_AppServiceTableDiag.png" alt="Table Diagnostics" /&gt;&lt;/p&gt;

&lt;p&gt;The trace entries are bunched together as a single &lt;code&gt;Verbose&lt;/code&gt; entry and the writes appear to be buffered. Not acceptable. I suppose the buffering could be because I had not used the &lt;code&gt;ImmediateFlush&lt;/code&gt; option for the &lt;code&gt;TraceAppender&lt;/code&gt;, but I need to have each Trace statement to have its own entry in the table.&lt;/p&gt;

&lt;p&gt;While there are a lot of posts on the internet on how to setup Log4Net with Azure, most of them appear to be out of date and seem to be compensating for features were not available in the Azure at the time of their implementation. Then there are others that targeted towards integrating with the Cloud Service which is not what I was looking for.&lt;/p&gt;

</description><pubDate>Sat, 23 May 2015 18:30:00 Z</pubDate><a10:updated>2015-05-23T18:30:00Z</a10:updated><a10:content type="html">&lt;p&gt;I've been working on moving an existing web based software solution into the Azure cloud ecosystem. The solution is tightly integrated with and uses Log4Net as it logging framework. My primary goal, in terms of logging, was to keep as much of my original architecture intact and at the same time make maximum use of the diagnostics infrastructure that is available in Azure.&lt;/p&gt;

&lt;p&gt;The &lt;a href="http://azure.microsoft.com/en-in/documentation/articles/web-sites-enable-diagnostic-log/"&gt;official documentation states&lt;/a&gt; that calls to the &lt;code&gt;System.Diagnostics.Trace&lt;/code&gt; methods are all that is required to start capturing diagnostic information. In summary, this is all I needed to do:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Enable diagnostics and configure the storage locations (discussed later down the post).&lt;/li&gt;
&lt;li&gt;From within my code write the &lt;code&gt;Warning&lt;/code&gt;, &lt;code&gt;Error&lt;/code&gt; and &lt;code&gt;Information&lt;/code&gt; messages via their respective trace methods.&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;li&gt;Azure starts capturing the custom diagnostics information - PROFIT! &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Sounds simple enough. &lt;/p&gt;

&lt;p&gt;So I thought if I just set up a &lt;code&gt;TraceAppender&lt;/code&gt; everything would work fine and that would be the end of it. The results were not what I was expecting and this was the output in my table storage:&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/AzureAppSvcDiag/10_AppServiceTableDiag.png" alt="Table Diagnostics" /&gt;&lt;/p&gt;

&lt;p&gt;The trace entries are bunched together as a single &lt;code&gt;Verbose&lt;/code&gt; entry and the writes appear to be buffered. Not acceptable. I suppose the buffering could be because I had not used the &lt;code&gt;ImmediateFlush&lt;/code&gt; option for the &lt;code&gt;TraceAppender&lt;/code&gt;, but I need to have each Trace statement to have its own entry in the table.&lt;/p&gt;

&lt;p&gt;While there are a lot of posts on the internet on how to setup Log4Net with Azure, most of them appear to be out of date and seem to be compensating for features were not available in the Azure at the time of their implementation. Then there are others that targeted towards integrating with the Cloud Service which is not what I was looking for.&lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;p&gt;Unable to find any existing implementation, I decided to roll my own appender. I started off by &lt;a href="https://github.com/apache/log4net/blob/trunk/src/log4net/Appender/TraceAppender.cs"&gt;looking at the TraceAppender code&lt;/a&gt; and observed that it just does a &lt;code&gt;Trace.Write&lt;/code&gt;, which I suppose is why Azure categorizes the entries under the &lt;code&gt;Verbose&lt;/code&gt; level. So my implementation would be identical but would make explicit calls to the &lt;code&gt;Trace.TraceWarning&lt;/code&gt;, &lt;code&gt;Trace.TraceError&lt;/code&gt; and &lt;code&gt;Trace.TraceInformation&lt;/code&gt; methods as necessary.&lt;/p&gt;

&lt;p&gt;Its quite simple really, this is the gist of it:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;protected override void Append(LoggingEvent loggingEvent)
{
    string logMessage = string.Format(this.RenderLoggingEvent(loggingEvent), ((LayoutSkeleton)this.category).Format(loggingEvent));

    if (loggingEvent.Level == Level.Alert ||
        loggingEvent.Level == Level.Critical ||
        loggingEvent.Level == Level.Emergency ||
        loggingEvent.Level == Level.Error ||
        loggingEvent.Level == Level.Fatal ||
        loggingEvent.Level == Level.Log4Net_Debug ||
        loggingEvent.Level == Level.Severe)
    {
        Trace.TraceError(logMessage);
    }
    else if (loggingEvent.Level == Level.Warn)
    {
        Trace.TraceWarning(logMessage);
    }
    else if (loggingEvent.Level == Level.Debug ||
        loggingEvent.Level == Level.Fine ||
        loggingEvent.Level == Level.Finer ||
        loggingEvent.Level == Level.Finest ||
        loggingEvent.Level == Level.Info ||
        loggingEvent.Level == Level.Notice ||
        loggingEvent.Level == Level.Trace ||
        loggingEvent.Level == Level.Verbose)
    {
        Trace.TraceInformation(logMessage);
    }

    if (!this.ImmediateFlush)
    {
        return;
    }

    Trace.Flush();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Configure the appender the same as you would the &lt;code&gt;TraceAppender&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;appender name="SimpleTraceAppender" type="Nullfactory.Log4Net.SimpleTraceAppender, Nullfactory.Log4Net"&amp;gt;
    &amp;lt;layout type="log4net.Layout.PatternLayout"&amp;gt;
        &amp;lt;conversionPattern value="%date [%thread] %-5level %logger [%property{NDC}] - %message%newline" /&amp;gt;
    &amp;lt;/layout&amp;gt;
&amp;lt;/appender&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And finally for the webjob contained in my solution, I paired my custom appender with a &lt;code&gt;ConsoleAppender&lt;/code&gt; so that it would automatically take advantage of the web job logging architecture without any additional code.&lt;/p&gt;

&lt;p&gt;I've uploaded my &lt;a href="https://github.com/shanec-/Nullfactory-Azure"&gt;full implementation and sample usage here&lt;/a&gt;.&lt;/p&gt;

&lt;h2&gt;Enabling Diagnostics on the Azure Portal&lt;/h2&gt;

&lt;p&gt;There are couple of steps that need to be done in order to enable diagnostics on the app service:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Login to the older Azure portal - &lt;a href="https://manage.windowsazure.net"&gt;https://manage.windowsazure.net&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Ensure that you already have a storage account set up. This would house the table that stores the diagnostic entries. &lt;/li&gt;
&lt;li&gt;&lt;p&gt;Next, navigate to the web app configuration page. &lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/AzureAppSvcDiag/20_WebAppDiagConfig.png" alt="Web App Configure" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Enable application logging (table storage)
and select a logging level.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/AzureAppSvcDiag/30_DiagTableStorage.png" alt="Web App, Application Diagnostics" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Next click on the &lt;code&gt;manage table storage&lt;/code&gt; button allows to configure the storage account and the table into which the diagnostic information is recorded into.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/AzureAppSvcDiag/40_DiagTableStorage2.png" alt="Web App Application Diagnostics Table Name" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;That's it, the web app should start capturing logging information. &lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;There were a few quirks that I faced attempting to set it up:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;This how-to provides the following instructions on &lt;a href="http://azure.microsoft.com/en-us/documentation/articles/web-sites-enable-diagnostic-log/"&gt;enabling diagnostics&lt;/a&gt;:  &lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;When enabling Application Logging you must also select the Logging Level and whether to enable logging to the file system, table storage, or blob storage. While all three storage locations provide the same basic information for logged events, table storage and blob storage log additional information such as the instance ID, thread ID, and a more granular timestamp (tick format) than logging to file system.&lt;/p&gt;
  
  &lt;p&gt;When enabling site diagnostics, you must select storage or file system for web server logging. Selecting storage allows you to select a storage account, and then a blob container that the logs will be written to. All other logs for site diagnostics are written to the file system only.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;At the time of writing this post the preview portal does not appear to have the diagnostics feature fully ported. While it does have the switch to enable it, it does not provide the options to select the storage location. That's why it is required to be enabled via the &lt;a href="https://manage.windowsazure.com/"&gt;older portal&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/AzureAppSvcDiag/60_PreviewAppDiagLogs.png" alt="Preview Portal, Web App Logging" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The newer (v2) storage accounts do not seem to be recognized by the older portal. So if you already using them via the preview portal, you would need to create a second set of storage accounts just for the diagnostics. Again, this is something I think this would be sorted out in future releases  &lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/AzureAppSvcDiag/50_StorAccV2Diag.png" alt="Web App, Diagnostics Storage Account V2 Missing" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/apache/log4net/blob/trunk/src/log4net/Appender/TraceAppender.cs"&gt;log4net/TraceAppender.cs at trunk · apache/log4net · GitHub&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://azure.microsoft.com/en-in/documentation/articles/web-sites-enable-diagnostic-log/"&gt;Enable diagnostics logging for web apps in Azure App Service&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.tylerdoerksen.com/2012/04/15/logging-in-azure-part-1/"&gt;Logging in Azure: Part 1 | Tyler's Azure Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.tylerdoerksen.com/2012/04/17/logging-in-azure-part-2table-storage/"&gt;Logging in Azure: Part 2–Table Storage | Tyler's Azure Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://zacg.github.io/blog/2014/02/05/azure-log4net-appender/"&gt;Azure Log4Net Appender - Zac Gross&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.kloud.com.au/2014/10/22/logging-with-log4net-and-azure-diagnostics-on-web-and-worker-roles/"&gt;Logging with log4net and Azure Diagnostics on Web and Worker Roles | Kloud Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://cloudshaper.wordpress.com/2010/10/30/logging-with-log4net-on-the-azure-platform/"&gt;Logging with Log4Net on the Azure platform | Cloud Shaper&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</a10:content></item><item><guid isPermaLink="true">http://nullfactory.net/2015/05/start-azure-webjobs-on-demand/</guid><link>http://nullfactory.net/2015/05/start-azure-webjobs-on-demand/</link><title>Start Azure Web Jobs On Demand</title><description>&lt;p&gt;I've been working on an Azure based solution recently and have been using the free tiers to quickly get the solution up and running and to perform the first few QA cycles. The core solution is based around single app service website and then a second website that acts as the host for a continuous web job which is triggered via a queue.
The problem with the free tiers is that there's a high possibility that the web job would shut itself down and hibernate if it is &lt;a href="http://azure.microsoft.com/en-us/documentation/articles/web-sites-create-web-jobs/"&gt;idle for more that 20 mins&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;As of March 2014, web apps in Free mode can time out after 20 minutes if there are no requests to the scm (deployment) site and the web app's portal is not open in Azure. Requests to the actual site will not reset this.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;A little research shows a few possible solutions:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;If the job is not time sensitive, then manually start the service remotely using a script or tool. &lt;/li&gt;
&lt;li&gt;Make your code explicitly start the web job just as a new request is being enqueued. This can be done by &lt;a href="https://github.com/projectkudu/kudu/wiki/WebJobs-API"&gt;making a REST call&lt;/a&gt; to the deployment site.&lt;/li&gt;
&lt;li&gt;And lastly, upgrade to a basic or standard tier and enabling "Always On" keeps the site (and jobs) "warm" and prevent them from hibernating.&lt;/li&gt;
&lt;/ol&gt;

</description><pubDate>Sun, 17 May 2015 18:30:00 Z</pubDate><a10:updated>2015-05-17T18:30:00Z</a10:updated><a10:content type="html">&lt;p&gt;I've been working on an Azure based solution recently and have been using the free tiers to quickly get the solution up and running and to perform the first few QA cycles. The core solution is based around single app service website and then a second website that acts as the host for a continuous web job which is triggered via a queue.
The problem with the free tiers is that there's a high possibility that the web job would shut itself down and hibernate if it is &lt;a href="http://azure.microsoft.com/en-us/documentation/articles/web-sites-create-web-jobs/"&gt;idle for more that 20 mins&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;As of March 2014, web apps in Free mode can time out after 20 minutes if there are no requests to the scm (deployment) site and the web app's portal is not open in Azure. Requests to the actual site will not reset this.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;A little research shows a few possible solutions:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;If the job is not time sensitive, then manually start the service remotely using a script or tool. &lt;/li&gt;
&lt;li&gt;Make your code explicitly start the web job just as a new request is being enqueued. This can be done by &lt;a href="https://github.com/projectkudu/kudu/wiki/WebJobs-API"&gt;making a REST call&lt;/a&gt; to the deployment site.&lt;/li&gt;
&lt;li&gt;And lastly, upgrade to a basic or standard tier and enabling "Always On" keeps the site (and jobs) "warm" and prevent them from hibernating.&lt;/li&gt;
&lt;/ol&gt;

&lt;!--excerpt--&gt;

&lt;h3&gt;Using Powershell&lt;/h3&gt;

&lt;p&gt;This method requires the &lt;code&gt;Microsoft Azure Powershell&lt;/code&gt; module to be installed on the machine. This can be &lt;a href="http://azure.microsoft.com/en-us/documentation/articles/powershell-install-configure/"&gt;installed via the Web Platform Installer&lt;/a&gt;.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Start of by logging into the Azure account and registering your subscription &lt;/p&gt;

&lt;p&gt;&lt;code&gt;Add-AzureAccount&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Next, starts the job: &lt;/p&gt;

&lt;p&gt;&lt;code&gt;start-azurewebsitejob -name samplejobweb -jobname sample-execution-job -jobtype continuous&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;And this command to stop the job: &lt;/p&gt;

&lt;p&gt;&lt;code&gt;stop-azurewebsitejob -name samplejobweb -jobname sample-execution-job&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3&gt;Using REST / Code&lt;/h3&gt;

&lt;p&gt;I &lt;a href="http://stackoverflow.com/questions/28904186/how-can-i-keep-my-azure-webjob-running-without-always-on/28923039#28923039"&gt;used this code as a template&lt;/a&gt;  to whip up a console application that can be used to start the service:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;static void Main(string[] args)
{
    string websiteName = "&amp;lt;website name&amp;gt;";
    string webjobName = "&amp;lt;job name&amp;gt;";
    string userName = "&amp;lt;publishing username&amp;gt;";
    string userPWD = "&amp;lt;publishing password&amp;gt;";
    string webjobUrl = string.Format("https://{0}.scm.azurewebsites.net/api/continuouswebjobs/{1}", websiteName, webjobName);

    var result = GetWebjobState(webjobUrl, userName, userPWD);
    Console.WriteLine(result);

    var postResult = StartWebjob(webjobUrl + "/Start", userName, userPWD);
    Console.WriteLine(postResult);

    Console.ReadKey(true);
}

private static JObject GetWebjobState(string url, string username, string password)
{
    var client = CreateHttpClient(username, password);
    var data = client.GetStringAsync(url).Result;
    var result = JsonConvert.DeserializeObject(data) as JObject;
    return result;
}

private static bool StartWebjob(string url, string username, string password)
{
    var client = CreateHttpClient(username, password);
    HttpResponseMessage data = client.PostAsync(url, new StringContent(string.Empty)).Result;
    return data.StatusCode == System.Net.HttpStatusCode.OK;
}

private static HttpClient CreateHttpClient(string username, string password)
{
    HttpClient client = new HttpClient();
    string auth = "Basic " + Convert.ToBase64String(Encoding.UTF8.GetBytes(username + ':' + password));
    client.DefaultRequestHeaders.Add("authorization", auth);
    client.DefaultRequestHeaders.Accept.Add(new MediaTypeWithQualityHeaderValue("application/json"));
    return client;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="http://azure.microsoft.com/en-us/documentation/articles/web-sites-create-web-jobs/"&gt;Run Background tasks with WebJobs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/28904186/how-can-i-keep-my-azure-webjob-running-without-always-on/28923039#28923039"&gt;How can I keep my Azure WebJob running without "Always On" - Stack Overflow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/28502696/continuous-webjob-stops-automatically"&gt;azure - continuous WebJob stops automatically - Stack Overflow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/projectkudu/kudu/wiki/WebJobs-API"&gt;Github  - WebJobs API · projectkudu/kudu Wiki&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/projectkudu/kudu/wiki/Deployment-credentials"&gt;Github - Deployment credentials · projectkudu/kudu Wiki&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Azure/azure-powershell"&gt;Github - Azure/azure-powershell&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://azure.microsoft.com/en-us/documentation/articles/powershell-install-configure/"&gt;MSDN - How to install and configure Azure PowerShell&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://msdn.microsoft.com/library/azure/jj554330.aspx"&gt;MSDN - Azure Cmdlet Reference&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</a10:content></item><item><guid isPermaLink="true">http://nullfactory.net/2015/05/ssdt-deployment-plan-modifer/</guid><link>http://nullfactory.net/2015/05/ssdt-deployment-plan-modifer/</link><title>Parameterize Schema Name within a SSDT Database Project for Multi-Tenant Solutions</title><description>&lt;p&gt;I've been working on an multi-tenant solution recently and have been trying to come up with an efficient way to manage the database deployment and upgrade. The database is designed to segregate each tenant's data under its own schema namespace as such I need to generate a re-useable script that can be deployed against each tenant. The approach I am going to take is to first source control the database schema within a SQL Server Data Tools (SSDT) database project and then use it to generate the script that can be parameterized with the tenant information.&lt;/p&gt;

&lt;p&gt;I first parameterized the the schema name as a SQLCMD variable - &lt;code&gt;$TenantName&lt;/code&gt;: &lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/DeploymentPlanModifer/10_varcmd.png" alt="SqlCmd Variable" /&gt;&lt;/p&gt;

&lt;p&gt;Next I tried to replace the schema name with the new variable, but this did not work as trying to build the solution now returns with a 71502 error as the project is no longer able to resolve and validate schema objects.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/DeploymentPlanModifer/20_SchemaValidation.png" alt="Schema Validation" /&gt;&lt;/p&gt;

&lt;p&gt;SQLCMD does not have any complaints if I replace the &lt;code&gt;[dbo].&lt;/code&gt; with &lt;code&gt;[$TenantName]&lt;/code&gt; in the generated script so its the SSDT project that is attempting to maintain the integrity of database. &lt;/p&gt;

&lt;p&gt;One possible way to overcome this is to &lt;a href="http://stackoverflow.com/questions/10826014/suppress-some-warnings-in-sql-server-ssdt"&gt;suppress the 71502&lt;/a&gt; by turning them into &lt;a href="https://social.msdn.microsoft.com/Forums/sqlserver/en-US/9b698de1-9f6d-4e51-8c73-93c57355e768/treat-specific-warning-as-error?forum=ssdt"&gt;warnings&lt;/a&gt;. The disadvantage in this approach is that you loose the rich validation in exchange for something that is essentially a deployment convenience.&lt;/p&gt;

&lt;p&gt;Another duct tape and bubble gum approach would be to just have some kind of post deployment operation that does a find and replace on the schema name. Sure it would work, but that's not going to be reliable in the long run. &lt;/p&gt;

&lt;p&gt;A little bit of research reveals that the proper way to alter the creation of deployment script process is to create a deployment plan modifier. A deployment plan modifier is essentially a class that inherits &lt;code&gt;DeploymentPlanModifier&lt;/code&gt; and allows you to inject custom actions when deploying a SQL project. There does not seem to be much formal documentation on the process, so I relied a lot on &lt;a href="https://msdn.microsoft.com/en-US/library/dn306642(v=vs.103).aspx"&gt;this article in MSDN&lt;/a&gt;, the sample &lt;a href="https://github.com/Microsoft/DACExtensions"&gt;DACExtensions&lt;/a&gt; and what forum posts I could find. So with a lot of trial and error I wrote my own plan modifier that would replace the schema identifiers when the database project is published.&lt;/p&gt;

</description><pubDate>Fri, 08 May 2015 18:30:00 Z</pubDate><a10:updated>2015-05-08T18:30:00Z</a10:updated><a10:content type="html">&lt;p&gt;I've been working on an multi-tenant solution recently and have been trying to come up with an efficient way to manage the database deployment and upgrade. The database is designed to segregate each tenant's data under its own schema namespace as such I need to generate a re-useable script that can be deployed against each tenant. The approach I am going to take is to first source control the database schema within a SQL Server Data Tools (SSDT) database project and then use it to generate the script that can be parameterized with the tenant information.&lt;/p&gt;

&lt;p&gt;I first parameterized the the schema name as a SQLCMD variable - &lt;code&gt;$TenantName&lt;/code&gt;: &lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/DeploymentPlanModifer/10_varcmd.png" alt="SqlCmd Variable" /&gt;&lt;/p&gt;

&lt;p&gt;Next I tried to replace the schema name with the new variable, but this did not work as trying to build the solution now returns with a 71502 error as the project is no longer able to resolve and validate schema objects.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/DeploymentPlanModifer/20_SchemaValidation.png" alt="Schema Validation" /&gt;&lt;/p&gt;

&lt;p&gt;SQLCMD does not have any complaints if I replace the &lt;code&gt;[dbo].&lt;/code&gt; with &lt;code&gt;[$TenantName]&lt;/code&gt; in the generated script so its the SSDT project that is attempting to maintain the integrity of database. &lt;/p&gt;

&lt;p&gt;One possible way to overcome this is to &lt;a href="http://stackoverflow.com/questions/10826014/suppress-some-warnings-in-sql-server-ssdt"&gt;suppress the 71502&lt;/a&gt; by turning them into &lt;a href="https://social.msdn.microsoft.com/Forums/sqlserver/en-US/9b698de1-9f6d-4e51-8c73-93c57355e768/treat-specific-warning-as-error?forum=ssdt"&gt;warnings&lt;/a&gt;. The disadvantage in this approach is that you loose the rich validation in exchange for something that is essentially a deployment convenience.&lt;/p&gt;

&lt;p&gt;Another duct tape and bubble gum approach would be to just have some kind of post deployment operation that does a find and replace on the schema name. Sure it would work, but that's not going to be reliable in the long run. &lt;/p&gt;

&lt;p&gt;A little bit of research reveals that the proper way to alter the creation of deployment script process is to create a deployment plan modifier. A deployment plan modifier is essentially a class that inherits &lt;code&gt;DeploymentPlanModifier&lt;/code&gt; and allows you to inject custom actions when deploying a SQL project. There does not seem to be much formal documentation on the process, so I relied a lot on &lt;a href="https://msdn.microsoft.com/en-US/library/dn306642(v=vs.103).aspx"&gt;this article in MSDN&lt;/a&gt;, the sample &lt;a href="https://github.com/Microsoft/DACExtensions"&gt;DACExtensions&lt;/a&gt; and what forum posts I could find. So with a lot of trial and error I wrote my own plan modifier that would replace the schema identifiers when the database project is published.&lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;h2&gt;How it works&lt;/h2&gt;

&lt;p&gt;There are two main components to the solution; first one is the &lt;code&gt;SchemaSubstituteScriptContributor&lt;/code&gt; that is based off of &lt;code&gt;DeploymentPlanModifier&lt;/code&gt; that hosts and coordinates the injection process. And the other is &lt;code&gt;OverrideSchemaVisitor&lt;/code&gt; which is based off of &lt;code&gt;TSqlFragmentVisitor&lt;/code&gt; and does the actual schema substitution.&lt;/p&gt;

&lt;p&gt;On the &lt;code&gt;SchemaSubstituteScriptContributor&lt;/code&gt; class, I've overridden the &lt;code&gt;OnExecute&lt;/code&gt; method to look for steps of type &lt;code&gt;DeploymentScriptDomStep&lt;/code&gt; and once it find it, navigate down the class hierarchy until it reaches the actual &lt;code&gt;TSqlStatement&lt;/code&gt;. And into this &lt;code&gt;TSqlStatement&lt;/code&gt; I pass in a new instance of &lt;code&gt;OverrideSchemaVisitor&lt;/code&gt; via the &lt;code&gt;Accept&lt;/code&gt; method.&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;OverrideSchemaVisitor&lt;/code&gt; has overridden methods to handle each type of statement that have schema references and need to be altered.&lt;/p&gt;

&lt;h2&gt;Installation and Usage&lt;/h2&gt;

&lt;p&gt;Visual Studio loads up any extensions that are available in the extensions folder every time it starts up. 
Now copy the assembly to the extensions folder that Visual Studio checks when it starts-up. I had some trouble locating as it was not in the location that the article mentioned (see &lt;em&gt;troubleshooting&lt;/em&gt;). Eventually I found out that mine was located at &lt;code&gt;%ProgramFiles(x86)%\Microsoft Visual Studio 12.0\Common7\IDE\Extensions\Microsoft\SQLDB\DAC\120\Extensions&lt;/code&gt;. &lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/DeploymentPlanModifer/30_ExtensionsFolder.png" alt="Extensions Folder" /&gt;&lt;/p&gt;

&lt;p&gt;Next, in order for the database project to make use of the new extensions, I add the following properties to the database project &lt;code&gt;SqlProj&lt;/code&gt; file:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  &amp;lt;PropertyGroup&amp;gt;
    &amp;lt;DeploymentContributors&amp;gt;    
      $(DeploymentContributors);Nullfactory.SchemaSubstitute
    &amp;lt;/DeploymentContributors&amp;gt;
    &amp;lt;ContributorArguments Condition="'$(Configuration)' == 'Debug'"&amp;gt;
      $(ContributorArguments);Nullfactory.SchemaSubstitute.OldSchemaName=dbo;Nullfactory.SchemaSubstitute.NewSchemaName=$TenantSchema;
    &amp;lt;/ContributorArguments&amp;gt;
  &amp;lt;/PropertyGroup&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The parameters for the extension are passed via the &lt;code&gt;&amp;lt;ContributorArguments&amp;gt;&lt;/code&gt; tag in a key-value pair format; where &lt;code&gt;Nullfactory.SchemaSubstitute.OldSchemaName&lt;/code&gt; is the source schema name and &lt;code&gt;Nullfactory.SchemaSubstitute.NewSchemaName&lt;/code&gt; is the new schema name. &lt;/p&gt;

&lt;p&gt;Now that everything is setup, anytime the project is published the schema name would be substituted appropriately. &lt;/p&gt;

&lt;h2&gt;Troubleshooting&lt;/h2&gt;

&lt;p&gt;My first problem was trying to figure out where to deploy the extensions. Although the source article stated that it should be in the &lt;code&gt;%Program Files%\Microsoft SQL Server\110\DAC\Bin\Extensions&lt;/code&gt; folder, Visual Studio refused to recognize it.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/DeploymentPlanModifer/40_UnableToLoadExtension.png" alt="Unable to Load Extensions" /&gt;&lt;/p&gt;

&lt;p&gt;Digging through the forums, I found out that the locations in which visual studio checks for extensions depends on how it was installed. The multiple locations are there in &lt;a href="https://social.msdn.microsoft.com/Forums/sqlserver/en-US/be484b63-a6cc-4dac-a2c2-78a56ff5b502/where-is-the-microsoftsqlserverdacdll-that-includes-support-for-sql-server-2014?forum=ssdt"&gt;order to avoid conflicts and maintain backward compatibility&lt;/a&gt;. Luckily, I found another post that shows how to &lt;a href="https://social.msdn.microsoft.com/Forums/en-US/eb0ccd5b-e7e0-4d90-950b-a4c696f0bd6e/deployment-contributor-could-not-be-loaded?forum=ssdt"&gt;definitively identify the location that is being checked&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ol&gt;
  &lt;li&gt;Open a new command prompt as Administrator.&lt;/li&gt;
  &lt;li&gt;&lt;p&gt;Run the following command&lt;/p&gt;
  
  &lt;p&gt;&lt;code&gt;logman create trace -n DacFxDebug -p "Microsoft-SQLServerDataTools" 0x800 -o "%LOCALAPPDATA%\DacFxDebug.etl" -ets&lt;/code&gt;
  &lt;code&gt;logman create trace -n SSDTDebug -p "Microsoft-SQLServerDataToolsVS" 0x800 -o "%LOCALAPPDATA%\SSDTDebug.etl" -ets&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
  &lt;li&gt;&lt;p&gt;Run whatever the target/issue scenario is in SSDT.&lt;/p&gt;&lt;/li&gt;
  &lt;li&gt;&lt;p&gt;Go back to the command prompt and run the following commands&lt;/p&gt;
  
  &lt;p&gt;&lt;code&gt;logman stop DacFxDebug -ets&lt;/code&gt;
  &lt;code&gt;logman stop SSDTDebug -ets&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
  &lt;/ol&gt;
  
  &lt;p&gt;The resulting ETL files will be located at &lt;code&gt;%LOCALAPPDATA%\SSDTDebug.etl &amp;amp; %LOCALAPPDATA%\DacFxDebug.etl&lt;/code&gt; and can be navigated to using Windows Explorer.
  The &lt;code&gt;DacFxDebug.etl&lt;/code&gt; file will contain extension load information. This can be opened and analyzed using the Windows Event Viewer.
  To do this, open the Windows Event Viewer application. In the right-hand panel, select Open Saved Log. Navigate to the location where you saved the log, open, and review the contents of the trace.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/DeploymentPlanModifer/50_EventViewerLocation.png" alt="Event Viewer extensions location" /&gt;&lt;/p&gt;

&lt;p&gt;I also had some trouble with referencing correct version of the assemblies. Here is the final list of references and the locations that they resided in. I am using SQL Server Data Tools version 12.0.50318.0 at the time of writing this post.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;System.ComponentModel.Composition - Framework

Microsoft.Data.Tools.Schema.Sql.dll - `C:\Program Files (x86)\Microsoft Visual Studio 12.0\Common7\IDE\Extensions\Microsoft\SQLDB\DAC\120\Microsoft.Data.Tools.Schema.Sql.dll`
Microsoft.SqlServer.Dac.dll - `C:\Program Files (x86)\Microsoft Visual Studio 12.0\Common7\IDE\Extensions\Microsoft\SQLDB\DAC\120\Microsoft.SqlServer.Dac.dll`
Microsoft.SqlServer.Dac.Extensions.dll - `C:\Program Files (x86)\Microsoft Visual Studio 12.0\Common7\IDE\Extensions\Microsoft\SQLDB\DAC\120\Microsoft.SqlServer.Dac.Extensions.dll`
Microsoft.SqlServer.TransactSql.ScriptDom.dll - `C:\Program Files (x86)\Microsoft SQL Server\120\SDK\Assemblies\Microsoft.SqlServer.TransactSql.ScriptDom.dll`
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Final thoughts&lt;/h2&gt;

&lt;p&gt;Its worth mentioning that this is not a problem for scripts that do not have a build action and scripts such as the pre and post deployment scripts are able to use the parameterized schema variable with no additional effort. &lt;/p&gt;

&lt;p&gt;Next step for me is to look at integrating this into and publishing script as part of a team build. Stay tuned.  &lt;/p&gt;

&lt;p&gt;I've hosted my final &lt;a href="https://github.com/shanec-/Nullfactory-DACExtensions"&gt;implementation here&lt;/a&gt; along with a sample database demonstrating its usage.&lt;/p&gt;

&lt;h2&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://msdn.microsoft.com/en-US/library/dn306642(v=vs.103).aspx"&gt;MSDN - Walkthrough: Extend Database Project Deployment to Modify the Deployment Plan&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://msdn.microsoft.com/en-us/library/dn306080(v=vs.103).aspx"&gt;MSDN - Walkthrough: Extend Database Project Build to Generate Model Statistics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Microsoft/DACExtensions"&gt;Microsoft/DACExtensions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://social.msdn.microsoft.com/Forums/sqlserver/en-US/eb0ccd5b-e7e0-4d90-950b-a4c696f0bd6e/deployment-contributor-could-not-be-loaded?forum=ssdt"&gt;MSDN Forum - Deployment Contributor could not be loaded&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://technet.microsoft.com/en-us/library/microsoft.sqlserver.dac.packageoptions.contributorarguments(v=sql.110).aspx"&gt;Technet - PackageOptions.ContributorArguments Property (Microsoft.SqlServer.Dac)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/10826014/suppress-some-warnings-in-sql-server-ssdt"&gt;Suppress some warnings in SQL Server SSDT - Stack Overflow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://social.msdn.microsoft.com/Forums/sqlserver/en-US/9b698de1-9f6d-4e51-8c73-93c57355e768/treat-specific-warning-as-error?forum=ssdt"&gt;MSDN Forum - Treat specific warning as error?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/NuGet/NuGet.Operations/blob/master/ext/SqlServer/Microsoft.SqlServer.Dac.Extensions.xml"&gt;NuGet.Operations/Microsoft.SqlServer.Dac.Extensions.xml at master · NuGet/NuGet.Operations&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</a10:content></item><item><guid isPermaLink="true">http://nullfactory.net/2015/03/disabling-sharepoint-search-service/</guid><link>http://nullfactory.net/2015/03/disabling-sharepoint-search-service/</link><title>Disabling the SharePoint Search Service</title><description>&lt;p&gt;If left unchecked, the SharePoint search service to attempts to consume most of the available memory in a resource constrained development box. I usually disable it when I am not actively working with it.&lt;/p&gt;

&lt;p&gt;&lt;a href="http://www.falconitservices.com/support/KB/Lists/Posts/Post.aspx?ID=182"&gt;This seems to be most effective&lt;/a&gt; way to completely disable the service. Although changing the password to an invalid one works as expected, it is important to replace the user account from a domain to a local user account as well. If not, the constant invalid login attempts could trigger your account lock out threshold policy in the domain.&lt;/p&gt;

&lt;p&gt;So for convenience sake I created two batch files - one to disable the service and another to bring it back up.  &lt;/p&gt;

</description><pubDate>Tue, 10 Mar 2015 18:30:00 Z</pubDate><a10:updated>2015-03-10T18:30:00Z</a10:updated><a10:content type="html">&lt;p&gt;If left unchecked, the SharePoint search service to attempts to consume most of the available memory in a resource constrained development box. I usually disable it when I am not actively working with it.&lt;/p&gt;

&lt;p&gt;&lt;a href="http://www.falconitservices.com/support/KB/Lists/Posts/Post.aspx?ID=182"&gt;This seems to be most effective&lt;/a&gt; way to completely disable the service. Although changing the password to an invalid one works as expected, it is important to replace the user account from a domain to a local user account as well. If not, the constant invalid login attempts could trigger your account lock out threshold policy in the domain.&lt;/p&gt;

&lt;p&gt;So for convenience sake I created two batch files - one to disable the service and another to bring it back up.  &lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;h2&gt;Disable the Search Service&lt;/h2&gt;

&lt;p&gt;The commands used to disable the search service:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;net user searchDummy Sup3rSecr3tPwd /add /passwordchg:no /expires:never
net stop SPSearchHostController
net stop OSearch15
sc config "SPSearchHostController" obj= ".\searchDummy" password= "WrongPwd"
sc config "OSearch15" obj= ".\searchDummy" password= "WrongPwd"
taskkill /im:noderunner.exe /f
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Notice that: &lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The first command creates the dummy user in the local machine - this will substitute the domain service account.&lt;/li&gt;
&lt;li&gt;The password is intentionally set to an incorrect one when assigned to the service.&lt;/li&gt;
&lt;li&gt;The last command is to force terminate any instances of &lt;code&gt;noderunner.exe&lt;/code&gt; and release some memory.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Enable the Search Service&lt;/h2&gt;

&lt;p&gt;The commands used to start the service up again:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sc config "SPSearchHostController" obj= "domain\searchservice" password= "CorrectPwd"
sc config "OSearch15" obj= "domain\searchservice" password= "CorrectPwd"
net start OSearch15
net start SPSearchHostController
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.falconitservices.com/support/KB/Lists/Posts/Post.aspx?ID=182"&gt;How to Disable SharePoint 2013 Search - IT Knowledgebase&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://technet.microsoft.com/en-us/library/hh994574.aspx"&gt;Technet -Account lockout threshold&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://technet.microsoft.com/en-us/library/cc990290.aspx"&gt;Technet - Sc Config&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/308298/how-to-set-windows-service-username-and-password-through-commandline"&gt;StackOverflow - how to set windows service username and password through commandline&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blogs.msdn.com/b/ssehgal/archive/2009/06/01/configuring-windows-services-using-command-prompt.aspx"&gt;MSDN Blogs - Configuring Windows services using Command Prompt - Sidharth Sehgal's blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.windows-commandline.com/add-user-from-command-line/"&gt;Add new user account from command line (CMD)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</a10:content></item><item><guid isPermaLink="true">http://nullfactory.net/2015/03/create-elevated-command-prompt-different-user-context/</guid><link>http://nullfactory.net/2015/03/create-elevated-command-prompt-different-user-context/</link><title>Create an Elevated Command Prompt Running Under a Different User Context</title><description>&lt;p&gt;User Account Control (UAC) is a security mechanism that is available in most modern versions of Windows. It restricts the ability to make changes to a computer environment without the explicit consent of an administrator. And as is with most production environments, it is very likely that this feature is already enabled. And just as likely, is the need to execute applications and commands under a different user within an elevated context during application deployment or maintenance. &lt;/p&gt;

&lt;p&gt;This is achieved by using the &lt;code&gt;runas&lt;/code&gt; command with the &lt;code&gt;/noprofile&lt;/code&gt; flag. The command below creates an elevated command line running under the &lt;code&gt;wunder\admin&lt;/code&gt; user:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;runas /noprofile /user:wunder\admin cmd 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now, all commands executed within this new command prompt would be in the same elevated status.&lt;/p&gt;

</description><pubDate>Fri, 06 Mar 2015 18:30:00 Z</pubDate><a10:updated>2015-03-06T18:30:00Z</a10:updated><a10:content type="html">&lt;p&gt;User Account Control (UAC) is a security mechanism that is available in most modern versions of Windows. It restricts the ability to make changes to a computer environment without the explicit consent of an administrator. And as is with most production environments, it is very likely that this feature is already enabled. And just as likely, is the need to execute applications and commands under a different user within an elevated context during application deployment or maintenance. &lt;/p&gt;

&lt;p&gt;This is achieved by using the &lt;code&gt;runas&lt;/code&gt; command with the &lt;code&gt;/noprofile&lt;/code&gt; flag. The command below creates an elevated command line running under the &lt;code&gt;wunder\admin&lt;/code&gt; user:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;runas /noprofile /user:wunder\admin cmd 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now, all commands executed within this new command prompt would be in the same elevated status.&lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;h2&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="http://ss64.com/nt/runas.html"&gt;Runas - Run under a different user account | Windows CMD | SS64.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://windows.microsoft.com/en-us/windows7/products/features/user-account-control"&gt;User Account Control&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://superuser.com/questions/42537/is-there-any-sudo-command-for-windows"&gt;SuperUser - Is there any 'sudo' command for Windows?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/12903629/how-do-i-run-a-program-from-command-prompt-as-a-different-user-and-as-an-admin"&gt;StackOverflow&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</a10:content></item><item><guid isPermaLink="true">http://nullfactory.net/2015/03/creating-a-self-signed-wild-card-ssl-certificate/</guid><link>http://nullfactory.net/2015/03/creating-a-self-signed-wild-card-ssl-certificate/</link><title>Creating a Self-Signed Wild Card SSL Certificate for Your Development Environment</title><description>&lt;p&gt;Secure Socket Layer (SSL) is a security standard used to ensure secure communication between a web server and browser and used in most modern web application. As a developer it is prudent to setup your development environment to closely resemble production as much as possible, including security concerns. However, getting a full fledged CA SSL certificate for you development environment might not be the most cost-effective solution. Therefore post summarizes the steps I take to create a self signed wild card certificate to be used in the internal environments. My guide is based on this &lt;a href="https://www.macaw.nl/weblog/2013/6/configuring-an-asp-net-project-for-development-with-ssl"&gt;excellent post&lt;/a&gt;.&lt;/p&gt;

&lt;h2&gt;Create the Certificate&lt;/h2&gt;

&lt;p&gt;In order to create the certificate we would be using the &lt;code&gt;MakeCert.exe&lt;/code&gt; tool which can be found at &lt;code&gt;C:\Program Files (x86)\Windows Kits\8.1\bin\x64\&lt;/code&gt;. This command creates the certificate and adds it to the logged in user's personal certificate store:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;makecert -r -pe -e 01/01/2099 -eku 1.3.6.1.5.5.7.3.1 -ss My -n CN="*.wunder.local" -sky exchange -sp "Microsoft RSA SChannel Cryptographic Provider" -sy 12 -len 2048 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Some of the notable flags:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;-r&lt;/strong&gt; - Indicates that we're creating a self-signed certificate.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-pe&lt;/strong&gt; - Includes the private key in the certificate and makes it exportable.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-e&lt;/strong&gt; - The validity period of the certificate.&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;-n&lt;/strong&gt; - The subject's certificate name - specify the wildcard url. &lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/SSWildCardSSL/1_CreateCertificate.png" alt="Create Certificate" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

</description><pubDate>Wed, 04 Mar 2015 18:30:00 Z</pubDate><a10:updated>2015-03-04T18:30:00Z</a10:updated><a10:content type="html">&lt;p&gt;Secure Socket Layer (SSL) is a security standard used to ensure secure communication between a web server and browser and used in most modern web application. As a developer it is prudent to setup your development environment to closely resemble production as much as possible, including security concerns. However, getting a full fledged CA SSL certificate for you development environment might not be the most cost-effective solution. Therefore post summarizes the steps I take to create a self signed wild card certificate to be used in the internal environments. My guide is based on this &lt;a href="https://www.macaw.nl/weblog/2013/6/configuring-an-asp-net-project-for-development-with-ssl"&gt;excellent post&lt;/a&gt;.&lt;/p&gt;

&lt;h2&gt;Create the Certificate&lt;/h2&gt;

&lt;p&gt;In order to create the certificate we would be using the &lt;code&gt;MakeCert.exe&lt;/code&gt; tool which can be found at &lt;code&gt;C:\Program Files (x86)\Windows Kits\8.1\bin\x64\&lt;/code&gt;. This command creates the certificate and adds it to the logged in user's personal certificate store:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;makecert -r -pe -e 01/01/2099 -eku 1.3.6.1.5.5.7.3.1 -ss My -n CN="*.wunder.local" -sky exchange -sp "Microsoft RSA SChannel Cryptographic Provider" -sy 12 -len 2048 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Some of the notable flags:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;-r&lt;/strong&gt; - Indicates that we're creating a self-signed certificate.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-pe&lt;/strong&gt; - Includes the private key in the certificate and makes it exportable.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-e&lt;/strong&gt; - The validity period of the certificate.&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;-n&lt;/strong&gt; - The subject's certificate name - specify the wildcard url. &lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/SSWildCardSSL/1_CreateCertificate.png" alt="Create Certificate" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;!--excerpt--&gt;

&lt;h3&gt;Verify Creation&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;Open a new &lt;code&gt;Microsoft Management Console (mmc.exe)&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Add the &lt;code&gt;Certificates&lt;/code&gt; Snap-In for &lt;code&gt;My Account&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Under the &lt;code&gt;Personal&lt;/code&gt; node, ensure that the newly created certificate exists.  &lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/SSWildCardSSL/2_CreateCertificate.png" alt="Verify Certificate" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3&gt;Export Certificate&lt;/h3&gt;

&lt;p&gt;Next we export the certificate, one with the private key (pfx) and one without (cer). &lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Within the same snap-in, right click on the certificate and select export. &lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/SSWildCardSSL/3_ExportCertificate.png" alt="Export Certificate Menu" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Select the option to export the private key. &lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/SSWildCardSSL/4_ExportPfxWizard.png" alt="Export Pfx Wizard 1" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/SSWildCardSSL/5_ExportPfxWizard.png" alt="Export Pfx Wizard 2" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Provide a password to protect the private key. &lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/SSWildCardSSL/6_ExportPfxWizard.png" alt="Export Pfx Wizard 3" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/SSWildCardSSL/7_ExportPfxWizard.png" alt="Export Pfx Wizard 4" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Provide a location to export the file.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/SSWildCardSSL/8_ExportPfxWizard.png" alt="Export Pfx Wizard 5" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/SSWildCardSSL/9_ExportPfxWizard.png" alt="Export Pfx Wizard 6" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Next let export the (.cer) file. Let's repeat the steps 1-4 but this time opting out of exporting the private key.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/SSWildCardSSL/10_ExportCerWizard.png" alt="Export Cer Wizard 1" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/SSWildCardSSL/11_ExportCerWizard.png" alt="Export Cer Wizard 2" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/SSWildCardSSL/12_ExportCerWizard.png" alt="Export Cer Wizard 3" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/SSWildCardSSL/13_ExportCerWizard.png" alt="Export Cer Wizard 4" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/SSWildCardSSL/14_ExportCerWizard.png" alt="Export Cer Wizard 5" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2&gt;Installation&lt;/h2&gt;

&lt;p&gt;Now, we install the pfx on the web server and each of the client machines consuming the web application.&lt;/p&gt;

&lt;h4&gt;Web Server&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;The easiest way to install the certificate is to right-click the certificate within explorer and select &lt;code&gt;Install PFX&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/SSWildCardSSL/15_InstallPfxWizard.png" alt="Install Pfx Wizard 1" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;This would launch the Certificate Import Wizard. Select the &lt;code&gt;Local Machine&lt;/code&gt; as the certificate store.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/SSWildCardSSL/16_InstallPfxWizard.png" alt="Install Pfx Wizard 2" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/SSWildCardSSL/17_InstallPfxWizard.png" alt="Install Pfx Wizard 3" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Provide the password for the private key. &lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/SSWildCardSSL/18_InstallPfxWizard.png" alt="Install Pfx Wizard 4" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Ensure that the certificate is installed under the &lt;code&gt;Personal&lt;/code&gt; store.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/SSWildCardSSL/19_InstallPfxWizard.png" alt="Install Pfx Wizard 5" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/SSWildCardSSL/20_InstallPfxWizard.png" alt="Install Pfx Wizard 6" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/SSWildCardSSL/21_InstallPfxWizard.png" alt="Install Pfx Wizard 7" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Navigate to Internet Information Services (IIS) Manager and make sure that the certificate is visible.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/SSWildCardSSL/22_VerifyIIS.png" alt="Verify Certificate in IIS" /&gt;&lt;/p&gt;

&lt;p&gt;Bind the certificate to the SSL Port and configure the web application as necessary.&lt;/p&gt;

&lt;h4&gt;Client Machines&lt;/h4&gt;

&lt;p&gt;Each of the client machines accessing the web application would have to trust the new certificate. This is done by adding the certificate to the the &lt;code&gt;Trusted Root Certification Authorities&lt;/code&gt; store.  &lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;On the client machine, right-click the certificate and selecting &lt;code&gt;Install&lt;/code&gt; from the menu. On the wizard select the &lt;code&gt;Local Machine&lt;/code&gt; as the store.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/SSWildCardSSL/23_InstallCertificate.png" alt="Install as Trusted Authority 1" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Add the certificate to the &lt;code&gt;Trusted Root Certification Authorities&lt;/code&gt; store.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/SSWildCardSSL/24_InstallCertificate.png" alt="Install as Trusted Authority 2" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/SSWildCardSSL/25_InstallCertificate.png" alt="Install as Trusted Authority 3" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/SSWildCardSSL/26_InstallCertificate.png" alt="Install as Trusted Authority 4" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2&gt;Final Thoughts&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;As suggested in the &lt;a href="https://www.macaw.nl/weblog/2013/6/configuring-an-asp-net-project-for-development-with-ssl"&gt;original article&lt;/a&gt;, this would be a good time check-in the certificates into source control so that the entire development team has access to the same files.&lt;/li&gt;
&lt;li&gt;While &lt;code&gt;Makecert.exe&lt;/code&gt; was used to create the certificate, there are other options such as OpenSSL that would work just the same. &lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.macaw.nl/weblog/2013/6/configuring-an-asp-net-project-for-development-with-ssl"&gt;Configuring an ASP.NET project for development with SSL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blogs.technet.com/b/salbawany/archive/2014/05/24/how-to-create-a-self-signed-wild-card-ssl-certificate.aspx"&gt;Technet - Faisal (Sal) Bawany’s TechNet Blog - How to create a self-signed Wildcard SSL Certificate&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://msdn.microsoft.com/en-us/library/bfsktky3(v=vs.110).aspx"&gt;MSDN - Makecert.exe (Certificate Creation Tool)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/26186780/difference-between-makecert-and-openssl-wrt-c-sharp-sslstream"&gt;Difference between MakeCert and OpenSSL wrt C# SslStream&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/26681192/whats-the-difference-between-the-personal-and-web-hosting-certificate-store"&gt;StackOverFlow - What's the difference between the Personal and Web Hosting certificate store?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</a10:content></item><item><guid isPermaLink="true">http://nullfactory.net/2015/03/could-not-establish-trust-relationship-ssl-tls/</guid><link>http://nullfactory.net/2015/03/could-not-establish-trust-relationship-ssl-tls/</link><title>Could Not Establish Trust Relationship for SSL/TLS Secure Channel</title><description>&lt;p&gt;A while back I worked on a project that required me to integrate to a third-party web service. The web service also in development in parallel by the external team and our team was provided a development endpoint that would be used for testing. &lt;/p&gt;

&lt;p&gt;The problem was the certificate used in the SSL was the same as the one production. This resulted in any call to the web service throwing an &lt;code&gt;Could not establish trust relationship for SSL/TLS secure channel&lt;/code&gt; error because of the url mismatch. &lt;/p&gt;

&lt;p&gt;Due to various constraints we were unable to get certificate replaced. So our temporary work around was to make our code to explicitly trust the external web service host:&lt;/p&gt;

</description><pubDate>Sun, 01 Mar 2015 18:30:00 Z</pubDate><a10:updated>2015-03-01T18:30:00Z</a10:updated><a10:content type="html">&lt;p&gt;A while back I worked on a project that required me to integrate to a third-party web service. The web service also in development in parallel by the external team and our team was provided a development endpoint that would be used for testing. &lt;/p&gt;

&lt;p&gt;The problem was the certificate used in the SSL was the same as the one production. This resulted in any call to the web service throwing an &lt;code&gt;Could not establish trust relationship for SSL/TLS secure channel&lt;/code&gt; error because of the url mismatch. &lt;/p&gt;

&lt;p&gt;Due to various constraints we were unable to get certificate replaced. So our temporary work around was to make our code to explicitly trust the external web service host:&lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;pre&gt;&lt;code&gt;using System.Linq;
using System.Net;
using System.Net.Security;

namespace SslTest
{
    public static class SslHelper
    {
        /// &amp;lt;summary&amp;gt;
        /// Explicitly trust the list of hosts provided and ignores any SSL trust related errors.
        /// &amp;lt;/summary&amp;gt;
        /// &amp;lt;param name="hosts"&amp;gt;List of hosts that are trusted&amp;lt;/param&amp;gt;
        /// &amp;lt;remarks&amp;gt;Only to be used in development environment. Do not use in production!&amp;lt;/remarks&amp;gt;
        public static void EnableTrustedHosts(string[] hosts)
        {
            ServicePointManager.ServerCertificateValidationCallback =
                (sender, certificate, chain, errors) =&amp;gt;
                {
                    if (errors == SslPolicyErrors.None)
                    {
                        return true;
                    }

                    var request = sender as HttpWebRequest;
                    if (request != null)
                    {
                        return hosts.Contains(request.RequestUri.Host);
                    }

                    return false;
                };
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The above callback invoked every time a certificate is validated. Call it once before making requests to the web service.&lt;/p&gt;

&lt;h2&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/703272/could-not-establish-trust-relationship-for-ssl-tls-secure-channel-soap"&gt;StackOverFlow - Could not establish trust relationship for SSL/TLS secure channel — SOAP&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</a10:content></item><item><guid isPermaLink="true">http://nullfactory.net/2015/02/obfuscate-sharepoint-ssrs-datasource/</guid><link>http://nullfactory.net/2015/02/obfuscate-sharepoint-ssrs-datasource/</link><title>Obfuscating a SharePoint-Integrated SSRS DataSource's Connection String</title><description>&lt;p&gt;When SQL Server Reporting Services (SSRS) is deployed as an SharePoint integrated solution, it enables much of its functionality to be managed right from within SharePoint. Starting from the 2013 version, the integration between SharePoint and SQL Server Reporting Services 2012 is more tightly coupled than previous iterations. &lt;/p&gt;

&lt;p&gt;One feature in integrated mode is the ability to have the data sources (.rsds) and report files (.rdl) within a document library itself. This means that reports can reference a DataSource within any document library in the SharePoint site. &lt;/p&gt;

&lt;p&gt;In order for the report to work the user should have read permission on both the data source as well as the report file. The problem with this is that the same user can now potentially view the settings within the data source file, including the connection string.&lt;/p&gt;

&lt;h2&gt;The Solution&lt;/h2&gt;

&lt;p&gt;In order to protect the connection string, I came up with a solution to obscure it through encryption. The solution can be broken down to two major steps:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Force the reports to get the connection string by evaluating an expression embedded within itself. &lt;/li&gt;
&lt;li&gt;Within this expression, call some custom code which manages the retrieval and decryption of the connection string. &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;One of the limitations with this method is that you can no longer use a shared data source and each report has to have its credentials embedded.&lt;/p&gt;

&lt;p&gt;In my example below, I will be retrieving the configuration string from a configuration list stored in the same SharePoint server. &lt;/p&gt;

</description><pubDate>Sun, 15 Feb 2015 18:30:00 Z</pubDate><a10:updated>2015-02-15T18:30:00Z</a10:updated><a10:content type="html">&lt;p&gt;When SQL Server Reporting Services (SSRS) is deployed as an SharePoint integrated solution, it enables much of its functionality to be managed right from within SharePoint. Starting from the 2013 version, the integration between SharePoint and SQL Server Reporting Services 2012 is more tightly coupled than previous iterations. &lt;/p&gt;

&lt;p&gt;One feature in integrated mode is the ability to have the data sources (.rsds) and report files (.rdl) within a document library itself. This means that reports can reference a DataSource within any document library in the SharePoint site. &lt;/p&gt;

&lt;p&gt;In order for the report to work the user should have read permission on both the data source as well as the report file. The problem with this is that the same user can now potentially view the settings within the data source file, including the connection string.&lt;/p&gt;

&lt;h2&gt;The Solution&lt;/h2&gt;

&lt;p&gt;In order to protect the connection string, I came up with a solution to obscure it through encryption. The solution can be broken down to two major steps:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Force the reports to get the connection string by evaluating an expression embedded within itself. &lt;/li&gt;
&lt;li&gt;Within this expression, call some custom code which manages the retrieval and decryption of the connection string. &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;One of the limitations with this method is that you can no longer use a shared data source and each report has to have its credentials embedded.&lt;/p&gt;

&lt;p&gt;In my example below, I will be retrieving the configuration string from a configuration list stored in the same SharePoint server. &lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;h3&gt;Create the report extensions assembly&lt;/h3&gt;

&lt;p&gt;Here's a summary of steps used to create report extension. You can find a link to the full source at the bottom of the post.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Create new a class library to host your custom code.&lt;/li&gt;
&lt;li&gt;Next, sign the assembly as we would be deploying it into the Global Assembly Cache. &lt;/li&gt;
&lt;li&gt;&lt;p&gt;In order for the report server to call the custom code, the strong-named assembly must be marked with the &lt;code&gt;[assembly: AllowPartiallyTrustedCallers]&lt;/code&gt; attribute. Let's do this now.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/ObfuscateSSRS/10_AllowPartiallyTrustedCallers.png" alt="Allow Partially Trusted Callers" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Create a new public class and method that would retrieve the connection string. This method would take the report server url as its only parameter. This parameter would be parsed and later used to generate the REST call to SharePoint. Next, add a &lt;code&gt;[SecuritySafeCritical]&lt;/code&gt; attribute to the method, we need to this to perform operations that require access outside of the sandbox. &lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/ObfuscateSSRS/20_CodeGetConnectionString.png" alt="GetConnectionStringMethod" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Now, create a helper method that retrieves the default credentials. This too would be decorated with the &lt;code&gt;[SecuritySafeCritical]&lt;/code&gt; attribute. In the body of the method, I explicitly assert the &lt;code&gt;EnvironmentPermission(EnvironmentPermissionAccess.Read, "USERNAME")&lt;/code&gt; permissions before using the &lt;code&gt;CredentialStore&lt;/code&gt;. We would run into a security exception if the explicit assertion is not done. &lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/ObfuscateSSRS/50_CodeGetSecurityCredentials.png" alt="GetSecurityCredential Method" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Finally, create the method that makes the REST call to retrieve the obfuscated connection string from a SharePoint configuration list.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/ObfuscateSSRS/40_CodeGetWebPermission.png" alt="GetConnectionStringFromSharePointList Method" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The &lt;code&gt;EnvironmentPermission&lt;/code&gt; assertion operation has to be in its own method with its own &lt;code&gt;[SecuritySafeCritical]&lt;/code&gt; attribute for it to work together with the &lt;code&gt;WebPermission&lt;/code&gt; assertion. Otherwise the following exception would be thrown:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Exception: System.Security.SecurityException Exception Message: Stack walk modifier must be reverted before another modification of the same type can be performed. Stacktrace:    at System.Security.CodeAccessSecurityEngine.Assert(CodeAccessPermission cap, StackCrawlMark&amp;amp; stackMark)
   at System.Security.CodeAccessPermission.Assert()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After numerous failed attempts at accessing the SPList via the SharePoint object model (I kept running into exceptions stating that I required full trust), I find that partial trust mode is &lt;a href="https://msdn.microsoft.com/en-us/library/office/dn268593.aspx"&gt;no longer supported and has been deprecated&lt;/a&gt;. As I was unable to find anyone online who had successfully got it to work, I opted to access the list via the REST service for its lesser dependencies and security permission requirements. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Compile and deploy the assembly into the Global Assembly Cache.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3&gt;Setting up the Report&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;Open up a copy of your report using the &lt;a href="http://www.microsoft.com/en-us/download/details.aspx?id=29072"&gt;latest version of Report Builder&lt;/a&gt;. &lt;/li&gt;
&lt;li&gt;&lt;p&gt;Right click on the work space area outside to bring up the context menu. Select the &lt;code&gt;Report Properties...&lt;/code&gt; menu item which opens up the &lt;code&gt;Report Properties&lt;/code&gt; dialog.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/ObfuscateSSRS/60_ReportPropertiesContextMenu.png" alt="Build Process Parameter" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/ObfuscateSSRS/70_ReoprtPropertiesDialog.png" alt="Build Process Parameter" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Navigate to the &lt;code&gt;References&lt;/code&gt; tab and add an entry for our custom assembly.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Next, create a new entry for the class containing our custom logic. Ensure that the class name is referred to using it full namespace and provide an instance name that would be used to call our code from within the report.  &lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/ObfuscateSSRS/80_ReportPropertiesDialog.png" alt="Build Process Parameter" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Now that our declarations have been done, edit the report data source for the report.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/ObfuscateSSRS/90_EditDataSource.png" alt="Build Process Parameter" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Click on the &lt;code&gt;fx&lt;/code&gt; button to open up the expressions dialog.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/ObfuscateSSRS/100_ConnStringSetExpression0.png" alt="Build Process Parameter" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Edit the expression to use the new custom method created previously. Pass in &lt;code&gt;Globals!ReportServerUrl&lt;/code&gt; as the method parameter.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/ObfuscateSSRS/110_ConnStringSetExpression1.png" alt="Build Process Parameter" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Now, upload the updated report back into the SharePoint list hosting our report files. If you already have a report with the same name and with a shared data source linked to it, our connection details would be overwritten. In order to avoid this, delete the report in the list and re-upload our new one. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Next, edit the Report Data Source by selecting the &lt;code&gt;Manage Data Sources&lt;/code&gt; menu item in the context menu. Ensure that connection type is set to &lt;code&gt;Custom data source&lt;/code&gt; and connection string to &lt;code&gt;Use connection string expression defined in the report&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/ObfuscateSSRS/130_ManageDataSource.png" alt="Build Process Parameter" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/ObfuscateSSRS/120_ConnStringNotInitialized.png" alt="Build Process Parameter" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;For the credentials, I will be using stored credentials. Note that the &lt;code&gt;Test Connection&lt;/code&gt; button does not work if the connection string needs to be evaluated at runtime.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2&gt;Final Thoughts&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;You can find the &lt;a href="https://github.com/shanec-/Nullfactory-SSRSExtensions"&gt;source here&lt;/a&gt;. It is meant only to be a template and should be extended to work with your own requirements.&lt;/li&gt;
&lt;li&gt;Since the custom assembly needs to be deployed into the Global Assembly Cache, I suggest including it as &lt;a href="https://msdn.microsoft.com/en-us/library/ee231595.aspx"&gt;part of the SharePoint Solution Package&lt;/a&gt; when automating your deployment process. &lt;/li&gt;
&lt;li&gt;Although this implementation was tested with a Microsoft SQL Server data source type, I suspect it can be altered to work with different connection types.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I would finally like to highlight the following articles as they gave me a lot of insight into Code Access Security (CAS) and better understanding of the security requirements I needed to address:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.simple-talk.com/dotnet/.net-framework/code-access-security-in-asp.net-4.0/"&gt;Simple-Talk - Code Access Security in ASP.NET 4.0&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.simple-talk.com/dotnet/.net-framework/whats-new-in-code-access-security-in-.net-framework-4.0---part-i/"&gt;Simple-Talk - What's New in Code Access Security in .NET Framework 4.0 - Part I&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.simple-talk.com/dotnet/.net-framework/whats-new-in-code-access-security-in-.net-framework-4.0---part-2/"&gt;Simple-Talk - What's New in Code Access Security in .NET Framework 4.0 - Part 2&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://technet.microsoft.com/en-us/library/bb326290%28v=sql.105%29.aspx"&gt;Technet - Features Supported by Reporting Services in SharePoint Integrated Mode&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://social.msdn.microsoft.com/Forums/sqlserver/en-US/d4588e88-5cb9-47cf-817b-a69942c507ac/how-to-use-microsoftsharepointdll-api-in-custom-assembly-of-ssrs-report?forum=sqlreportingservices"&gt;MSDN Forums - How to use "Microsoft.SharePoint.dll" API in custom assembly of SSRS report&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://msdn.microsoft.com/en-us/library/ms154658.aspx"&gt;MSDN - Code Access Security in Reporting Services&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://msdn.microsoft.com/en-us/library/ms153561.aspx"&gt;MSDN - Using Custom Assemblies with Reports&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://msdn.microsoft.com/en-us/library/ms154645.aspx"&gt;MSDN - Referencing Assemblies in an RDL File&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://msdn.microsoft.com/en-us/library/ms155034.aspx"&gt;MSDN - Deploying a Custom Assembly&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://msdn.microsoft.com/en-us/library/ms153587.aspx"&gt;MSDN - Asserting Permissions in Custom Assemblies&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://msdn.microsoft.com/en-us/library/ms154507.aspx"&gt;MSDN - Accessing Custom Assemblies Through Expressions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://msdn.microsoft.com/en-us/library/ms153693.aspx"&gt;MSDN - How to: Debug Custom Assemblies&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.simple-talk.com/dotnet/.net-framework/code-access-security-in-asp.net-4.0/"&gt;Simple-Talk - Code Access Security in ASP.NET 4.0&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.simple-talk.com/dotnet/.net-framework/whats-new-in-code-access-security-in-.net-framework-4.0---part-i/"&gt;Simple-Talk - What's New in Code Access Security in .NET Framework 4.0 - Part I&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.simple-talk.com/dotnet/.net-framework/whats-new-in-code-access-security-in-.net-framework-4.0---part-2/"&gt;Simple-Talk - What's New in Code Access Security in .NET Framework 4.0 - Part 2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://msdn.microsoft.com/en-us/library/office/dn268593.aspx"&gt;MSDN - Deciding between apps for SharePoint and SharePoint solution - Partial-trust user code is deprecated&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://msdn.microsoft.com/en-us/library/ee231595.aspx"&gt;MSDN - How to: Add and Remove Additional Assemblies&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</a10:content></item></channel></rss>
<rss xmlns:a10="http://www.w3.org/2005/Atom" version="2.0"><channel><title>nullfactory.net</title><link>http://nullfactory.net/rss.xml</link><description>nullfactory.net</description><item><guid isPermaLink="true">http://nullfactory.net/2016/04/checklist-enabling-quick-create-subgrid/</guid><link>http://nullfactory.net/2016/04/checklist-enabling-quick-create-subgrid/</link><title>Checklist for Enabling Quick Create from Subgrid</title><description>&lt;p&gt;There have been a few instances where I've wanted to launch a quick create a record directly from a sub-grid add-button. That is, without having an extra step of bringing down the lookup view and then clicking the &lt;code&gt;+ New&lt;/code&gt; button. &lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/QuickCreateSubGrid/10_ExpectedResult.png" alt="The expected result" /&gt;&lt;/p&gt;

&lt;p&gt;While the required steps are covered between these two great posts - &lt;a href="http://ledgeviewpartners.com/blog/manage-quick-create-forms-dynamics-crm/"&gt;here&lt;/a&gt; and &lt;a href="http://www.powerobjects.com/2015/03/10/open-quick-create-sub-grid/"&gt;here&lt;/a&gt;, I have summarized the checklist here for convenience.&lt;/p&gt;

</description><pubDate>Sat, 16 Apr 2016 14:00:00 Z</pubDate><a10:updated>2016-04-16T14:00:00Z</a10:updated><a10:content type="html">&lt;p&gt;There have been a few instances where I've wanted to launch a quick create a record directly from a sub-grid add-button. That is, without having an extra step of bringing down the lookup view and then clicking the &lt;code&gt;+ New&lt;/code&gt; button. &lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/QuickCreateSubGrid/10_ExpectedResult.png" alt="The expected result" /&gt;&lt;/p&gt;

&lt;p&gt;While the required steps are covered between these two great posts - &lt;a href="http://ledgeviewpartners.com/blog/manage-quick-create-forms-dynamics-crm/"&gt;here&lt;/a&gt; and &lt;a href="http://www.powerobjects.com/2015/03/10/open-quick-create-sub-grid/"&gt;here&lt;/a&gt;, I have summarized the checklist here for convenience.&lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;p&gt;In order to get the CRM sub-grid to show the quick create dialog, ensure that:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;The &lt;code&gt;Allow quick create&lt;/code&gt; is enabled for the child entity.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/QuickCreateSubGrid/20_AllowQuickCreateOption.png" alt="Enable Quick Create" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A quick create form exists for the entity. If not, create a new one.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/QuickCreateSubGrid/30_EnsureQuickCreateForm.png" alt="Ensure Quick Create form exists" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Ensure that the related foreign key field is &lt;code&gt;Business Required&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/QuickCreateSubGrid/40_BusinessRequired.png" alt="Ensure foreign key is business required" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="http://ledgeviewpartners.com/blog/manage-quick-create-forms-dynamics-crm/"&gt;How to Manage Quick Create Forms in Dynamics CRM - Ledgeview Partners&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.powerobjects.com/2015/03/10/open-quick-create-sub-grid/"&gt;How to: Open Quick Create from a Sub Grid&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</a10:content></item><item><guid isPermaLink="true">http://nullfactory.net/2016/04/non-searchable-field-breaks-pre-filtering/</guid><link>http://nullfactory.net/2016/04/non-searchable-field-breaks-pre-filtering/</link><title>Non-searchable Primary Key Field Breaks Pre-filtering</title><description>&lt;p&gt;I recently implemented a custom FetchXml based SSRS report that was designed to be run against a filtered list of accounts. The accounts were to be determined by the user at the time of execution, hence the report was setup to use pre-filtering on the accounts entity.&lt;/p&gt;

&lt;p&gt;The report worked fine except in one environment where the user was greeted with the following warning message:&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/PreFilterNonSearchable/10_FilteringError.png" alt="Filtering error" /&gt;&lt;/p&gt;

&lt;p&gt;Dismissing the warning opened up the &lt;code&gt;Report Filtering Criteria&lt;/code&gt; dialog with the following error:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;There was an error in showing this condition
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And additional information:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;The condition was referencing the field accountid. The field has been removed from the system or is not valid for advanced find.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/PreFilterNonSearchable/20_ReportFilteringCriteria.png" alt="Report filtering criteria" /&gt;&lt;/p&gt;

</description><pubDate>Fri, 15 Apr 2016 14:00:00 Z</pubDate><a10:updated>2016-04-15T14:00:00Z</a10:updated><a10:content type="html">&lt;p&gt;I recently implemented a custom FetchXml based SSRS report that was designed to be run against a filtered list of accounts. The accounts were to be determined by the user at the time of execution, hence the report was setup to use pre-filtering on the accounts entity.&lt;/p&gt;

&lt;p&gt;The report worked fine except in one environment where the user was greeted with the following warning message:&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/PreFilterNonSearchable/10_FilteringError.png" alt="Filtering error" /&gt;&lt;/p&gt;

&lt;p&gt;Dismissing the warning opened up the &lt;code&gt;Report Filtering Criteria&lt;/code&gt; dialog with the following error:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;There was an error in showing this condition
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And additional information:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;The condition was referencing the field accountid. The field has been removed from the system or is not valid for advanced find.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/PreFilterNonSearchable/20_ReportFilteringCriteria.png" alt="Report filtering criteria" /&gt;&lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;p&gt;A quick bit of investigating revealed that this particular environment had the &lt;code&gt;Searchable&lt;/code&gt; property of the primary key, within the account entity, set to &lt;code&gt;No&lt;/code&gt;.
This meant that the &lt;code&gt;Account&lt;/code&gt; attribute would not appear on any advanced find dialogs, there by affecting the &lt;code&gt;Reporting Filtering Criteria&lt;/code&gt; dialog. Re-enabling this got the report working as expected.&lt;/p&gt;

&lt;h2&gt;Reference&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.microsoft.com/en-us/dynamics/crm-customer-center/create-or-edit-entity-fields.aspx"&gt;Create or edit entity fields | Microsoft Dynamics CRM&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</a10:content></item><item><guid isPermaLink="true">http://nullfactory.net/2016/04/dynamics-crm-base64-attachment-size/</guid><link>http://nullfactory.net/2016/04/dynamics-crm-base64-attachment-size/</link><title>Base64 and Maximum Attachment Size in Dynamics CRM</title><description>&lt;p&gt;Microsoft Dynamics CRM provides out-of-the-box functionality to store and associate small file attachments against an entity record. This is achieved via the &lt;code&gt;annotation&lt;/code&gt; entity - it is similar to any other entity except that it stores meta data as well as the &lt;a href="https://msdn.microsoft.com/en-us/library/gg334398.aspx"&gt;actual content of the file attachment&lt;/a&gt; within it. &lt;/p&gt;

&lt;p&gt;As CRM is not designed to be a &lt;a href="http://www.optimalcrm.co.uk/storage-limit-reached-in-microsoft-dynamics-crm-online/"&gt;file store&lt;/a&gt;, it imposes some limitations on the size of attachments that can be uploaded. Recent versions of the product, including 2016, defaults this size to 5120Kb which can be adjusted to a &lt;a href="https://dynamicscrmherald.wordpress.com/2014/01/03/increasing-web-resource-and-email-note-attachment-file-size-in-microsoft-dynamics-crm-2013/"&gt;maximum hard limit of 32768Kb&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;However, there is one caveat with this limitation - CRM stores the byte stream in a base64 encoded format, this means that there would be an &lt;a href="http://stackoverflow.com/questions/4715415/base64-what-is-the-worst-possible-increase-in-space-usage"&gt;increase&lt;/a&gt; in the final saved file size. &lt;/p&gt;

</description><pubDate>Thu, 14 Apr 2016 14:00:00 Z</pubDate><a10:updated>2016-04-14T14:00:00Z</a10:updated><a10:content type="html">&lt;p&gt;Microsoft Dynamics CRM provides out-of-the-box functionality to store and associate small file attachments against an entity record. This is achieved via the &lt;code&gt;annotation&lt;/code&gt; entity - it is similar to any other entity except that it stores meta data as well as the &lt;a href="https://msdn.microsoft.com/en-us/library/gg334398.aspx"&gt;actual content of the file attachment&lt;/a&gt; within it. &lt;/p&gt;

&lt;p&gt;As CRM is not designed to be a &lt;a href="http://www.optimalcrm.co.uk/storage-limit-reached-in-microsoft-dynamics-crm-online/"&gt;file store&lt;/a&gt;, it imposes some limitations on the size of attachments that can be uploaded. Recent versions of the product, including 2016, defaults this size to 5120Kb which can be adjusted to a &lt;a href="https://dynamicscrmherald.wordpress.com/2014/01/03/increasing-web-resource-and-email-note-attachment-file-size-in-microsoft-dynamics-crm-2013/"&gt;maximum hard limit of 32768Kb&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;However, there is one caveat with this limitation - CRM stores the byte stream in a base64 encoded format, this means that there would be an &lt;a href="http://stackoverflow.com/questions/4715415/base64-what-is-the-worst-possible-increase-in-space-usage"&gt;increase&lt;/a&gt; in the final saved file size. &lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;p&gt;I recently learned that the upload restriction is done based on the encoded file size and not the original byte stream as I was expecting. I imagine this would be especially important to remember when designing integration components that create &lt;code&gt;annotation&lt;/code&gt; records.&lt;/p&gt;

&lt;h2&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://msdn.microsoft.com/en-us/library/gg334398.aspx"&gt;MSDN - Annotation (note) entity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.optimalcrm.co.uk/storage-limit-reached-in-microsoft-dynamics-crm-online/"&gt;Storage Limit Reached in Microsoft Dynamics CRM Online&lt;/a&gt; &lt;/li&gt;
&lt;li&gt;&lt;a href="https://dynamicscrmherald.wordpress.com/2014/01/03/increasing-web-resource-and-email-note-attachment-file-size-in-microsoft-dynamics-crm-2013/"&gt;Increasing Web Resource and Email / Note Attachment File Size in Microsoft Dynamics CRM 2013 | The Dynamics CRM Herald&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</a10:content></item><item><guid isPermaLink="true">http://nullfactory.net/2016/01/crm-solution-tfs-microsoft-xrm-data-powershell/</guid><link>http://nullfactory.net/2016/01/crm-solution-tfs-microsoft-xrm-data-powershell/</link><title>Strategy for Maintaining CRM Solutions in Team Foundation Server using Microsoft.Xrm.Data.PowerShell</title><description>&lt;p&gt;I've come across a few strategies on the internet on achieving this goal, with each one having its pros and cons. This post describes my own attempt at setting up a development workflow that can be integrated with the team builds.&lt;/p&gt;

&lt;p&gt;This implementation at its core revolves around the &lt;a href="https://github.com/seanmcne/Microsoft.Xrm.Data.PowerShell"&gt;&lt;code&gt;Microsoft.Xrm.Data.PowerShell&lt;/code&gt;&lt;/a&gt; module and the &lt;code&gt;Solution Packager&lt;/code&gt; tool provided with the official SDK. I have minimized the use of 3rd party libraries and have intentionally excluded the use of any visual studio extensions or helper tools.&lt;/p&gt;

&lt;h2&gt;Setting up the Tools&lt;/h2&gt;

&lt;h3&gt;Installing Microsoft.CrmSdk.CoreTools&lt;/h3&gt;

&lt;p&gt;Let's start off by creating a "tooling" project that would act as a hosts for the tools and scripts involved in the process.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Create a class library project to host the tools using for building the packages. I named mine &lt;code&gt;Nullfactory.Crm.Tooling&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Install the &lt;code&gt;Microsoft.CrmSdk.CoreTools&lt;/code&gt; nuget package by running the following command in the package manager console: &lt;/p&gt;

&lt;p&gt;&lt;code&gt;Install-Package Microsoft.CrmSdk.CoreTools -Project Nullfactory.Crm.Tooling&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This nuget package includes the &lt;code&gt;SolutionPackager.exe&lt;/code&gt; tool.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/CrmDataPowershell/10_InstallCoreTools.png" alt="Install Crm Core Tools" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Next, clean up the project by removing the default &lt;code&gt;Class1.cs&lt;/code&gt; file as well as the &lt;code&gt;Debug&lt;/code&gt; and &lt;code&gt;Release&lt;/code&gt; within the &lt;code&gt;bin&lt;/code&gt; folder.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Update the solution configurations to not build this project. Do this by navigating to the solution property pages &gt; &lt;code&gt;Configuration Properties&lt;/code&gt; and un-ticking the check box against the build column.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/CrmDataPowershell/20_DontBuild.png" alt="Do not Build Project" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

</description><pubDate>Wed, 20 Jan 2016 13:00:00 Z</pubDate><a10:updated>2016-01-20T13:00:00Z</a10:updated><a10:content type="html">&lt;p&gt;I've come across a few strategies on the internet on achieving this goal, with each one having its pros and cons. This post describes my own attempt at setting up a development workflow that can be integrated with the team builds.&lt;/p&gt;

&lt;p&gt;This implementation at its core revolves around the &lt;a href="https://github.com/seanmcne/Microsoft.Xrm.Data.PowerShell"&gt;&lt;code&gt;Microsoft.Xrm.Data.PowerShell&lt;/code&gt;&lt;/a&gt; module and the &lt;code&gt;Solution Packager&lt;/code&gt; tool provided with the official SDK. I have minimized the use of 3rd party libraries and have intentionally excluded the use of any visual studio extensions or helper tools.&lt;/p&gt;

&lt;h2&gt;Setting up the Tools&lt;/h2&gt;

&lt;h3&gt;Installing Microsoft.CrmSdk.CoreTools&lt;/h3&gt;

&lt;p&gt;Let's start off by creating a "tooling" project that would act as a hosts for the tools and scripts involved in the process.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Create a class library project to host the tools using for building the packages. I named mine &lt;code&gt;Nullfactory.Crm.Tooling&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Install the &lt;code&gt;Microsoft.CrmSdk.CoreTools&lt;/code&gt; nuget package by running the following command in the package manager console: &lt;/p&gt;

&lt;p&gt;&lt;code&gt;Install-Package Microsoft.CrmSdk.CoreTools -Project Nullfactory.Crm.Tooling&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This nuget package includes the &lt;code&gt;SolutionPackager.exe&lt;/code&gt; tool.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/CrmDataPowershell/10_InstallCoreTools.png" alt="Install Crm Core Tools" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Next, clean up the project by removing the default &lt;code&gt;Class1.cs&lt;/code&gt; file as well as the &lt;code&gt;Debug&lt;/code&gt; and &lt;code&gt;Release&lt;/code&gt; within the &lt;code&gt;bin&lt;/code&gt; folder.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Update the solution configurations to not build this project. Do this by navigating to the solution property pages &gt; &lt;code&gt;Configuration Properties&lt;/code&gt; and un-ticking the check box against the build column.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/CrmDataPowershell/20_DontBuild.png" alt="Do not Build Project" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;!--excerpt--&gt;

&lt;h3&gt;Install Microsoft.Xrm.Data.PowerShell&lt;/h3&gt;

&lt;p&gt;The &lt;code&gt;Microsoft.Xrm.Data.Powershell&lt;/code&gt; module makes interacting with CRM so much easier - it is used to connect to CRM and export the solutions. &lt;/p&gt;

&lt;p&gt;Follow these steps to install it:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Download the latest release from &lt;a href="https://github.com/seanmcne/Microsoft.Xrm.Data.PowerShell/releases/"&gt;here&lt;/a&gt;. Detailed installation instructions can be found on their github page. &lt;/li&gt;
&lt;li&gt;&lt;p&gt;Ensure that the zip file is unblocked &lt;em&gt;before extracting the contents&lt;/em&gt;. Once extracted, add them into the bin folder as part of the tooling project.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/CrmDataPowershell/30_UnblockZip.png" alt="Unblock Zip Before Extraction" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Since this module would have to be installed on each of the developer machines, I created a helper script that automates it - &lt;code&gt;Install-Microsoft.Xrm.Data.Powershell.ps1&lt;/code&gt;. Add this as part of the project as well. &lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/CrmDataPowershell/40_InstallPowershell.png" alt="Install Microsoft.Xrm.Data.Powershell" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://github.com/shanec-/Crm-PowershellBuildDemo/blob/master/src/Nullfactory.Crm.Tooling/bin/Install-Microsoft.Xrm.Data.Powershell.ps1"&gt;Download the install script here&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2&gt;Setting up the Projects&lt;/h2&gt;

&lt;p&gt;Next, lets create class library projects for each of the CRM Solutions. This makes visualizing and managing the solution from within Visual Studio easier. And more importantly, give us the ability to add a msbuild tasks.&lt;/p&gt;

&lt;p&gt;Edit the &lt;code&gt;csproj&lt;/code&gt; file of the newly created project and add the following ms build task. &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;Target Name="Build"&amp;gt;
    &amp;lt;Exec Command="$(SolutionDir)\Nullfactory.Crm.Tooling\bin\coretools\SolutionPackager.exe /action:pack /packagetype:both /folder:$(MSBuildProjectDirectory) /zipfile:$(OutDir)$(MSBuildProjectName).zip" /&amp;gt;
&amp;lt;/Target&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This ensures that both unmanaged and managed versions of the CRM solution is packaged anytime the project is built. &lt;/p&gt;

&lt;p&gt;Optionally, remove the &lt;code&gt;properties&lt;/code&gt; folder and &lt;code&gt;AssemblyInfo.cs&lt;/code&gt; file as they will not be required for these projects.&lt;/p&gt;

&lt;h3&gt;Add Solution Export and Synchronization Script&lt;/h3&gt;

&lt;p&gt;Add the &lt;code&gt;Sync-CrmSolution.ps1&lt;/code&gt; and &lt;code&gt;Sync-CrmSolution.Param.ps1&lt;/code&gt; files into the tooling project. These scripts can be downloaded &lt;a href="https://github.com/shanec-/Crm-PowershellBuildDemo/blob/master/src/Nullfactory.Crm.Tooling/bin/Sync-CrmSolution.ps1"&gt;here&lt;/a&gt; and &lt;a href="https://github.com/shanec-/Crm-PowershellBuildDemo/blob/master/src/Nullfactory.Crm.Tooling/bin/Sync-CrmSolution.Param.ps1"&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/CrmDataPowershell/60_SyncScriptsInstalled.png" alt="Installed Synchronization Scripts" /&gt;&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;Sync-CrmSolution.ps1&lt;/code&gt; script handles the exporting of the solution and performs the following actions:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Deletes all the artifacts from the CRM solution project folder.&lt;/li&gt;
&lt;li&gt;Connects to the organization and exports both the managed and un-managed versions of the solution.&lt;/li&gt;
&lt;li&gt;Finally, unpacks them into the previously emptied folder.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The &lt;code&gt;Sync-CrmSolution.Param.ps1&lt;/code&gt; script acts as a controller script with the actual parameters. Each developer would update this script to point to their own development CRM organization.&lt;/p&gt;

&lt;h2&gt;Unpacking and Synchronizing&lt;/h2&gt;

&lt;p&gt;Next, we unpack the initial version of the solution into the project. This is done using the following steps: &lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Ensure that the &lt;code&gt;Sync-CrmSolution.Param.ps1&lt;/code&gt; script is pointing to a valid CRM organization and solution and execute the script.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/CrmDataPowershell/50_ExtractingSolution.png" alt="Extracting Solution" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Once the solution has been unpacked, add the new artifacts into the project.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/CrmDataPowershell/70_SolutionExtracted.png" alt="Crm Solution Extracted" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Check-in all the changes done so far.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Now that the initial version is in source control, it raises the problem of figuring out the files that have changes in subsequent extractions. How do you figure out which files have changed so that only those files are check-in?&lt;/p&gt;

&lt;p&gt;One of my colleague introduced me to an interesting technique that hes been using for a while. I like it a lot as its simple, effective and avoids having to do any explicit TFS integration.   &lt;/p&gt;

&lt;p&gt;This method leverages Microsoft Visual Studio Team Foundation Server 2015 Power Tools in order to identify the files changed in the working folder. It requires each developer &lt;a href="https://visualstudiogallery.msdn.microsoft.com/898a828a-af00-42c6-bbb2-530dc7b8f2e1"&gt;install&lt;/a&gt; it on their development box.&lt;/p&gt;

&lt;p&gt;Whenever a developer synchronizes their version of the solution using the &lt;code&gt;Sync-CrmSolution.Param.ps1&lt;/code&gt; script, the power tools would automatically detect and check out the edited files. One would still have to manually include new and deleted files into the project via the detected changes dialog, but that's a minor inconvenience I can live with. &lt;/p&gt;

&lt;p&gt;A positive side effect of this method is that we no longer have to be concerned about the &lt;code&gt;allowDelete&lt;/code&gt; and &lt;code&gt;allowWrite&lt;/code&gt; parameters in the Solution Packager tool.&lt;/p&gt;

&lt;h2&gt;Final Thoughts&lt;/h2&gt;

&lt;p&gt;Now any time the class libraries hosting the solutions are built, the output would be packaged zip files for both managed and un-managed CRM solutions. &lt;/p&gt;

&lt;p&gt;Although I did not setup up separate projects for plugins and web resources in this example, it is certainly possible.  &lt;/p&gt;

&lt;p&gt;I might also explore converting the entire &lt;code&gt;Nullfactory.Crm.Tooling&lt;/code&gt; project into a template in a future post. It should make it a lot more easier integrate it into new projects.&lt;/p&gt;

&lt;p&gt;Finally, I feel that the day-to-day operation part of this process is a little bit tedious and does not offer any significant advantage over the convenience of using an Visual Studio extension. I knew this going in, but I wanted to have an understanding of the work involved in setting this up. &lt;/p&gt;

&lt;h2&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/seanmcne/Microsoft.Xrm.Data.PowerShell/releases/"&gt;Releases · seanmcne/Microsoft.Xrm.Data.PowerShell&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://msdn.microsoft.com/en-us/library/jj602987.aspx"&gt;Use the SolutionPackager tool to compress and extract a solution file&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://technet.microsoft.com/en-us/library/dd878350(v=vs.85).aspx"&gt;Installing Modules&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blogs.msdn.com/b/koteshb/archive/2010/02/13/powershell-creating-a-pscredential-object.aspx"&gt;PowerShell - How to create a PSCredential object - Kotesh Bandhamravuri - Site Home - MSDN Blogs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=65MVXzMAWyg"&gt;Integrating SolutionPackager into Visual Studio - YouTube&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://waelhamze.com/2014/01/12/dynamics-crm-parallel-development-with-solution-packager/"&gt;Dynamics CRM Parallel Development with Solution Packager | Wael Hamze&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://visualstudiogallery.msdn.microsoft.com/898a828a-af00-42c6-bbb2-530dc7b8f2e1"&gt;Microsoft Visual Studio Team Foundation Server 2015 Power Tools extension&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</a10:content></item><item><guid isPermaLink="true">http://nullfactory.net/2015/12/disabling-recurring-ondemand-webjob/</guid><link>http://nullfactory.net/2015/12/disabling-recurring-ondemand-webjob/</link><title>Disabling Recurring and OnDemand Web Jobs within a Deployment Slot</title><description>&lt;p&gt;I've come to realize that things can get a bit tricky when working with slot deployments and webjobs. I learned &lt;em&gt;the hard way&lt;/em&gt; that stopping a slotted Web App does &lt;strong&gt;not&lt;/strong&gt; stop the web jobs it hosts. This means that I can't just stop all my website slots and expect the related jobs to automatically shutdown as well. Bummer. 
Okay, so I am thinking maybe I'll just disable the individual jobs for each of the slots? Not much luck on that front either as the Azure portal only provides a &lt;code&gt;stop&lt;/code&gt; option for &lt;code&gt;continuous&lt;/code&gt; jobs and not for the &lt;code&gt;recurring&lt;/code&gt; and &lt;code&gt;OnDemand&lt;/code&gt; jobs.&lt;/p&gt;

&lt;p&gt;This limits us to a few possible solutions:&lt;/p&gt;

</description><pubDate>Sat, 19 Dec 2015 13:00:00 Z</pubDate><a10:updated>2015-12-19T13:00:00Z</a10:updated><a10:content type="html">&lt;p&gt;I've come to realize that things can get a bit tricky when working with slot deployments and webjobs. I learned &lt;em&gt;the hard way&lt;/em&gt; that stopping a slotted Web App does &lt;strong&gt;not&lt;/strong&gt; stop the web jobs it hosts. This means that I can't just stop all my website slots and expect the related jobs to automatically shutdown as well. Bummer. 
Okay, so I am thinking maybe I'll just disable the individual jobs for each of the slots? Not much luck on that front either as the Azure portal only provides a &lt;code&gt;stop&lt;/code&gt; option for &lt;code&gt;continuous&lt;/code&gt; jobs and not for the &lt;code&gt;recurring&lt;/code&gt; and &lt;code&gt;OnDemand&lt;/code&gt; jobs.&lt;/p&gt;

&lt;p&gt;This limits us to a few possible solutions:&lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;ol&gt;
&lt;li&gt;Make sure that all the resources accessed by the slotted web app / jobs are isolated from each other - Ensure that the necessary appsettings are defined as slot settings and point to different values. This is done so as to ensure that you do not inadvertently run a scheduled job multiple times (once via the production slot and one time for each of the slots). &lt;/li&gt;
&lt;li&gt;&lt;p&gt;Baking-in custom disabling logic right into your job - For example, a web job could skip its operation based on a custom appsetting value. Once again, this appsetting would be defined as a slot setting. &lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A word of caution - be weary when implementing the "skipping" logic on continous jobs as "skipping" can be considered a successful run which would in turn pop the last message in the tiggered queue.&lt;/p&gt;
&lt;/blockquote&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The nuke option - entirely delete the web job entries in each of the slots (not recommended).&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
</a10:content></item><item><guid isPermaLink="true">http://nullfactory.net/2015/11/strategy-updating-sql-server-schema-via-ssdt-delta-script/</guid><link>http://nullfactory.net/2015/11/strategy-updating-sql-server-schema-via-ssdt-delta-script/</link><title>Strategy for Updating a SQL Server Database Schema via SSDT Delta Script</title><description>&lt;p&gt;This posts talks about the high level steps I went through in order to get the SQL Server related components ready for automation in a project I worked on recently. &lt;/p&gt;

&lt;p&gt;This project uses SQL Server Data Tools (SSDT) project in order to maintain the database schema in source control. Its output - the Data-tier Application Component Packages (DACPAC) gets deployed into the appropriate target environment via a WebDeploy package. And considering that the solution was designed as an Entity Framework (EF) database first approach, code first migrations were not a viable upgrade strategy.&lt;/p&gt;

&lt;p&gt;Here are the steps I followed in order to bring the production environment up-to-date: &lt;/p&gt;

</description><pubDate>Tue, 24 Nov 2015 13:00:00 Z</pubDate><a10:updated>2015-11-24T13:00:00Z</a10:updated><a10:content type="html">&lt;p&gt;This posts talks about the high level steps I went through in order to get the SQL Server related components ready for automation in a project I worked on recently. &lt;/p&gt;

&lt;p&gt;This project uses SQL Server Data Tools (SSDT) project in order to maintain the database schema in source control. Its output - the Data-tier Application Component Packages (DACPAC) gets deployed into the appropriate target environment via a WebDeploy package. And considering that the solution was designed as an Entity Framework (EF) database first approach, code first migrations were not a viable upgrade strategy.&lt;/p&gt;

&lt;p&gt;Here are the steps I followed in order to bring the production environment up-to-date: &lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;ol&gt;
&lt;li&gt;Create a baseline DACPAC and move it into source control - this represents the schema currently in production.&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Next, ensure that every time the SSDT project is built a post event would generate a differential delta script between the baseline and latest DACPAC. I tried to simplify the following command by wrapping it up within a powershell script:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;amp;"C:\Program Files (x86)\Microsoft SQL Server\110\DAC\bin\sqlpackage" /a:Script /sf:$SourceDacpac  /tf:$TargetDacpac /op:$OutputDeltaFile /tdn:$DBName /p:IncludeTransactionalScripts=True /p:IncludeCompositeObjects=True /p:ScriptDatabaseOptions=False /p:BlockOnPossibleDataLoss=True /v:TenantSchemaName=dbo
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that one of the parameters (&lt;code&gt;p:IncludeTransactionalScripts=True&lt;/code&gt;) was to ensure that the script would be generated as a transaction.  &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;(optional) Perform any post processing on the generated delta script - In my specific use-case I had to tinker the script to work within a multi-tenant scenario. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;Deploy the generated delta script against the target environment. This can be done using a tools &lt;code&gt;SqlCmd&lt;/code&gt; or a custom tool such as &lt;a href="https://github.com/rusanu/DbUtilSqlCmd"&gt;https://github.com/rusanu/DbUtilSqlCmd&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Upon successful release, update the baseline to the latest DACPAC file.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/22352298/sqlpackage-with-script-action-does-not-produce-any-copy-always-scripts"&gt;Stack Overflow - ssdt - SQLPackage with Script Action does not produce any Copy Always scripts&lt;/a&gt; &lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/15502659/what-is-the-syntax-for-adding-multiple-arguments-onto-the-variables-parameter"&gt;Stack Overflow - ssdt - What is the syntax for adding multiple arguments onto the "Variables" parameter in sqlpackage.exe?&lt;/a&gt; &lt;/li&gt;
&lt;li&gt;&lt;a href="https://msdn.microsoft.com/en-us/library/hh550080(v=vs.103).aspx"&gt;MSDN - SqlPackage.exe&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://phoebix.com/2013/09/19/extract-dacpac-using-command-line/"&gt;Extract DacPac Using Command Line | phoebix&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/rusanu/DbUtilSqlCmd"&gt;rusanu/DbUtilSqlCmd · GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</a10:content></item><item><guid isPermaLink="true">http://nullfactory.net/2015/10/cdn-streaming-video-azure-storage/</guid><link>http://nullfactory.net/2015/10/cdn-streaming-video-azure-storage/</link><title>Setting up a CDN to Stream Video via Azure Storage</title><description>&lt;p&gt;I needed to setup an Azure Content Delivery Network (CDN) in order to stream some video files stored in Azure Blob Storage. Sounds simple enough right? Well, yes for the most part, but I did hit a few hurdles along the way. This post would hopefully help me avoid them the next time.&lt;/p&gt;

&lt;h2&gt;Create the Storage Account&lt;/h2&gt;

&lt;p&gt;Something I found out after the fact was that CDN endpoints &lt;a href="http://stackoverflow.com/questions/32569564/azure-resource-manager-deployment-vs-classic-deployment-of-storage-accounts"&gt;currently only support classic storage accounts&lt;/a&gt;. So the first order of business is to create a classic storage account either via old portal or using a &lt;a href="http://nullfactory.net/2015/10/deploy-classic-storage-azure-resource-manager/"&gt;resource group manager template&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;Another thing I found out is that, at the time of writing, classic storage accounts cannot be made under the 'East US' location. The closest alternative was 'East US 2' and worked fine; I guess its something worth considering if you wanted to co-locate all your resources.&lt;/p&gt;

&lt;p&gt;Next, create a container within storage account - the container would host the files that would be served by the CDN. It can be created manually via the old portal or even through visual studio. Ensure that container access type is set to &lt;code&gt;Public Blob&lt;/code&gt;.&lt;/p&gt;

&lt;h2&gt;Upgrade the Storage Account to a Newer Service Version&lt;/h2&gt;

&lt;p&gt;The first time I tried to tried to stream a video, it did not work as expected; stream was very choppy. It turns out that the service version that got set on the storage was not the latest. &lt;a href="http://blog.thoughtstuff.co.uk/2014/01/streaming-mp4-video-files-in-azure-storage-containers-blob-storage/"&gt;Read more here&lt;/a&gt;, &lt;a href="https://msdn.microsoft.com/library/azure/dd894041.aspx"&gt;and here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So the next step is update the storage account to the latest version in order to take advantage of the improvements. This can be done using the following code:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    var credentials = new StorageCredentials("accountname", "accountkey");
    var account = new CloudStorageAccount(credentials, true);
    var client = account.CreateCloudBlobClient();
    var properties = client.GetServiceProperties();
    properties.DefaultServiceVersion = "2013-08-15";
    client.SetServiceProperties(properties);
    Console.WriteLine(properties.DefaultServiceVersion);
&lt;/code&gt;&lt;/pre&gt;

</description><pubDate>Sat, 10 Oct 2015 13:00:00 Z</pubDate><a10:updated>2015-10-10T13:00:00Z</a10:updated><a10:content type="html">&lt;p&gt;I needed to setup an Azure Content Delivery Network (CDN) in order to stream some video files stored in Azure Blob Storage. Sounds simple enough right? Well, yes for the most part, but I did hit a few hurdles along the way. This post would hopefully help me avoid them the next time.&lt;/p&gt;

&lt;h2&gt;Create the Storage Account&lt;/h2&gt;

&lt;p&gt;Something I found out after the fact was that CDN endpoints &lt;a href="http://stackoverflow.com/questions/32569564/azure-resource-manager-deployment-vs-classic-deployment-of-storage-accounts"&gt;currently only support classic storage accounts&lt;/a&gt;. So the first order of business is to create a classic storage account either via old portal or using a &lt;a href="http://nullfactory.net/2015/10/deploy-classic-storage-azure-resource-manager/"&gt;resource group manager template&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;Another thing I found out is that, at the time of writing, classic storage accounts cannot be made under the 'East US' location. The closest alternative was 'East US 2' and worked fine; I guess its something worth considering if you wanted to co-locate all your resources.&lt;/p&gt;

&lt;p&gt;Next, create a container within storage account - the container would host the files that would be served by the CDN. It can be created manually via the old portal or even through visual studio. Ensure that container access type is set to &lt;code&gt;Public Blob&lt;/code&gt;.&lt;/p&gt;

&lt;h2&gt;Upgrade the Storage Account to a Newer Service Version&lt;/h2&gt;

&lt;p&gt;The first time I tried to tried to stream a video, it did not work as expected; stream was very choppy. It turns out that the service version that got set on the storage was not the latest. &lt;a href="http://blog.thoughtstuff.co.uk/2014/01/streaming-mp4-video-files-in-azure-storage-containers-blob-storage/"&gt;Read more here&lt;/a&gt;, &lt;a href="https://msdn.microsoft.com/library/azure/dd894041.aspx"&gt;and here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So the next step is update the storage account to the latest version in order to take advantage of the improvements. This can be done using the following code:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    var credentials = new StorageCredentials("accountname", "accountkey");
    var account = new CloudStorageAccount(credentials, true);
    var client = account.CreateCloudBlobClient();
    var properties = client.GetServiceProperties();
    properties.DefaultServiceVersion = "2013-08-15";
    client.SetServiceProperties(properties);
    Console.WriteLine(properties.DefaultServiceVersion);
&lt;/code&gt;&lt;/pre&gt;

&lt;!--excerpt--&gt;

&lt;h2&gt;Create the CDN Endpoint&lt;/h2&gt;

&lt;p&gt;Setting up the CDN itself it pretty straight forward:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Create a new CDN through the old portal by selecting &lt;code&gt;New &amp;gt; CDN &amp;gt; Quick Create&lt;/code&gt;. &lt;/li&gt;
&lt;li&gt;&lt;p&gt;Select your subscription and set the origin type as &lt;code&gt;Storage Account&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href="http://nullfactory.net/images/posts/AzureCDNStream/10_CreateCDN.png"&gt;&lt;img src="http://nullfactory.net/images/posts/AzureCDNStream/10_CreateCDN.png" alt="Azure Create CDN" /&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Select one of the classic storage accounts from the &lt;code&gt;Origin Url&lt;/code&gt; drop down and hit the create button.&lt;/p&gt;

&lt;p&gt;&lt;a href="http://nullfactory.net/images/posts/AzureCDNStream/20_CDNCreated.png"&gt;&lt;img src="http://nullfactory.net/images/posts/AzureCDNStream/20_CDNCreated.png" alt="Azure CDN Created" /&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2&gt;Upload Content&lt;/h2&gt;

&lt;p&gt;Now that everything is setup, go ahead and upload the content into blob storage using Visual Studio or &lt;a href="https://azurestorageexplorer.codeplex.com/"&gt;Azure Storage Explorer&lt;/a&gt;. Once the content is propagated, video streaming should be smooth and working as expected.&lt;/p&gt;

&lt;h2&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/32569564/azure-resource-manager-deployment-vs-classic-deployment-of-storage-accounts"&gt;Stack Overflow - Azure Resource Manager Deployment vs Classic Deployment of Storage Accounts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/7235082/is-microsoft-azure-cdn-a-real-cdn-or-something-else-entirely"&gt;Stack Overflow - Is Microsoft Azure CDN A Real CDN Or Something Else Entirely?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.thoughtstuff.co.uk/2014/01/streaming-mp4-video-files-in-azure-storage-containers-blob-storage/"&gt;Streaming MP4 video in Azure Storage containers (Blob Storage) | thoughtstuff | Tom Morgan&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://msdn.microsoft.com/library/azure/dd894041.aspx"&gt;MSDN - Versioning for the Azure Storage Services&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://azurestorageexplorer.codeplex.com/"&gt;Azure Storage Explorer - Home&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</a10:content></item><item><guid isPermaLink="true">http://nullfactory.net/2015/10/deploy-classic-storage-azure-resource-manager/</guid><link>http://nullfactory.net/2015/10/deploy-classic-storage-azure-resource-manager/</link><title>Deploying a Azure Classic Storage Account using Azure Resource Manager</title><description>&lt;p&gt;I've been working on Azure Resource Group templates quite a bit over the last few weeks. While it has been a pleasant experience overall, I ran into some hurdles the other day while attempting to figure out how to create a &lt;code&gt;Microsoft.ClassicStorage/StorageAccounts&lt;/code&gt; using the Azure Resource Manager(ARM) API.&lt;/p&gt;

&lt;p&gt;The latest version (2.7 at the time of writing) of Azure SDK GUI tools for visual studio were not particularly helpful in generating the required json, but thankfully &lt;a href="http://stackoverflow.com/questions/27347200/add-storage-to-azure-resource-manager"&gt;this&lt;/a&gt; post pointed me in the right direction. And after a little bit of fiddling I find that &lt;code&gt;2015-06-01&lt;/code&gt; appears to be last supported &lt;code&gt;apiVersion&lt;/code&gt; that works with classic storage.&lt;/p&gt;

&lt;p&gt;&lt;a href="http://nullfactory.net/images/posts/DeployClassicStorageArm/10_SupportedVersion.png"&gt;&lt;img src="http://nullfactory.net/images/posts/DeployClassicStorageArm/10_SupportedVersion.png" alt="Azure PowerShell Unsupported" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Here's the final script I used to create a classic storage container: &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    "$schema": "https://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
    "contentVersion": "1.0.0.0",
    "parameters": {
        "PrimaryStorageName": {
            "type": "string"
        },
        "PrimaryStorageType": {
            "type": "string",
            "defaultValue": "Standard_LRS",
            "allowedValues": [
                "Standard_LRS",
                "Standard_GRS",
                "Standard_ZRS"
            ]
        },
        "PrimaryStorageLocation": {
        "type": "string",
        "defaultValue": "East US",
        "allowedValues": [
            "East US",
            "West US",
            "West Europe",
            "East Asia",
            "South East Asia"
            ]
        }
    },
    "variables": {
    },
    "resources": [
        {
            "name": "[parameters('PrimaryStorageName')]",
            "type": "Microsoft.ClassicStorage/StorageAccounts",
            "location": "[parameters('PrimaryStorageLocation')]",
            "apiVersion":  "2015-06-01",
            "dependsOn": [ ],
            "properties": {
                "accountType": "[parameters('PrimaryStorageType')]"
            }
        }
    ],
    "outputs": {
    }
}
&lt;/code&gt;&lt;/pre&gt;

</description><pubDate>Fri, 09 Oct 2015 13:00:00 Z</pubDate><a10:updated>2015-10-09T13:00:00Z</a10:updated><a10:content type="html">&lt;p&gt;I've been working on Azure Resource Group templates quite a bit over the last few weeks. While it has been a pleasant experience overall, I ran into some hurdles the other day while attempting to figure out how to create a &lt;code&gt;Microsoft.ClassicStorage/StorageAccounts&lt;/code&gt; using the Azure Resource Manager(ARM) API.&lt;/p&gt;

&lt;p&gt;The latest version (2.7 at the time of writing) of Azure SDK GUI tools for visual studio were not particularly helpful in generating the required json, but thankfully &lt;a href="http://stackoverflow.com/questions/27347200/add-storage-to-azure-resource-manager"&gt;this&lt;/a&gt; post pointed me in the right direction. And after a little bit of fiddling I find that &lt;code&gt;2015-06-01&lt;/code&gt; appears to be last supported &lt;code&gt;apiVersion&lt;/code&gt; that works with classic storage.&lt;/p&gt;

&lt;p&gt;&lt;a href="http://nullfactory.net/images/posts/DeployClassicStorageArm/10_SupportedVersion.png"&gt;&lt;img src="http://nullfactory.net/images/posts/DeployClassicStorageArm/10_SupportedVersion.png" alt="Azure PowerShell Unsupported" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Here's the final script I used to create a classic storage container: &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    "$schema": "https://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
    "contentVersion": "1.0.0.0",
    "parameters": {
        "PrimaryStorageName": {
            "type": "string"
        },
        "PrimaryStorageType": {
            "type": "string",
            "defaultValue": "Standard_LRS",
            "allowedValues": [
                "Standard_LRS",
                "Standard_GRS",
                "Standard_ZRS"
            ]
        },
        "PrimaryStorageLocation": {
        "type": "string",
        "defaultValue": "East US",
        "allowedValues": [
            "East US",
            "West US",
            "West Europe",
            "East Asia",
            "South East Asia"
            ]
        }
    },
    "variables": {
    },
    "resources": [
        {
            "name": "[parameters('PrimaryStorageName')]",
            "type": "Microsoft.ClassicStorage/StorageAccounts",
            "location": "[parameters('PrimaryStorageLocation')]",
            "apiVersion":  "2015-06-01",
            "dependsOn": [ ],
            "properties": {
                "accountType": "[parameters('PrimaryStorageType')]"
            }
        }
    ],
    "outputs": {
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;!--excerpt--&gt;

&lt;h2&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://azure.microsoft.com/en-us/documentation/articles/resource-manager-deployment-model/"&gt;Microsoft Azure - Understand differences between Resource Manager and classic deployment models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/27347200/add-storage-to-azure-resource-manager"&gt;Stack Overflow - Add storage to Azure resource manager&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/31886601/how-to-force-azure-storage-account-as-classic"&gt;Stack Overflow - powershell - How to force Azure Storage Account as classic&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</a10:content></item><item><guid isPermaLink="true">http://nullfactory.net/2015/08/publishing-assemblies-without-gacutil/</guid><link>http://nullfactory.net/2015/08/publishing-assemblies-without-gacutil/</link><title>Publishing Assemblies into the GAC without GacUtil</title><description>&lt;p&gt;I constantly find myself googling this code snippet - its nice to keep handy: &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[System.Reflection.Assembly]::Load("System.EnterpriseServices, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b03f5f7f11d50a3a")
$publish = New-Object System.EnterpriseServices.Internal.Publish
$publish.GacInstall("c:\temp\publish_dll.dll")
&lt;/code&gt;&lt;/pre&gt;

</description><pubDate>Sun, 30 Aug 2015 14:00:00 Z</pubDate><a10:updated>2015-08-30T14:00:00Z</a10:updated><a10:content type="html">&lt;p&gt;I constantly find myself googling this code snippet - its nice to keep handy: &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[System.Reflection.Assembly]::Load("System.EnterpriseServices, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b03f5f7f11d50a3a")
$publish = New-Object System.EnterpriseServices.Internal.Publish
$publish.GacInstall("c:\temp\publish_dll.dll")
&lt;/code&gt;&lt;/pre&gt;

&lt;!--excerpt--&gt;

&lt;h2&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://msdn.microsoft.com/en-us/library/system.enterpriseservices.internal.publish.gacinstall.aspx"&gt;MSDN - Publish.GacInstall Method (System.EnterpriseServices.Internal)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://weblogs.asp.net/adweigert/powershell-install-gac-gacutil-for-powershell"&gt;The Technical Adventures of Adam Weigert - PowerShell: Install-Gac (GACUTIL for PowerShell)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/24950268/deploy-multiple-dll-files-into-gac-without-gacutil"&gt;StackOverflow.com - Deploy multiple dll files into gac without gacutil&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</a10:content></item><item><guid isPermaLink="true">http://nullfactory.net/2015/08/sharing-configuration-between-webjobs/</guid><link>http://nullfactory.net/2015/08/sharing-configuration-between-webjobs/</link><title>Sharing Configuration Between WebJobs</title><description>&lt;p&gt;The project I am working on started out with the single webjob and has since grown to multiple jobs running in parallel. They are all hosted within a dedicated web app, which allows us to scale the jobs independent of the rest of the application. And because they share a single container there is the added side effect of the jobs sharing all the Application Settings and connection strings too.&lt;/p&gt;

&lt;p&gt;While each webjob had its own class library, I didn't want to maintain multiple copies of  the &lt;code&gt;App.Config&lt;/code&gt; file. I decided to share the the common bits (&lt;code&gt;AppSettings&lt;/code&gt; and &lt;code&gt;ConnectionString&lt;/code&gt; sections) in their own files:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;In one of the webjob projects, I moved the &lt;code&gt;AppSettings&lt;/code&gt; and &lt;code&gt;ConnectionStrings&lt;/code&gt; into their own &lt;code&gt;.config&lt;/code&gt; files - &lt;code&gt;appSettings.config&lt;/code&gt; and &lt;code&gt;connectionStrings.config&lt;/code&gt; respectively.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Next, I referenced them back to the &lt;code&gt;App.config&lt;/code&gt; using the &lt;code&gt;configSource&lt;/code&gt; attribute.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Finally, I added the same files as linked files to the otherweb jobs and set their &lt;code&gt;Copy to Output Directory&lt;/code&gt; file property to &lt;code&gt;Copy Always&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This works well enough, but for one caveat - which prompted me to write this post in the first place. The problem is that the &lt;code&gt;Web Deploy Package&lt;/code&gt; publishing process does not appear to honor folder structures for the config files. That means that if you've separated the configuration into sub folders (like shown below), the publishing process would flatten it out.&lt;/p&gt;

</description><pubDate>Fri, 28 Aug 2015 14:00:00 Z</pubDate><a10:updated>2015-08-28T14:00:00Z</a10:updated><a10:content type="html">&lt;p&gt;The project I am working on started out with the single webjob and has since grown to multiple jobs running in parallel. They are all hosted within a dedicated web app, which allows us to scale the jobs independent of the rest of the application. And because they share a single container there is the added side effect of the jobs sharing all the Application Settings and connection strings too.&lt;/p&gt;

&lt;p&gt;While each webjob had its own class library, I didn't want to maintain multiple copies of  the &lt;code&gt;App.Config&lt;/code&gt; file. I decided to share the the common bits (&lt;code&gt;AppSettings&lt;/code&gt; and &lt;code&gt;ConnectionString&lt;/code&gt; sections) in their own files:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;In one of the webjob projects, I moved the &lt;code&gt;AppSettings&lt;/code&gt; and &lt;code&gt;ConnectionStrings&lt;/code&gt; into their own &lt;code&gt;.config&lt;/code&gt; files - &lt;code&gt;appSettings.config&lt;/code&gt; and &lt;code&gt;connectionStrings.config&lt;/code&gt; respectively.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Next, I referenced them back to the &lt;code&gt;App.config&lt;/code&gt; using the &lt;code&gt;configSource&lt;/code&gt; attribute.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Finally, I added the same files as linked files to the otherweb jobs and set their &lt;code&gt;Copy to Output Directory&lt;/code&gt; file property to &lt;code&gt;Copy Always&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This works well enough, but for one caveat - which prompted me to write this post in the first place. The problem is that the &lt;code&gt;Web Deploy Package&lt;/code&gt; publishing process does not appear to honor folder structures for the config files. That means that if you've separated the configuration into sub folders (like shown below), the publishing process would flatten it out.&lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;appSettings configSource="CommonConfig/appSettings.config" /&amp;gt;
&amp;lt;connectionStrings configSource="CommonConfig/connectionString.config" /&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/ShareConfigWebJob/10_SolutionStructure.png" alt="Solution Structure" /&gt;&lt;/p&gt;

&lt;p&gt;This is the new structure created when published:&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/ShareConfigWebJob/20_PackageStructure.png" alt="Package Structure" /&gt;&lt;/p&gt;

&lt;p&gt;I suppose we could possibly make it work if we create the webjob folder structure manually in the App_Data folder in your web project, but I don't think its worth the additional complexity for such a trivial issue.&lt;/p&gt;

&lt;p&gt;I guess the work around/best practice would be use a simple flat configuration folder structure.&lt;/p&gt;

&lt;h2&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/7417062/how-to-use-partial-config-files"&gt;c# - How to use partial config files - Stack Overflow&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</a10:content></item></channel></rss>
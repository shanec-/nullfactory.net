<feed xmlns="http://www.w3.org/2005/Atom"><title type="text">nullfactory.net</title><subtitle type="text">nullfactory.net</subtitle><id>http://nullfactory.net/</id><updated>2016-01-22T15:03:15+05:30</updated><author><name>Shane Carvalho</name><uri>http://nullfactory.net</uri><email>shanec_@hotmail.com</email></author><generator>Sandra.Snow Atom Generator</generator><link rel="alternate" href="http://nullfactory.net/feed.xml" /><link rel="self" type="text/html" title="nullfactory.net" href="http://nullfactory.net/feed.xml" /><entry><id>http://nullfactory.net/2016/01/crm-solution-tfs-microsoft-xrm-data-powershell/</id><title type="text">Strategy for Maintaining CRM Solutions in Team Foundation Server using Microsoft.Xrm.Data.PowerShell</title><summary type="html">&lt;p&gt;I've come across a few strategies on the internet on achieving this goal, with each one having its pros and cons. This post describes my own attempt at setting up a development workflow that can be integrated with the team builds.&lt;/p&gt;

&lt;p&gt;This implementation at its core revolves around the &lt;a href="https://github.com/seanmcne/Microsoft.Xrm.Data.PowerShell"&gt;&lt;code&gt;Microsoft.Xrm.Data.PowerShell&lt;/code&gt;&lt;/a&gt; module and the &lt;code&gt;Solution Packager&lt;/code&gt; tool provided with the official SDK. I have minimized the use of 3rd party libraries and have intentionally excluded the use of any visual studio extensions or helper tools.&lt;/p&gt;

&lt;h2&gt;Setting up the Tools&lt;/h2&gt;

&lt;h3&gt;Installing Microsoft.CrmSdk.CoreTools&lt;/h3&gt;

&lt;p&gt;Let's start off by creating a "tooling" project that would act as a hosts for the tools and scripts involved in the process.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Create a class library project to host the tools using for building the packages. I named mine &lt;code&gt;Nullfactory.Crm.Tooling&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Install the &lt;code&gt;Microsoft.CrmSdk.CoreTools&lt;/code&gt; nuget package by running the following command in the package manager console: &lt;/p&gt;

&lt;p&gt;&lt;code&gt;Install-Package Microsoft.CrmSdk.CoreTools -Project Nullfactory.Crm.Tooling&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This nuget package includes the &lt;code&gt;SolutionPackager.exe&lt;/code&gt; tool.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/CrmDataPowershell/10_InstallCoreTools.png" alt="Install Crm Core Tools" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Next, clean up the project by removing the default &lt;code&gt;Class1.cs&lt;/code&gt; file as well as the &lt;code&gt;Debug&lt;/code&gt; and &lt;code&gt;Release&lt;/code&gt; within the &lt;code&gt;bin&lt;/code&gt; folder.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Update the solution configurations to not build this project. Do this by navigating to the solution property pages &gt; &lt;code&gt;Configuration Properties&lt;/code&gt; and un-ticking the check box against the build column.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/CrmDataPowershell/20_DontBuild.png" alt="Do not Build Project" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

</summary><published>2016-01-20T18:30:00Z</published><updated>2016-01-20T18:30:00Z</updated><link rel="alternate" href="http://nullfactory.net/2016/01/crm-solution-tfs-microsoft-xrm-data-powershell/" /><content type="html">&lt;p&gt;I've come across a few strategies on the internet on achieving this goal, with each one having its pros and cons. This post describes my own attempt at setting up a development workflow that can be integrated with the team builds.&lt;/p&gt;

&lt;p&gt;This implementation at its core revolves around the &lt;a href="https://github.com/seanmcne/Microsoft.Xrm.Data.PowerShell"&gt;&lt;code&gt;Microsoft.Xrm.Data.PowerShell&lt;/code&gt;&lt;/a&gt; module and the &lt;code&gt;Solution Packager&lt;/code&gt; tool provided with the official SDK. I have minimized the use of 3rd party libraries and have intentionally excluded the use of any visual studio extensions or helper tools.&lt;/p&gt;

&lt;h2&gt;Setting up the Tools&lt;/h2&gt;

&lt;h3&gt;Installing Microsoft.CrmSdk.CoreTools&lt;/h3&gt;

&lt;p&gt;Let's start off by creating a "tooling" project that would act as a hosts for the tools and scripts involved in the process.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Create a class library project to host the tools using for building the packages. I named mine &lt;code&gt;Nullfactory.Crm.Tooling&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Install the &lt;code&gt;Microsoft.CrmSdk.CoreTools&lt;/code&gt; nuget package by running the following command in the package manager console: &lt;/p&gt;

&lt;p&gt;&lt;code&gt;Install-Package Microsoft.CrmSdk.CoreTools -Project Nullfactory.Crm.Tooling&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This nuget package includes the &lt;code&gt;SolutionPackager.exe&lt;/code&gt; tool.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/CrmDataPowershell/10_InstallCoreTools.png" alt="Install Crm Core Tools" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Next, clean up the project by removing the default &lt;code&gt;Class1.cs&lt;/code&gt; file as well as the &lt;code&gt;Debug&lt;/code&gt; and &lt;code&gt;Release&lt;/code&gt; within the &lt;code&gt;bin&lt;/code&gt; folder.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Update the solution configurations to not build this project. Do this by navigating to the solution property pages &gt; &lt;code&gt;Configuration Properties&lt;/code&gt; and un-ticking the check box against the build column.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/CrmDataPowershell/20_DontBuild.png" alt="Do not Build Project" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;!--excerpt--&gt;

&lt;h3&gt;Install Microsoft.Xrm.Data.PowerShell&lt;/h3&gt;

&lt;p&gt;The &lt;code&gt;Microsoft.Xrm.Data.Powershell&lt;/code&gt; module makes interacting with CRM so much easier - it is used to connect to CRM and export the solutions. &lt;/p&gt;

&lt;p&gt;Follow these steps to install it:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Download the latest release from &lt;a href="https://github.com/seanmcne/Microsoft.Xrm.Data.PowerShell/releases/"&gt;here&lt;/a&gt;. Detailed installation instructions can be found on their github page. &lt;/li&gt;
&lt;li&gt;&lt;p&gt;Ensure that the zip file is unblocked &lt;em&gt;before extracting the contents&lt;/em&gt;. Once extracted, add them into the bin folder as part of the tooling project.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/CrmDataPowershell/30_UnblockZip.png" alt="Unblock Zip Before Extraction" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Since this module would have to be installed on each of the developer machines, I created a helper script that automates it - &lt;code&gt;Install-Microsoft.Xrm.Data.Powershell.ps1&lt;/code&gt;. Add this as part of the project as well. &lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/CrmDataPowershell/40_InstallPowershell.png" alt="Install Microsoft.Xrm.Data.Powershell" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://github.com/shanec-/Crm-PowershellBuildDemo/blob/master/src/Nullfactory.Crm.Tooling/bin/Install-Microsoft.Xrm.Data.Powershell.ps1"&gt;Download the install script here&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2&gt;Setting up the Projects&lt;/h2&gt;

&lt;p&gt;Next, lets create class library projects for each of the CRM Solutions. This makes visualizing and managing the solution from within Visual Studio easier. And more importantly, give us the ability to add a msbuild tasks.&lt;/p&gt;

&lt;p&gt;Edit the &lt;code&gt;csproj&lt;/code&gt; file of the newly created project and add the following ms build task. &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;Target Name="Build"&amp;gt;
    &amp;lt;Exec Command="$(SolutionDir)\Nullfactory.Crm.Tooling\bin\coretools\SolutionPackager.exe /action:pack /packagetype:both /folder:$(MSBuildProjectDirectory) /zipfile:$(OutDir)$(MSBuildProjectName).zip" /&amp;gt;
&amp;lt;/Target&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This ensures that both unmanaged and managed versions of the CRM solution is packaged anytime the project is built. &lt;/p&gt;

&lt;p&gt;Optionally, remove the &lt;code&gt;properties&lt;/code&gt; folder and &lt;code&gt;AssemblyInfo.cs&lt;/code&gt; file as they will not be required for these projects.&lt;/p&gt;

&lt;h3&gt;Add Solution Export and Synchronization Script&lt;/h3&gt;

&lt;p&gt;Add the &lt;code&gt;Sync-CrmSolution.ps1&lt;/code&gt; and &lt;code&gt;Sync-CrmSolution.Param.ps1&lt;/code&gt; files into the tooling project. These scripts can be downloaded &lt;a href="https://github.com/shanec-/Crm-PowershellBuildDemo/blob/master/src/Nullfactory.Crm.Tooling/bin/Sync-CrmSolution.ps1"&gt;here&lt;/a&gt; and &lt;a href="https://github.com/shanec-/Crm-PowershellBuildDemo/blob/master/src/Nullfactory.Crm.Tooling/bin/Sync-CrmSolution.Param.ps1"&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/CrmDataPowershell/60_SyncScriptsInstalled.png" alt="Installed Synchronization Scripts" /&gt;&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;Sync-CrmSolution.ps1&lt;/code&gt; script handles the exporting of the solution and performs the following actions:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Deletes all the artifacts from the CRM solution project folder.&lt;/li&gt;
&lt;li&gt;Connects to the organization and exports both the managed and un-managed versions of the solution.&lt;/li&gt;
&lt;li&gt;Finally, unpacks them into the previously emptied folder.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The &lt;code&gt;Sync-CrmSolution.Param.ps1&lt;/code&gt; script acts as a controller script with the actual parameters. Each developer would update this script to point to their own development CRM organization.&lt;/p&gt;

&lt;h2&gt;Unpacking and Synchronizing&lt;/h2&gt;

&lt;p&gt;Next, we unpack the initial version of the solution into the project. This is done using the following steps: &lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Ensure that the &lt;code&gt;Sync-CrmSolution.Param.ps1&lt;/code&gt; script is pointing to a valid CRM organization and solution and execute the script.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/CrmDataPowershell/50_ExtractingSolution.png" alt="Extracting Solution" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Once the solution has been unpacked, add the new artifacts into the project.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/CrmDataPowershell/70_SolutionExtracted.png" alt="Crm Solution Extracted" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Check-in all the changes done so far.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Now that the initial version is in source control, it raises the problem of figuring out the files that have changes in subsequent extractions. How do you figure out which files have changed so that only those files are check-in?&lt;/p&gt;

&lt;p&gt;One of my colleague introduced me to an interesting technique that hes been using for a while. I like it a lot as its simple, effective and avoids having to do any explicit TFS integration.   &lt;/p&gt;

&lt;p&gt;This method leverages Microsoft Visual Studio Team Foundation Server 2015 Power Tools in order to identify the files changed in the working folder. It requires each developer &lt;a href="https://visualstudiogallery.msdn.microsoft.com/898a828a-af00-42c6-bbb2-530dc7b8f2e1"&gt;install&lt;/a&gt; it on their development box.&lt;/p&gt;

&lt;p&gt;Whenever a developer synchronizes their version of the solution using the &lt;code&gt;Sync-CrmSolution.Param.ps1&lt;/code&gt; script, the power tools would automatically detect and check out the edited files. One would still have to manually include new and deleted files into the project via the detected changes dialog, but that's a minor inconvenience I can live with. &lt;/p&gt;

&lt;p&gt;A positive side effect of this method is that we no longer have to be concerned about the &lt;code&gt;allowDelete&lt;/code&gt; and &lt;code&gt;allowWrite&lt;/code&gt; parameters in the Solution Packager tool.&lt;/p&gt;

&lt;h2&gt;Final Thoughts&lt;/h2&gt;

&lt;p&gt;Now any time the class libraries hosting the solutions are built, the output would be packaged zip files for both managed and un-managed CRM solutions. &lt;/p&gt;

&lt;p&gt;Although I did not setup up separate projects for plugins and web resources in this example, it is certainly possible.  &lt;/p&gt;

&lt;p&gt;I might also explore converting the entire &lt;code&gt;Nullfactory.Crm.Tooling&lt;/code&gt; project into a template in a future post. It should make it a lot more easier integrate it into new projects.&lt;/p&gt;

&lt;p&gt;Finally, I feel that the day-to-day operation part of this process is a little bit tedious and does not offer any significant advantage over the convenience of using an Visual Studio extension. I knew this going in, but I wanted to have an understanding of the work involved in setting this up. &lt;/p&gt;

&lt;h2&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/seanmcne/Microsoft.Xrm.Data.PowerShell/releases/"&gt;Releases · seanmcne/Microsoft.Xrm.Data.PowerShell&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://msdn.microsoft.com/en-us/library/jj602987.aspx"&gt;Use the SolutionPackager tool to compress and extract a solution file&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://technet.microsoft.com/en-us/library/dd878350(v=vs.85).aspx"&gt;Installing Modules&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blogs.msdn.com/b/koteshb/archive/2010/02/13/powershell-creating-a-pscredential-object.aspx"&gt;PowerShell - How to create a PSCredential object - Kotesh Bandhamravuri - Site Home - MSDN Blogs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=65MVXzMAWyg"&gt;Integrating SolutionPackager into Visual Studio - YouTube&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://waelhamze.com/2014/01/12/dynamics-crm-parallel-development-with-solution-packager/"&gt;Dynamics CRM Parallel Development with Solution Packager | Wael Hamze&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://visualstudiogallery.msdn.microsoft.com/898a828a-af00-42c6-bbb2-530dc7b8f2e1"&gt;Microsoft Visual Studio Team Foundation Server 2015 Power Tools extension&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content></entry><entry><id>http://nullfactory.net/2015/12/disabling-recurring-ondemand-webjob/</id><title type="text">Disabling Recurring and OnDemand Web Jobs within a Deployment Slot</title><summary type="html">&lt;p&gt;I've come to realize that things can get a bit tricky when working with slot deployments and webjobs. I learned &lt;em&gt;the hard way&lt;/em&gt; that stopping a slotted Web App does &lt;strong&gt;not&lt;/strong&gt; stop the web jobs it hosts. This means that I can't just stop all my website slots and expect the related jobs to automatically shutdown as well. Bummer. 
Okay, so I am thinking maybe I'll just disable the individual jobs for each of the slots? Not much luck on that front either as the Azure portal only provides a &lt;code&gt;stop&lt;/code&gt; option for &lt;code&gt;continuous&lt;/code&gt; jobs and not for the &lt;code&gt;recurring&lt;/code&gt; and &lt;code&gt;OnDemand&lt;/code&gt; jobs.&lt;/p&gt;

&lt;p&gt;This limits us to a few possible solutions:&lt;/p&gt;

</summary><published>2015-12-19T18:30:00Z</published><updated>2015-12-19T18:30:00Z</updated><link rel="alternate" href="http://nullfactory.net/2015/12/disabling-recurring-ondemand-webjob/" /><content type="html">&lt;p&gt;I've come to realize that things can get a bit tricky when working with slot deployments and webjobs. I learned &lt;em&gt;the hard way&lt;/em&gt; that stopping a slotted Web App does &lt;strong&gt;not&lt;/strong&gt; stop the web jobs it hosts. This means that I can't just stop all my website slots and expect the related jobs to automatically shutdown as well. Bummer. 
Okay, so I am thinking maybe I'll just disable the individual jobs for each of the slots? Not much luck on that front either as the Azure portal only provides a &lt;code&gt;stop&lt;/code&gt; option for &lt;code&gt;continuous&lt;/code&gt; jobs and not for the &lt;code&gt;recurring&lt;/code&gt; and &lt;code&gt;OnDemand&lt;/code&gt; jobs.&lt;/p&gt;

&lt;p&gt;This limits us to a few possible solutions:&lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;ol&gt;
&lt;li&gt;Make sure that all the resources accessed by the slotted web app / jobs are isolated from each other - Ensure that the necessary appsettings are defined as slot settings and point to different values. This is done so as to ensure that you do not inadvertently run a scheduled job multiple times (once via the production slot and one time for each of the slots). &lt;/li&gt;
&lt;li&gt;&lt;p&gt;Baking-in custom disabling logic right into your job - For example, a web job could skip its operation based on a custom appsetting value. Once again, this appsetting would be defined as a slot setting. &lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A word of caution - be weary when implementing the "skipping" logic on continous jobs as "skipping" can be considered a successful run which would in turn pop the last message in the tiggered queue.&lt;/p&gt;
&lt;/blockquote&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The nuke option - entirely delete the web job entries in each of the slots (not recommended).&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
</content></entry><entry><id>http://nullfactory.net/2015/11/strategy-updating-sql-server-schema-via-ssdt-delta-script/</id><title type="text">Strategy for Updating a SQL Server Database Schema via SSDT Delta Script</title><summary type="html">&lt;p&gt;This posts talks about the high level steps I went through in order to get the SQL Server related components ready for automation in a project I worked on recently. &lt;/p&gt;

&lt;p&gt;This project uses SQL Server Data Tools (SSDT) project in order to maintain the database schema in source control. Its output - the Data-tier Application Component Packages (DACPAC) gets deployed into the appropriate target environment via a WebDeploy package. And considering that the solution was designed as an Entity Framework (EF) database first approach, code first migrations were not a viable upgrade strategy.&lt;/p&gt;

&lt;p&gt;Here are the steps I followed in order to bring the production environment up-to-date: &lt;/p&gt;

</summary><published>2015-11-24T18:30:00Z</published><updated>2015-11-24T18:30:00Z</updated><link rel="alternate" href="http://nullfactory.net/2015/11/strategy-updating-sql-server-schema-via-ssdt-delta-script/" /><content type="html">&lt;p&gt;This posts talks about the high level steps I went through in order to get the SQL Server related components ready for automation in a project I worked on recently. &lt;/p&gt;

&lt;p&gt;This project uses SQL Server Data Tools (SSDT) project in order to maintain the database schema in source control. Its output - the Data-tier Application Component Packages (DACPAC) gets deployed into the appropriate target environment via a WebDeploy package. And considering that the solution was designed as an Entity Framework (EF) database first approach, code first migrations were not a viable upgrade strategy.&lt;/p&gt;

&lt;p&gt;Here are the steps I followed in order to bring the production environment up-to-date: &lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;ol&gt;
&lt;li&gt;Create a baseline DACPAC and move it into source control - this represents the schema currently in production.&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Next, ensure that every time the SSDT project is built a post event would generate a differential delta script between the baseline and latest DACPAC. I tried to simplify the following command by wrapping it up within a powershell script:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;amp;"C:\Program Files (x86)\Microsoft SQL Server\110\DAC\bin\sqlpackage" /a:Script /sf:$SourceDacpac  /tf:$TargetDacpac /op:$OutputDeltaFile /tdn:$DBName /p:IncludeTransactionalScripts=True /p:IncludeCompositeObjects=True /p:ScriptDatabaseOptions=False /p:BlockOnPossibleDataLoss=True /v:TenantSchemaName=dbo
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that one of the parameters (&lt;code&gt;p:IncludeTransactionalScripts=True&lt;/code&gt;) was to ensure that the script would be generated as a transaction.  &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;(optional) Perform any post processing on the generated delta script - In my specific use-case I had to tinker the script to work within a multi-tenant scenario. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;Deploy the generated delta script against the target environment. This can be done using a tools &lt;code&gt;SqlCmd&lt;/code&gt; or a custom tool such as &lt;a href="https://github.com/rusanu/DbUtilSqlCmd"&gt;https://github.com/rusanu/DbUtilSqlCmd&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Upon successful release, update the baseline to the latest DACPAC file.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/22352298/sqlpackage-with-script-action-does-not-produce-any-copy-always-scripts"&gt;Stack Overflow - ssdt - SQLPackage with Script Action does not produce any Copy Always scripts&lt;/a&gt; &lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/15502659/what-is-the-syntax-for-adding-multiple-arguments-onto-the-variables-parameter"&gt;Stack Overflow - ssdt - What is the syntax for adding multiple arguments onto the "Variables" parameter in sqlpackage.exe?&lt;/a&gt; &lt;/li&gt;
&lt;li&gt;&lt;a href="https://msdn.microsoft.com/en-us/library/hh550080(v=vs.103).aspx"&gt;MSDN - SqlPackage.exe&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://phoebix.com/2013/09/19/extract-dacpac-using-command-line/"&gt;Extract DacPac Using Command Line | phoebix&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/rusanu/DbUtilSqlCmd"&gt;rusanu/DbUtilSqlCmd · GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content></entry><entry><id>http://nullfactory.net/2015/10/cdn-streaming-video-azure-storage/</id><title type="text">Setting up a CDN to Stream Video via Azure Storage</title><summary type="html">&lt;p&gt;I needed to setup an Azure Content Delivery Network (CDN) in order to stream some video files stored in Azure Blob Storage. Sounds simple enough right? Well, yes for the most part, but I did hit a few hurdles along the way. This post would hopefully help me avoid them the next time.&lt;/p&gt;

&lt;h2&gt;Create the Storage Account&lt;/h2&gt;

&lt;p&gt;Something I found out after the fact was that CDN endpoints &lt;a href="http://stackoverflow.com/questions/32569564/azure-resource-manager-deployment-vs-classic-deployment-of-storage-accounts"&gt;currently only support classic storage accounts&lt;/a&gt;. So the first order of business is to create a classic storage account either via old portal or using a &lt;a href="http://nullfactory.net/2015/10/deploy-classic-storage-azure-resource-manager/"&gt;resource group manager template&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;Another thing I found out is that, at the time of writing, classic storage accounts cannot be made under the 'East US' location. The closest alternative was 'East US 2' and worked fine; I guess its something worth considering if you wanted to co-locate all your resources.&lt;/p&gt;

&lt;p&gt;Next, create a container within storage account - the container would host the files that would be served by the CDN. It can be created manually via the old portal or even through visual studio. Ensure that container access type is set to &lt;code&gt;Public Blob&lt;/code&gt;.&lt;/p&gt;

&lt;h2&gt;Upgrade the Storage Account to a Newer Service Version&lt;/h2&gt;

&lt;p&gt;The first time I tried to tried to stream a video, it did not work as expected; stream was very choppy. It turns out that the service version that got set on the storage was not the latest. &lt;a href="http://blog.thoughtstuff.co.uk/2014/01/streaming-mp4-video-files-in-azure-storage-containers-blob-storage/"&gt;Read more here&lt;/a&gt;, &lt;a href="https://msdn.microsoft.com/library/azure/dd894041.aspx"&gt;and here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So the next step is update the storage account to the latest version in order to take advantage of the improvements. This can be done using the following code:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    var credentials = new StorageCredentials("accountname", "accountkey");
    var account = new CloudStorageAccount(credentials, true);
    var client = account.CreateCloudBlobClient();
    var properties = client.GetServiceProperties();
    properties.DefaultServiceVersion = "2013-08-15";
    client.SetServiceProperties(properties);
    Console.WriteLine(properties.DefaultServiceVersion);
&lt;/code&gt;&lt;/pre&gt;

</summary><published>2015-10-10T18:30:00Z</published><updated>2015-10-10T18:30:00Z</updated><link rel="alternate" href="http://nullfactory.net/2015/10/cdn-streaming-video-azure-storage/" /><content type="html">&lt;p&gt;I needed to setup an Azure Content Delivery Network (CDN) in order to stream some video files stored in Azure Blob Storage. Sounds simple enough right? Well, yes for the most part, but I did hit a few hurdles along the way. This post would hopefully help me avoid them the next time.&lt;/p&gt;

&lt;h2&gt;Create the Storage Account&lt;/h2&gt;

&lt;p&gt;Something I found out after the fact was that CDN endpoints &lt;a href="http://stackoverflow.com/questions/32569564/azure-resource-manager-deployment-vs-classic-deployment-of-storage-accounts"&gt;currently only support classic storage accounts&lt;/a&gt;. So the first order of business is to create a classic storage account either via old portal or using a &lt;a href="http://nullfactory.net/2015/10/deploy-classic-storage-azure-resource-manager/"&gt;resource group manager template&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;Another thing I found out is that, at the time of writing, classic storage accounts cannot be made under the 'East US' location. The closest alternative was 'East US 2' and worked fine; I guess its something worth considering if you wanted to co-locate all your resources.&lt;/p&gt;

&lt;p&gt;Next, create a container within storage account - the container would host the files that would be served by the CDN. It can be created manually via the old portal or even through visual studio. Ensure that container access type is set to &lt;code&gt;Public Blob&lt;/code&gt;.&lt;/p&gt;

&lt;h2&gt;Upgrade the Storage Account to a Newer Service Version&lt;/h2&gt;

&lt;p&gt;The first time I tried to tried to stream a video, it did not work as expected; stream was very choppy. It turns out that the service version that got set on the storage was not the latest. &lt;a href="http://blog.thoughtstuff.co.uk/2014/01/streaming-mp4-video-files-in-azure-storage-containers-blob-storage/"&gt;Read more here&lt;/a&gt;, &lt;a href="https://msdn.microsoft.com/library/azure/dd894041.aspx"&gt;and here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So the next step is update the storage account to the latest version in order to take advantage of the improvements. This can be done using the following code:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    var credentials = new StorageCredentials("accountname", "accountkey");
    var account = new CloudStorageAccount(credentials, true);
    var client = account.CreateCloudBlobClient();
    var properties = client.GetServiceProperties();
    properties.DefaultServiceVersion = "2013-08-15";
    client.SetServiceProperties(properties);
    Console.WriteLine(properties.DefaultServiceVersion);
&lt;/code&gt;&lt;/pre&gt;

&lt;!--excerpt--&gt;

&lt;h2&gt;Create the CDN Endpoint&lt;/h2&gt;

&lt;p&gt;Setting up the CDN itself it pretty straight forward:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Create a new CDN through the old portal by selecting &lt;code&gt;New &amp;gt; CDN &amp;gt; Quick Create&lt;/code&gt;. &lt;/li&gt;
&lt;li&gt;&lt;p&gt;Select your subscription and set the origin type as &lt;code&gt;Storage Account&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href="http://nullfactory.net/images/posts/AzureCDNStream/10_CreateCDN.png"&gt;&lt;img src="http://nullfactory.net/images/posts/AzureCDNStream/10_CreateCDN.png" alt="Azure Create CDN" /&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Select one of the classic storage accounts from the &lt;code&gt;Origin Url&lt;/code&gt; drop down and hit the create button.&lt;/p&gt;

&lt;p&gt;&lt;a href="http://nullfactory.net/images/posts/AzureCDNStream/20_CDNCreated.png"&gt;&lt;img src="http://nullfactory.net/images/posts/AzureCDNStream/20_CDNCreated.png" alt="Azure CDN Created" /&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2&gt;Upload Content&lt;/h2&gt;

&lt;p&gt;Now that everything is setup, go ahead and upload the content into blob storage using Visual Studio or &lt;a href="https://azurestorageexplorer.codeplex.com/"&gt;Azure Storage Explorer&lt;/a&gt;. Once the content is propagated, video streaming should be smooth and working as expected.&lt;/p&gt;

&lt;h2&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/32569564/azure-resource-manager-deployment-vs-classic-deployment-of-storage-accounts"&gt;Stack Overflow - Azure Resource Manager Deployment vs Classic Deployment of Storage Accounts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/7235082/is-microsoft-azure-cdn-a-real-cdn-or-something-else-entirely"&gt;Stack Overflow - Is Microsoft Azure CDN A Real CDN Or Something Else Entirely?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.thoughtstuff.co.uk/2014/01/streaming-mp4-video-files-in-azure-storage-containers-blob-storage/"&gt;Streaming MP4 video in Azure Storage containers (Blob Storage) | thoughtstuff | Tom Morgan&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://msdn.microsoft.com/library/azure/dd894041.aspx"&gt;MSDN - Versioning for the Azure Storage Services&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://azurestorageexplorer.codeplex.com/"&gt;Azure Storage Explorer - Home&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content></entry><entry><id>http://nullfactory.net/2015/10/deploy-classic-storage-azure-resource-manager/</id><title type="text">Deploying a Azure Classic Storage Account using Azure Resource Manager</title><summary type="html">&lt;p&gt;I've been working on Azure Resource Group templates quite a bit over the last few weeks. While it has been a pleasant experience overall, I ran into some hurdles the other day while attempting to figure out how to create a &lt;code&gt;Microsoft.ClassicStorage/StorageAccounts&lt;/code&gt; using the Azure Resource Manager(ARM) API.&lt;/p&gt;

&lt;p&gt;The latest version (2.7 at the time of writing) of Azure SDK GUI tools for visual studio were not particularly helpful in generating the required json, but thankfully &lt;a href="http://stackoverflow.com/questions/27347200/add-storage-to-azure-resource-manager"&gt;this&lt;/a&gt; post pointed me in the right direction. And after a little bit of fiddling I find that &lt;code&gt;2015-06-01&lt;/code&gt; appears to be last supported &lt;code&gt;apiVersion&lt;/code&gt; that works with classic storage.&lt;/p&gt;

&lt;p&gt;&lt;a href="http://nullfactory.net/images/posts/DeployClassicStorageArm/10_SupportedVersion.png"&gt;&lt;img src="http://nullfactory.net/images/posts/DeployClassicStorageArm/10_SupportedVersion.png" alt="Azure PowerShell Unsupported" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Here's the final script I used to create a classic storage container: &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    "$schema": "https://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
    "contentVersion": "1.0.0.0",
    "parameters": {
        "PrimaryStorageName": {
            "type": "string"
        },
        "PrimaryStorageType": {
            "type": "string",
            "defaultValue": "Standard_LRS",
            "allowedValues": [
                "Standard_LRS",
                "Standard_GRS",
                "Standard_ZRS"
            ]
        },
        "PrimaryStorageLocation": {
        "type": "string",
        "defaultValue": "East US",
        "allowedValues": [
            "East US",
            "West US",
            "West Europe",
            "East Asia",
            "South East Asia"
            ]
        }
    },
    "variables": {
    },
    "resources": [
        {
            "name": "[parameters('PrimaryStorageName')]",
            "type": "Microsoft.ClassicStorage/StorageAccounts",
            "location": "[parameters('PrimaryStorageLocation')]",
            "apiVersion":  "2015-06-01",
            "dependsOn": [ ],
            "properties": {
                "accountType": "[parameters('PrimaryStorageType')]"
            }
        }
    ],
    "outputs": {
    }
}
&lt;/code&gt;&lt;/pre&gt;

</summary><published>2015-10-09T18:30:00Z</published><updated>2015-10-09T18:30:00Z</updated><link rel="alternate" href="http://nullfactory.net/2015/10/deploy-classic-storage-azure-resource-manager/" /><content type="html">&lt;p&gt;I've been working on Azure Resource Group templates quite a bit over the last few weeks. While it has been a pleasant experience overall, I ran into some hurdles the other day while attempting to figure out how to create a &lt;code&gt;Microsoft.ClassicStorage/StorageAccounts&lt;/code&gt; using the Azure Resource Manager(ARM) API.&lt;/p&gt;

&lt;p&gt;The latest version (2.7 at the time of writing) of Azure SDK GUI tools for visual studio were not particularly helpful in generating the required json, but thankfully &lt;a href="http://stackoverflow.com/questions/27347200/add-storage-to-azure-resource-manager"&gt;this&lt;/a&gt; post pointed me in the right direction. And after a little bit of fiddling I find that &lt;code&gt;2015-06-01&lt;/code&gt; appears to be last supported &lt;code&gt;apiVersion&lt;/code&gt; that works with classic storage.&lt;/p&gt;

&lt;p&gt;&lt;a href="http://nullfactory.net/images/posts/DeployClassicStorageArm/10_SupportedVersion.png"&gt;&lt;img src="http://nullfactory.net/images/posts/DeployClassicStorageArm/10_SupportedVersion.png" alt="Azure PowerShell Unsupported" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Here's the final script I used to create a classic storage container: &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    "$schema": "https://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
    "contentVersion": "1.0.0.0",
    "parameters": {
        "PrimaryStorageName": {
            "type": "string"
        },
        "PrimaryStorageType": {
            "type": "string",
            "defaultValue": "Standard_LRS",
            "allowedValues": [
                "Standard_LRS",
                "Standard_GRS",
                "Standard_ZRS"
            ]
        },
        "PrimaryStorageLocation": {
        "type": "string",
        "defaultValue": "East US",
        "allowedValues": [
            "East US",
            "West US",
            "West Europe",
            "East Asia",
            "South East Asia"
            ]
        }
    },
    "variables": {
    },
    "resources": [
        {
            "name": "[parameters('PrimaryStorageName')]",
            "type": "Microsoft.ClassicStorage/StorageAccounts",
            "location": "[parameters('PrimaryStorageLocation')]",
            "apiVersion":  "2015-06-01",
            "dependsOn": [ ],
            "properties": {
                "accountType": "[parameters('PrimaryStorageType')]"
            }
        }
    ],
    "outputs": {
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;!--excerpt--&gt;

&lt;h2&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://azure.microsoft.com/en-us/documentation/articles/resource-manager-deployment-model/"&gt;Microsoft Azure - Understand differences between Resource Manager and classic deployment models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/27347200/add-storage-to-azure-resource-manager"&gt;Stack Overflow - Add storage to Azure resource manager&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/31886601/how-to-force-azure-storage-account-as-classic"&gt;Stack Overflow - powershell - How to force Azure Storage Account as classic&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content></entry><entry><id>http://nullfactory.net/2015/08/publishing-assemblies-without-gacutil/</id><title type="text">Publishing Assemblies into the GAC without GacUtil</title><summary type="html">&lt;p&gt;I constantly find myself googling this code snippet - its nice to keep handy: &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[System.Reflection.Assembly]::Load("System.EnterpriseServices, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b03f5f7f11d50a3a")
$publish = New-Object System.EnterpriseServices.Internal.Publish
$publish.GacInstall("c:\temp\publish_dll.dll")
&lt;/code&gt;&lt;/pre&gt;

</summary><published>2015-08-30T18:30:00Z</published><updated>2015-08-30T18:30:00Z</updated><link rel="alternate" href="http://nullfactory.net/2015/08/publishing-assemblies-without-gacutil/" /><content type="html">&lt;p&gt;I constantly find myself googling this code snippet - its nice to keep handy: &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[System.Reflection.Assembly]::Load("System.EnterpriseServices, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b03f5f7f11d50a3a")
$publish = New-Object System.EnterpriseServices.Internal.Publish
$publish.GacInstall("c:\temp\publish_dll.dll")
&lt;/code&gt;&lt;/pre&gt;

&lt;!--excerpt--&gt;

&lt;h2&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://msdn.microsoft.com/en-us/library/system.enterpriseservices.internal.publish.gacinstall.aspx"&gt;MSDN - Publish.GacInstall Method (System.EnterpriseServices.Internal)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://weblogs.asp.net/adweigert/powershell-install-gac-gacutil-for-powershell"&gt;The Technical Adventures of Adam Weigert - PowerShell: Install-Gac (GACUTIL for PowerShell)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/24950268/deploy-multiple-dll-files-into-gac-without-gacutil"&gt;StackOverflow.com - Deploy multiple dll files into gac without gacutil&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content></entry><entry><id>http://nullfactory.net/2015/08/sharing-configuration-between-webjobs/</id><title type="text">Sharing Configuration Between WebJobs</title><summary type="html">&lt;p&gt;The project I am working on started out with the single webjob and has since grown to multiple jobs running in parallel. They are all hosted within a dedicated web app, which allows us to scale the jobs independent of the rest of the application. And because they share a single container there is the added side effect of the jobs sharing all the Application Settings and connection strings too.&lt;/p&gt;

&lt;p&gt;While each webjob had its own class library, I didn't want to maintain multiple copies of  the &lt;code&gt;App.Config&lt;/code&gt; file. I decided to share the the common bits (&lt;code&gt;AppSettings&lt;/code&gt; and &lt;code&gt;ConnectionString&lt;/code&gt; sections) in their own files:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;In one of the webjob projects, I moved the &lt;code&gt;AppSettings&lt;/code&gt; and &lt;code&gt;ConnectionStrings&lt;/code&gt; into their own &lt;code&gt;.config&lt;/code&gt; files - &lt;code&gt;appSettings.config&lt;/code&gt; and &lt;code&gt;connectionStrings.config&lt;/code&gt; respectively.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Next, I referenced them back to the &lt;code&gt;App.config&lt;/code&gt; using the &lt;code&gt;configSource&lt;/code&gt; attribute.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Finally, I added the same files as linked files to the otherweb jobs and set their &lt;code&gt;Copy to Output Directory&lt;/code&gt; file property to &lt;code&gt;Copy Always&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This works well enough, but for one caveat - which prompted me to write this post in the first place. The problem is that the &lt;code&gt;Web Deploy Package&lt;/code&gt; publishing process does not appear to honor folder structures for the config files. That means that if you've separated the configuration into sub folders (like shown below), the publishing process would flatten it out.&lt;/p&gt;

</summary><published>2015-08-28T18:30:00Z</published><updated>2015-08-28T18:30:00Z</updated><link rel="alternate" href="http://nullfactory.net/2015/08/sharing-configuration-between-webjobs/" /><content type="html">&lt;p&gt;The project I am working on started out with the single webjob and has since grown to multiple jobs running in parallel. They are all hosted within a dedicated web app, which allows us to scale the jobs independent of the rest of the application. And because they share a single container there is the added side effect of the jobs sharing all the Application Settings and connection strings too.&lt;/p&gt;

&lt;p&gt;While each webjob had its own class library, I didn't want to maintain multiple copies of  the &lt;code&gt;App.Config&lt;/code&gt; file. I decided to share the the common bits (&lt;code&gt;AppSettings&lt;/code&gt; and &lt;code&gt;ConnectionString&lt;/code&gt; sections) in their own files:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;In one of the webjob projects, I moved the &lt;code&gt;AppSettings&lt;/code&gt; and &lt;code&gt;ConnectionStrings&lt;/code&gt; into their own &lt;code&gt;.config&lt;/code&gt; files - &lt;code&gt;appSettings.config&lt;/code&gt; and &lt;code&gt;connectionStrings.config&lt;/code&gt; respectively.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Next, I referenced them back to the &lt;code&gt;App.config&lt;/code&gt; using the &lt;code&gt;configSource&lt;/code&gt; attribute.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Finally, I added the same files as linked files to the otherweb jobs and set their &lt;code&gt;Copy to Output Directory&lt;/code&gt; file property to &lt;code&gt;Copy Always&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This works well enough, but for one caveat - which prompted me to write this post in the first place. The problem is that the &lt;code&gt;Web Deploy Package&lt;/code&gt; publishing process does not appear to honor folder structures for the config files. That means that if you've separated the configuration into sub folders (like shown below), the publishing process would flatten it out.&lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;appSettings configSource="CommonConfig/appSettings.config" /&amp;gt;
&amp;lt;connectionStrings configSource="CommonConfig/connectionString.config" /&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/ShareConfigWebJob/10_SolutionStructure.png" alt="Solution Structure" /&gt;&lt;/p&gt;

&lt;p&gt;This is the new structure created when published:&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/ShareConfigWebJob/20_PackageStructure.png" alt="Package Structure" /&gt;&lt;/p&gt;

&lt;p&gt;I suppose we could possibly make it work if we create the webjob folder structure manually in the App_Data folder in your web project, but I don't think its worth the additional complexity for such a trivial issue.&lt;/p&gt;

&lt;p&gt;I guess the work around/best practice would be use a simple flat configuration folder structure.&lt;/p&gt;

&lt;h2&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/7417062/how-to-use-partial-config-files"&gt;c# - How to use partial config files - Stack Overflow&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content></entry><entry><id>http://nullfactory.net/2015/08/enable-ssrs-remote-error-sharepoint-integrated/</id><title type="text">Enable SSRS Remote Errors in SharePoint Integrated Mode</title><summary type="html">&lt;p&gt;Any time I have to troubleshoot issues in SQL Server Reporting Services (SSRS) reports in a production environment, I usually end up enabling &lt;code&gt;Remote Errors&lt;/code&gt; at some point as part my process. &lt;/p&gt;

&lt;p&gt;Remote errors are enabled via the SSRS Service Application:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Navigate to &lt;code&gt;Central Administration &amp;gt; Application Management &amp;gt; Manage Service Applications&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Next, click on the appropriate  &lt;code&gt;SQL Server Reporting Services Service Application&lt;/code&gt; service application to manage it. &lt;/li&gt;
&lt;li&gt;Click &lt;code&gt;System Settings&lt;/code&gt; from the toolbar.&lt;/li&gt;
&lt;li&gt;Finally, enable remote errors by navigating into checking the &lt;code&gt;Enable Remote Errors&lt;/code&gt; checkbox. &lt;/li&gt;
&lt;/ol&gt;

</summary><published>2015-08-27T18:30:00Z</published><updated>2015-08-27T18:30:00Z</updated><link rel="alternate" href="http://nullfactory.net/2015/08/enable-ssrs-remote-error-sharepoint-integrated/" /><content type="html">&lt;p&gt;Any time I have to troubleshoot issues in SQL Server Reporting Services (SSRS) reports in a production environment, I usually end up enabling &lt;code&gt;Remote Errors&lt;/code&gt; at some point as part my process. &lt;/p&gt;

&lt;p&gt;Remote errors are enabled via the SSRS Service Application:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Navigate to &lt;code&gt;Central Administration &amp;gt; Application Management &amp;gt; Manage Service Applications&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Next, click on the appropriate  &lt;code&gt;SQL Server Reporting Services Service Application&lt;/code&gt; service application to manage it. &lt;/li&gt;
&lt;li&gt;Click &lt;code&gt;System Settings&lt;/code&gt; from the toolbar.&lt;/li&gt;
&lt;li&gt;Finally, enable remote errors by navigating into checking the &lt;code&gt;Enable Remote Errors&lt;/code&gt; checkbox. &lt;/li&gt;
&lt;/ol&gt;

&lt;!--excerpt--&gt;

&lt;p&gt;Although the &lt;a href="https://msdn.microsoft.com/en-us/library/aa337165.aspx"&gt;MSDN documentation&lt;/a&gt; states that this is all that is required, I've found that I need to enable it on the individual site's settings in order to get it working:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Navigate to &lt;code&gt;Site Settings &amp;gt; Reporting Services &amp;gt; Reporting Services Site Settings&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Ensure that the &lt;code&gt;Enable Local Mode Error Messages&lt;/code&gt; is checked.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Once the troubleshooting session is over, follow the same steps in reverse order to disable remote errors.  &lt;/p&gt;

&lt;h2&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://msdn.microsoft.com/en-us/library/aa337165.aspx"&gt;Enable Remote Errors (Reporting Services)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/4850346/ssrs-remote-errors-enabled-but-not-working"&gt;StackOverflow - SSRS Remote Errors Enabled but NOT Working&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content></entry><entry><id>http://nullfactory.net/2015/06/entity-framework-multiple-context-namespace-collision/</id><title type="text">Entity Framework Namespace Collisions When Working with Multiple Contexts</title><summary type="html">&lt;p&gt;I came across the following exception whilst attempting working with a solution that contained a &lt;em&gt;couple of&lt;/em&gt; Entity Framework (EF) 6 database contexts.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;System.Data.Entity.Core.MetadataException

Schema specified is not valid. Errors: 
The mapping of CLR type to EDM type is ambiguous because multiple CLR types match the EDM type 'Setting'. Previously found CLR type 'SqlHelper.Primary.Setting', newly found CLR type 'SqlHelper.Secondary.Setting'.

at System.Data.Entity.Core.Metadata.Edm.ObjectItemCollection.LoadAssemblyFromCache(Assembly assembly, Boolean loadReferencedAssemblies, EdmItemCollection edmItemCollection, Action`1 logLoadMessage)
at System.Data.Entity.Core.Metadata.Edm.ObjectItemCollection.ExplicitLoadFromAssembly(Assembly assembly, EdmItemCollection edmItemCollection, Action`1 logLoadMessage)
at System.Data.Entity.Core.Metadata.Edm.MetadataWorkspace.ExplicitLoadFromAssembly(Assembly assembly, ObjectItemCollection collection, Action`1 logLoadMessage)
at System.Data.Entity.Core.Metadata.Edm.MetadataWorkspace.LoadFromAssembly(Assembly assembly, Action`1 logLoadMessage)
at System.Data.Entity.Core.Metadata.Edm.MetadataWorkspace.LoadFromAssembly(Assembly assembly)
at System.Data.Entity.Internal.InternalContext.TryUpdateEntitySetMappingsForType(Type entityType)
at System.Data.Entity.Internal.InternalContext.UpdateEntitySetMappingsForType(Type entityType)
at System.Data.Entity.Internal.InternalContext.GetEntitySetAndBaseTypeForType(Type entityType)
at System.Data.Entity.Internal.Linq.InternalSet`1.Initialize()
at System.Data.Entity.Internal.Linq.InternalSet`1.get_InternalContext()
at System.Data.Entity.Internal.Linq.InternalSet`1.ActOnSet(Action action, EntityState newState, Object entity, String methodName)
at System.Data.Entity.Internal.Linq.InternalSet`1.Add(Object entity)
at System.Data.Entity.DbSet`1.Add(TEntity entity)
at MultiContextConsoleApp.Program.Main(String[] args) in e:\shane\Projects\Orca\Sandbox\MultiContextConsoleApp\MultiContextConsoleApp\Program.cs:line 16
at System.AppDomain._nExecuteAssembly(RuntimeAssembly assembly, String[] args)
at System.AppDomain.ExecuteAssembly(String assemblyFile, Evidence assemblySecurity, String[] args)
at Microsoft.VisualStudio.HostingProcess.HostProc.RunUsersAssembly()
at System.Threading.ThreadHelper.ThreadStart_Context(Object state)
at System.Threading.ExecutionContext.RunInternal(ExecutionContext executionContext, ContextCallback callback, Object state, Boolean preserveSyncCtx)
at System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Object state, Boolean preserveSyncCtx)
at System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Object state)
at System.Threading.ThreadHelper.ThreadStart()
&lt;/code&gt;&lt;/pre&gt;

</summary><published>2015-06-02T18:30:00Z</published><updated>2015-06-02T18:30:00Z</updated><link rel="alternate" href="http://nullfactory.net/2015/06/entity-framework-multiple-context-namespace-collision/" /><content type="html">&lt;p&gt;I came across the following exception whilst attempting working with a solution that contained a &lt;em&gt;couple of&lt;/em&gt; Entity Framework (EF) 6 database contexts.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;System.Data.Entity.Core.MetadataException

Schema specified is not valid. Errors: 
The mapping of CLR type to EDM type is ambiguous because multiple CLR types match the EDM type 'Setting'. Previously found CLR type 'SqlHelper.Primary.Setting', newly found CLR type 'SqlHelper.Secondary.Setting'.

at System.Data.Entity.Core.Metadata.Edm.ObjectItemCollection.LoadAssemblyFromCache(Assembly assembly, Boolean loadReferencedAssemblies, EdmItemCollection edmItemCollection, Action`1 logLoadMessage)
at System.Data.Entity.Core.Metadata.Edm.ObjectItemCollection.ExplicitLoadFromAssembly(Assembly assembly, EdmItemCollection edmItemCollection, Action`1 logLoadMessage)
at System.Data.Entity.Core.Metadata.Edm.MetadataWorkspace.ExplicitLoadFromAssembly(Assembly assembly, ObjectItemCollection collection, Action`1 logLoadMessage)
at System.Data.Entity.Core.Metadata.Edm.MetadataWorkspace.LoadFromAssembly(Assembly assembly, Action`1 logLoadMessage)
at System.Data.Entity.Core.Metadata.Edm.MetadataWorkspace.LoadFromAssembly(Assembly assembly)
at System.Data.Entity.Internal.InternalContext.TryUpdateEntitySetMappingsForType(Type entityType)
at System.Data.Entity.Internal.InternalContext.UpdateEntitySetMappingsForType(Type entityType)
at System.Data.Entity.Internal.InternalContext.GetEntitySetAndBaseTypeForType(Type entityType)
at System.Data.Entity.Internal.Linq.InternalSet`1.Initialize()
at System.Data.Entity.Internal.Linq.InternalSet`1.get_InternalContext()
at System.Data.Entity.Internal.Linq.InternalSet`1.ActOnSet(Action action, EntityState newState, Object entity, String methodName)
at System.Data.Entity.Internal.Linq.InternalSet`1.Add(Object entity)
at System.Data.Entity.DbSet`1.Add(TEntity entity)
at MultiContextConsoleApp.Program.Main(String[] args) in e:\shane\Projects\Orca\Sandbox\MultiContextConsoleApp\MultiContextConsoleApp\Program.cs:line 16
at System.AppDomain._nExecuteAssembly(RuntimeAssembly assembly, String[] args)
at System.AppDomain.ExecuteAssembly(String assemblyFile, Evidence assemblySecurity, String[] args)
at Microsoft.VisualStudio.HostingProcess.HostProc.RunUsersAssembly()
at System.Threading.ThreadHelper.ThreadStart_Context(Object state)
at System.Threading.ExecutionContext.RunInternal(ExecutionContext executionContext, ContextCallback callback, Object state, Boolean preserveSyncCtx)
at System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Object state, Boolean preserveSyncCtx)
at System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Object state)
at System.Threading.ThreadHelper.ThreadStart()
&lt;/code&gt;&lt;/pre&gt;

&lt;!--excerpt--&gt;

&lt;h2&gt;Reproducing the Problem&lt;/h2&gt;

&lt;p&gt;Here's a quick run down of the steps required to reproduce the scenario:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Start off by creating two databases.&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Create a new table with the same name on each of them.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/EFNamespaceConflict/10_DatabaseSchema.png" alt="Database Schema" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Next, open up Visual Studio and create a Class Library project to host both EF database contexts.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Within the same project, create two EF (&lt;em&gt;ADO.NET Entity Data Model&lt;/em&gt;) contexts; one for each database. Ensure that each context is under its own namespace.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/EFNamespaceConflict/15_InitialProjectStructure.png" alt="Project Structure" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/EFNamespaceConflict/20_PrimaryContext.png" alt="Primary Context" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/EFNamespaceConflict/30_SecondaryContext.png" alt="Secondary Context" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/EFNamespaceConflict/40_PrimarySetting.png" alt="Primary Context Settings File" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/EFNamespaceConflict/50_SecondarySetting.png" alt="Secondary Context Settings File" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Next, let's create a simple console application that would act as the client and invoke operations on the contexts. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Run the application - an exception is thrown the moment there is any kind of interaction with either of the contexts. &lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/EFNamespaceConflict/60_Exception.png" alt="SSMS Context Menu" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2&gt;The Solution&lt;/h2&gt;

&lt;p&gt;This issue is only reproducible when working with multiple database contexts that have tables with the same name and share the same assembly. It does not even matter that the contexts are across different namespaces. &lt;/p&gt;

&lt;p&gt;The problem appears to be how Entity Framework resolves namespaces, &lt;a href="http://entityframework.codeplex.com/workitem/483"&gt;this ticket goes into more detail&lt;/a&gt;. I was able to reproduce this with the latest version of EF and a fix does not appear to be on the immediate schedule. &lt;/p&gt;

&lt;p&gt;Luckily there are couple of workarounds which are pretty straightforward:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Make sure that that both contexts don't share tables with the same name - &lt;em&gt;not the most practical approach&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Restructure the solution by isolating the database contexts within their own assemblies.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/EFNamespaceConflict/70_NewProjectStructure.png" alt="SSMS Context Menu" /&gt;   &lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="http://entityframework.codeplex.com/workitem/483"&gt;CodePlex - Entity Framework - View Issue #483: Can't map two classes with same name from different namespace&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/14927391/the-mapping-of-clr-type-to-edm-type-is-ambiguous-with-ef-6-5"&gt;StackOverflow.com - c# - The mapping of CLR type to EDM type is ambiguous with EF 6 &amp;amp; 5?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://social.msdn.microsoft.com/Forums/en-US/5a8ea003-c6bc-4fc6-ad2a-634f09447c49/ef4-mapping-of-clr-type-to-edm-type-is-ambiguous-error?forum=adodotnetentityframework"&gt;MSDN Forum - EF4 Mapping of CLR type to EDM type is ambiguous error.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content></entry><entry><id>http://nullfactory.net/2015/06/generate-clean-up-script-drop-objects-sql-database/</id><title type="text">Generate a Clean Up Script to Drop All Objects in a SQL Server Database</title><summary type="html">&lt;p&gt;I needed a quick and reusable way to drop all SQL server objects from an Azure database. The objective was to have some kind of process to clean up and prep the database before the main deployment is kicked off. And given that I am particularly biased towards using a sql script my search for a solution focused around it.&lt;/p&gt;

&lt;p&gt;In addition to actually dropping the artifacts, the script should be aware of the order in which it should do it - that is to drop the most dependent objects first and work its way towards the least dependent ones. And my nice-to-have feature is to be able to parameterize the schema name so that it could be used with a multi-tenant database schema.&lt;/p&gt;

&lt;p&gt;I saw a few possible solutions and finally settled on using the &lt;a href="http://stackoverflow.com/questions/536350/drop-all-the-tables-stored-procedures-triggers-constraints-and-all-the-depend"&gt;out-of-the-box feature&lt;/a&gt; that's already available through SQL Server Management Studio (SSMS).&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Open up SQL Server Management Studio.&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Select &lt;code&gt;Task  &amp;gt; Generate Script...&lt;/code&gt; on on your the database context menu. This would open up the &lt;code&gt;Generate and Publish Scripts&lt;/code&gt; dialog.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/GenerateDropScript/10_ContextMenu.png" alt="SSMS Context Menu" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;First, navigate to the &lt;code&gt;Choose Objects&lt;/code&gt; tab and select all the objects that need to be dropped.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Next, on the &lt;code&gt;Set Scripting Options&lt;/code&gt; tab, select the preferred output location.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/GenerateDropScript/20_SetScriptingOptions.png" alt="Set Scripting Options" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Next, click the &lt;code&gt;Advanced&lt;/code&gt; button which result in the &lt;code&gt;Advanced Scripting Options&lt;/code&gt; dialog.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/GenerateDropScript/30_AdvancedScriptingOptions.png" alt="Advanced Scripting Options" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Navigate down towards to and change the &lt;code&gt;General &amp;gt; Script DROP and CREATE&lt;/code&gt; option to &lt;code&gt;Script DROP&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;Set the default values for the rest of the steps and finally click the &lt;code&gt;Finish&lt;/code&gt; button.&lt;/li&gt;
&lt;/ol&gt;

</summary><published>2015-06-01T18:30:00Z</published><updated>2015-06-01T18:30:00Z</updated><link rel="alternate" href="http://nullfactory.net/2015/06/generate-clean-up-script-drop-objects-sql-database/" /><content type="html">&lt;p&gt;I needed a quick and reusable way to drop all SQL server objects from an Azure database. The objective was to have some kind of process to clean up and prep the database before the main deployment is kicked off. And given that I am particularly biased towards using a sql script my search for a solution focused around it.&lt;/p&gt;

&lt;p&gt;In addition to actually dropping the artifacts, the script should be aware of the order in which it should do it - that is to drop the most dependent objects first and work its way towards the least dependent ones. And my nice-to-have feature is to be able to parameterize the schema name so that it could be used with a multi-tenant database schema.&lt;/p&gt;

&lt;p&gt;I saw a few possible solutions and finally settled on using the &lt;a href="http://stackoverflow.com/questions/536350/drop-all-the-tables-stored-procedures-triggers-constraints-and-all-the-depend"&gt;out-of-the-box feature&lt;/a&gt; that's already available through SQL Server Management Studio (SSMS).&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Open up SQL Server Management Studio.&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Select &lt;code&gt;Task  &amp;gt; Generate Script...&lt;/code&gt; on on your the database context menu. This would open up the &lt;code&gt;Generate and Publish Scripts&lt;/code&gt; dialog.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/GenerateDropScript/10_ContextMenu.png" alt="SSMS Context Menu" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;First, navigate to the &lt;code&gt;Choose Objects&lt;/code&gt; tab and select all the objects that need to be dropped.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Next, on the &lt;code&gt;Set Scripting Options&lt;/code&gt; tab, select the preferred output location.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/GenerateDropScript/20_SetScriptingOptions.png" alt="Set Scripting Options" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Next, click the &lt;code&gt;Advanced&lt;/code&gt; button which result in the &lt;code&gt;Advanced Scripting Options&lt;/code&gt; dialog.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://nullfactory.net/images/posts/GenerateDropScript/30_AdvancedScriptingOptions.png" alt="Advanced Scripting Options" /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Navigate down towards to and change the &lt;code&gt;General &amp;gt; Script DROP and CREATE&lt;/code&gt; option to &lt;code&gt;Script DROP&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;Set the default values for the rest of the steps and finally click the &lt;code&gt;Finish&lt;/code&gt; button.&lt;/li&gt;
&lt;/ol&gt;

&lt;!--excerpt--&gt;

&lt;p&gt;SSMS sorts out the dependencies and generates a script similar to the one below. Note that the statements are in the required sequence.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;USE [test]
GO
ALTER TABLE [dbo].[Contact] DROP CONSTRAINT [FK_Contact_Company]
GO
/****** Object:  Table [dbo].[Contact]Script Date: 6/2/2015 9:33:36 AM ******/
DROP TABLE [dbo].[Contact]
GO
/****** Object:  Table [dbo].[Company]Script Date: 6/2/2015 9:33:36 AM ******/
DROP TABLE [dbo].[Company]
GO
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I finally made the following tweaks to convert the script to a &lt;code&gt;SQLCMD&lt;/code&gt; script and parameterize the schema:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;:setvar TenantSchemaName "scm"

ALTER TABLE [$(TenantSchemaName)].[Contact] DROP CONSTRAINT [FK_Contact_Company]
GO
/****** Object:  Table [$(TenantSchemaName)].[Contact]    Script Date: 6/2/2015 9:33:36 AM ******/
DROP TABLE [$(TenantSchemaName)].[Contact]
GO
/****** Object:  Table [$(TenantSchemaName)].[Company]    Script Date: 6/2/2015 9:33:36 AM ******/
DROP TABLE [$(TenantSchemaName)].[Company]
GO
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Although, I was not really focused on automation, it should not be too difficult to integrate it with existing automated processes.&lt;/p&gt;

&lt;h2&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/536350/drop-all-the-tables-stored-procedures-triggers-constraints-and-all-the-depend"&gt;StackOverflow.com - sql server - Drop all the tables, stored procedures, triggers, constraints and all the dependencies in one sql statement - Stack Overflow&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content></entry></feed>